Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Traceback (most recent call last):
  File "/home/ubuntu/anaconda3/envs/torch16/bin/fairseq-train", line 33, in <module>
    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())
  File "/home/ubuntu/courses/fairseq/fairseq_cli/train.py", line 352, in cli_main
    distributed_utils.call_main(args, main)
  File "/home/ubuntu/courses/fairseq/fairseq/distributed_utils.py", line 241, in call_main
    torch.multiprocessing.spawn(
  File "/home/ubuntu/anaconda3/envs/torch16/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 200, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/home/ubuntu/anaconda3/envs/torch16/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 158, in start_processes
    while not context.join():
  File "/home/ubuntu/anaconda3/envs/torch16/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 111, in join
    raise Exception(
Exception: process 0 terminated with exit code 1
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:27:02 | INFO | fairseq.distributed_utils | distributed init (rank 0): tcp://localhost:16503
2020-10-13 10:27:02 | INFO | fairseq.distributed_utils | distributed init (rank 1): tcp://localhost:16503
2020-10-13 10:27:02 | INFO | fairseq.distributed_utils | initialized host ip-172-31-31-6 as rank 1
2020-10-13 10:27:02 | INFO | fairseq.distributed_utils | initialized host ip-172-31-31-6 as rank 0
2020-10-13 10:27:06 | WARNING | fairseq.data.multilingual.multilingual_data_manager | External language dictionary is not provided; use lang-pairs to infer the set of supported languages. The language ordering is not stable which might cause misalignment in pretraining and finetuning.
2020-10-13 10:27:06 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_iwslt_de_en', attention_dropout=0.0, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', clip_norm=25.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='fairseq/data-bin/ted_azeazpturtup_sepspm8000/M2O/', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_langtok=False, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method='tcp://localhost:16503', distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, enable_lang_ids=False, enable_reservsed_directions_shared_datasets=False, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_langtok=None, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, extra_data=None, extra_lang_pairs=None, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', keep_best_checkpoints=-1, keep_inference_langtok=False, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, lang_dict=None, lang_pairs='aze-eng,tur-eng,azp-eng,tup-eng', lang_tok_replacing_bos_eos=False, lang_tok_style='multilingual', langs=None, langtoks=None, langtoks_specs=['main'], layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, local_rank=0, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0002], lr_scheduler='inverse_sqrt', max_epoch=40, max_source_positions=1024, max_target_positions=1024, max_tokens=4500, max_tokens_valid=4500, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', sampling_method='concat', sampling_temperature=1.5, sampling_weights=None, sampling_weights_from_file=None, save_dir='fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/', save_interval=1, save_interval_updates=0, scoring='bleu', seed=2, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0, target_lang=None, task='translation_multi_simple_epoch', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[2], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, virtual_data_size=None, virtual_epoch_size=1000000, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0, zero_sharding='none')
2020-10-13 10:27:06 | WARNING | fairseq.data.multilingual.multilingual_data_manager | External language dictionary is not provided; use lang-pairs to infer the set of supported languages. The language ordering is not stable which might cause misalignment in pretraining and finetuning.
2020-10-13 10:27:06 | INFO | fairseq.data.multilingual.multilingual_data_manager | inferred language list: ['aze', 'azp', 'eng', 'tup', 'tur']
2020-10-13 10:27:06 | INFO | fairseq.data.multilingual.multilingual_data_manager | [aze] dictionary: 32621 types
2020-10-13 10:27:06 | INFO | fairseq.data.multilingual.multilingual_data_manager | [azp] dictionary: 32621 types
2020-10-13 10:27:06 | INFO | fairseq.data.multilingual.multilingual_data_manager | [eng] dictionary: 32621 types
2020-10-13 10:27:06 | INFO | fairseq.data.multilingual.multilingual_data_manager | [tup] dictionary: 32621 types
2020-10-13 10:27:06 | INFO | fairseq.data.multilingual.multilingual_data_manager | [tur] dictionary: 32621 types
2020-10-13 10:27:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | loading data for valid epoch=1/None
2020-10-13 10:27:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=6155.05078125Mb; avail=238399.6328125Mb
2020-10-13 10:27:06 | INFO | fairseq.data.multilingual.multilingual_data_manager | langtoks settings: {'main': (None, None)}
2020-10-13 10:27:06 | INFO | fairseq.data.multilingual.multilingual_data_manager | [valid] num of shards: {'main:aze-eng': 1, 'main:tur-eng': 1, 'main:azp-eng': 1, 'main:tup-eng': 1}
2020-10-13 10:27:06 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:aze-eng src_langtok: None; tgt_langtok: None
2020-10-13 10:27:06 | INFO | fairseq.data.data_utils | loaded 671 examples from: fairseq/data-bin/ted_azeazpturtup_sepspm8000/M2O/valid.aze-eng.aze
2020-10-13 10:27:06 | INFO | fairseq.data.data_utils | loaded 671 examples from: fairseq/data-bin/ted_azeazpturtup_sepspm8000/M2O/valid.aze-eng.eng
2020-10-13 10:27:06 | INFO | fairseq.data.multilingual.multilingual_data_manager | fairseq/data-bin/ted_azeazpturtup_sepspm8000/M2O/ valid aze-eng 671 examples
2020-10-13 10:27:06 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:tur-eng src_langtok: None; tgt_langtok: None
2020-10-13 10:27:06 | INFO | fairseq.data.data_utils | loaded 4045 examples from: fairseq/data-bin/ted_azeazpturtup_sepspm8000/M2O/valid.tur-eng.tur
2020-10-13 10:27:06 | INFO | fairseq.data.data_utils | loaded 4045 examples from: fairseq/data-bin/ted_azeazpturtup_sepspm8000/M2O/valid.tur-eng.eng
2020-10-13 10:27:06 | INFO | fairseq.data.multilingual.multilingual_data_manager | fairseq/data-bin/ted_azeazpturtup_sepspm8000/M2O/ valid tur-eng 4045 examples
2020-10-13 10:27:06 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:azp-eng src_langtok: None; tgt_langtok: None
2020-10-13 10:27:06 | INFO | fairseq.data.data_utils | loaded 671 examples from: fairseq/data-bin/ted_azeazpturtup_sepspm8000/M2O/valid.azp-eng.azp
2020-10-13 10:27:06 | INFO | fairseq.data.data_utils | loaded 671 examples from: fairseq/data-bin/ted_azeazpturtup_sepspm8000/M2O/valid.azp-eng.eng
2020-10-13 10:27:06 | INFO | fairseq.data.multilingual.multilingual_data_manager | fairseq/data-bin/ted_azeazpturtup_sepspm8000/M2O/ valid azp-eng 671 examples
2020-10-13 10:27:06 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:tup-eng src_langtok: None; tgt_langtok: None
2020-10-13 10:27:06 | INFO | fairseq.data.data_utils | loaded 4045 examples from: fairseq/data-bin/ted_azeazpturtup_sepspm8000/M2O/valid.tup-eng.tup
2020-10-13 10:27:06 | INFO | fairseq.data.data_utils | loaded 4045 examples from: fairseq/data-bin/ted_azeazpturtup_sepspm8000/M2O/valid.tup-eng.eng
2020-10-13 10:27:06 | INFO | fairseq.data.multilingual.multilingual_data_manager | fairseq/data-bin/ted_azeazpturtup_sepspm8000/M2O/ valid tup-eng 4045 examples
2020-10-13 10:27:07 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(32621, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(32621, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=32621, bias=False)
  )
)
2020-10-13 10:27:07 | INFO | fairseq_cli.train | task: translation_multi_simple_epoch (TranslationMultiSimpleEpochTask)
2020-10-13 10:27:07 | INFO | fairseq_cli.train | model: transformer_iwslt_de_en (TransformerModel)
2020-10-13 10:27:07 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2020-10-13 10:27:07 | INFO | fairseq_cli.train | num. model params: 48245248 (num. trained: 48245248)
2020-10-13 10:27:07 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2020-10-13 10:27:07 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2020-10-13 10:27:07 | INFO | fairseq.utils | ***********************CUDA enviroments for all 2 workers***********************
2020-10-13 10:27:07 | INFO | fairseq.utils | rank   0: capabilities =  7.0  ; total memory = 15.752 GB ; name = Tesla V100-SXM2-16GB                    
2020-10-13 10:27:07 | INFO | fairseq.utils | rank   1: capabilities =  7.0  ; total memory = 15.752 GB ; name = Tesla V100-SXM2-16GB                    
2020-10-13 10:27:07 | INFO | fairseq.utils | ***********************CUDA enviroments for all 2 workers***********************
2020-10-13 10:27:07 | INFO | fairseq_cli.train | training on 2 devices (GPUs/TPUs)
2020-10-13 10:27:07 | INFO | fairseq_cli.train | max tokens per GPU = 4500 and max sentences per GPU = None
2020-10-13 10:27:07 | INFO | fairseq.trainer | no existing checkpoint found fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/checkpoint_last.pt
2020-10-13 10:27:07 | INFO | fairseq.trainer | loading train data for epoch 1
2020-10-13 10:27:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | loading data for train epoch=1/None
2020-10-13 10:27:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=6401.91796875Mb; avail=238152.77734375Mb
2020-10-13 10:27:07 | INFO | fairseq.data.multilingual.multilingual_data_manager | langtoks settings: {'main': (None, None)}
2020-10-13 10:27:07 | INFO | fairseq.data.multilingual.multilingual_data_manager | [train] num of shards: {'main:aze-eng': 1, 'main:tur-eng': 1, 'main:azp-eng': 1, 'main:tup-eng': 1}
2020-10-13 10:27:07 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:aze-eng src_langtok: None; tgt_langtok: None
2020-10-13 10:27:07 | INFO | fairseq.data.data_utils | loaded 5946 examples from: fairseq/data-bin/ted_azeazpturtup_sepspm8000/M2O/train.aze-eng.aze
2020-10-13 10:27:07 | INFO | fairseq.data.data_utils | loaded 5946 examples from: fairseq/data-bin/ted_azeazpturtup_sepspm8000/M2O/train.aze-eng.eng
2020-10-13 10:27:07 | INFO | fairseq.data.multilingual.multilingual_data_manager | fairseq/data-bin/ted_azeazpturtup_sepspm8000/M2O/ train aze-eng 5946 examples
2020-10-13 10:27:07 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:tur-eng src_langtok: None; tgt_langtok: None
2020-10-13 10:27:07 | INFO | fairseq.data.data_utils | loaded 182419 examples from: fairseq/data-bin/ted_azeazpturtup_sepspm8000/M2O/train.tur-eng.tur
2020-10-13 10:27:07 | INFO | fairseq.data.data_utils | loaded 182419 examples from: fairseq/data-bin/ted_azeazpturtup_sepspm8000/M2O/train.tur-eng.eng
2020-10-13 10:27:07 | INFO | fairseq.data.multilingual.multilingual_data_manager | fairseq/data-bin/ted_azeazpturtup_sepspm8000/M2O/ train tur-eng 182419 examples
2020-10-13 10:27:07 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:azp-eng src_langtok: None; tgt_langtok: None
2020-10-13 10:27:07 | INFO | fairseq.data.data_utils | loaded 5946 examples from: fairseq/data-bin/ted_azeazpturtup_sepspm8000/M2O/train.azp-eng.azp
2020-10-13 10:27:07 | INFO | fairseq.data.data_utils | loaded 5946 examples from: fairseq/data-bin/ted_azeazpturtup_sepspm8000/M2O/train.azp-eng.eng
2020-10-13 10:27:07 | INFO | fairseq.data.multilingual.multilingual_data_manager | fairseq/data-bin/ted_azeazpturtup_sepspm8000/M2O/ train azp-eng 5946 examples
2020-10-13 10:27:07 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:tup-eng src_langtok: None; tgt_langtok: None
2020-10-13 10:27:07 | INFO | fairseq.data.data_utils | loaded 182414 examples from: fairseq/data-bin/ted_azeazpturtup_sepspm8000/M2O/train.tup-eng.tup
2020-10-13 10:27:07 | INFO | fairseq.data.data_utils | loaded 182414 examples from: fairseq/data-bin/ted_azeazpturtup_sepspm8000/M2O/train.tup-eng.eng
2020-10-13 10:27:07 | INFO | fairseq.data.multilingual.multilingual_data_manager | fairseq/data-bin/ted_azeazpturtup_sepspm8000/M2O/ train tup-eng 182414 examples
2020-10-13 10:27:07 | WARNING | fairseq.data.multilingual.sampled_multi_epoch_dataset | virtual epoch size 1000000 is greater than virtual dataset size 376725
2020-10-13 10:27:07 | INFO | fairseq.data.multilingual.multilingual_data_manager | estimated total data sizes of all shards used in sampling ratios: [('main:aze-eng', 5946), ('main:tur-eng', 182419), ('main:azp-eng', 5946), ('main:tup-eng', 182414)]. Note that if the data a shard has not been loaded yet, use the max known data size to approximate
2020-10-13 10:27:07 | INFO | fairseq.data.multilingual.sampling_method | selected sampler: concat
2020-10-13 10:27:07 | WARNING | fairseq.data.multilingual.sampled_multi_epoch_dataset | virtual epoch size 1000000 is greater than virtual dataset size 376725
2020-10-13 10:27:07 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | virtual epoch size 376725; virtual dataset size 376725
2020-10-13 10:27:07 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=1/shard_epoch=1
2020-10-13 10:27:07 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:aze-eng': 5946, 'main:tur-eng': 182419, 'main:azp-eng': 5946, 'main:tup-eng': 182414}; raw total size: 376725
2020-10-13 10:27:07 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:aze-eng': 5946, 'main:tur-eng': 182419, 'main:azp-eng': 5946, 'main:tup-eng': 182414}; resampled total size: 376725
2020-10-13 10:27:07 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] A concat dataset
2020-10-13 10:27:07 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.041551
2020-10-13 10:27:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=6404.37890625Mb; avail=238150.31640625Mb
2020-10-13 10:27:07 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.006964
2020-10-13 10:27:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.079319
2020-10-13 10:27:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=6415.43359375Mb; avail=238139.26171875Mb
2020-10-13 10:27:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.003213
2020-10-13 10:27:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=6415.0234375Mb; avail=238139.671875Mb
2020-10-13 10:27:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.476222
2020-10-13 10:27:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.559656
2020-10-13 10:27:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=6438.3515625Mb; avail=238116.359375Mb
2020-10-13 10:27:09 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16
2020-10-13 10:27:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=6437.78515625Mb; avail=238116.92578125Mb
2020-10-13 10:27:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.061451
2020-10-13 10:27:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=6429.21484375Mb; avail=238125.49609375Mb
2020-10-13 10:27:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.002816
2020-10-13 10:27:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=6429.21484375Mb; avail=238125.49609375Mb
2020-10-13 10:27:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.500564
2020-10-13 10:27:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.565695
2020-10-13 10:27:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=6436.40625Mb; avail=238118.3046875Mb
2020-10-13 10:27:10 | INFO | fairseq.trainer | begin training epoch 1
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:27:49 | INFO | train_inner | epoch 001:    100 / 634 loss=14.53, nll_loss=14.398, ppl=21584.1, wps=44827.8, ups=2.81, wpb=15907.7, bsz=584, num_updates=100, lr=5.0975e-06, gnorm=4.485, clip=0, train_wall=35, wall=42
2020-10-13 10:28:25 | INFO | train_inner | epoch 001:    200 / 634 loss=12.758, nll_loss=12.421, ppl=5484.92, wps=43972.7, ups=2.78, wpb=15794.1, bsz=620.2, num_updates=200, lr=1.0095e-05, gnorm=1.865, clip=0, train_wall=34, wall=78
2020-10-13 10:29:01 | INFO | train_inner | epoch 001:    300 / 634 loss=11.863, nll_loss=11.421, ppl=2742.07, wps=44456.1, ups=2.81, wpb=15848.8, bsz=590.5, num_updates=300, lr=1.50925e-05, gnorm=1.435, clip=0, train_wall=34, wall=114
2020-10-13 10:29:37 | INFO | train_inner | epoch 001:    400 / 634 loss=10.673, nll_loss=10.067, ppl=1072.35, wps=43873.1, ups=2.79, wpb=15709.7, bsz=595.3, num_updates=400, lr=2.009e-05, gnorm=1.623, clip=0, train_wall=34, wall=150
2020-10-13 10:30:13 | INFO | train_inner | epoch 001:    500 / 634 loss=9.747, nll_loss=8.973, ppl=502.59, wps=43977.6, ups=2.79, wpb=15779.2, bsz=587.4, num_updates=500, lr=2.50875e-05, gnorm=1.034, clip=0, train_wall=34, wall=186
2020-10-13 10:30:48 | INFO | train_inner | epoch 001:    600 / 634 loss=9.398, nll_loss=8.527, ppl=368.77, wps=43633.5, ups=2.79, wpb=15630.1, bsz=603.5, num_updates=600, lr=3.0085e-05, gnorm=1.343, clip=0, train_wall=34, wall=222
2020-10-13 10:31:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 10:31:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13281.70703125Mb; avail=231247.5546875Mb
2020-10-13 10:31:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001829
2020-10-13 10:31:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13281.70703125Mb; avail=231247.5546875Mb
2020-10-13 10:31:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.127965
2020-10-13 10:31:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13272.890625Mb; avail=231256.37109375Mb
2020-10-13 10:31:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.097022
2020-10-13 10:31:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.227604
2020-10-13 10:31:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13272.890625Mb; avail=231256.37109375Mb
2020-10-13 10:31:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13275.3046875Mb; avail=231253.95703125Mb
2020-10-13 10:31:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001706
2020-10-13 10:31:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13275.3046875Mb; avail=231253.95703125Mb
2020-10-13 10:31:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.129503
2020-10-13 10:31:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13279.1640625Mb; avail=231250.09765625Mb
2020-10-13 10:31:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.095470
2020-10-13 10:31:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.227525
2020-10-13 10:31:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13273.62109375Mb; avail=231255.640625Mb
/home/ubuntu/courses/fairseq/fairseq/utils.py:340: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
/home/ubuntu/courses/fairseq/fairseq/utils.py:340: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:31:07 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.999 | nll_loss 7.996 | ppl 255.21 | wps 92005.1 | wpb 5051.4 | bsz 192.5 | num_updates 634
2020-10-13 10:31:07 | INFO | fairseq_cli.train | begin save checkpoint
2020-10-13 10:31:09 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/checkpoint_best.pt (epoch 1 @ 634 updates, score 8.999) (writing took 2.010903690941632 seconds)
2020-10-13 10:31:09 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2020-10-13 10:31:09 | INFO | train | epoch 001 | loss 11.385 | nll_loss 10.838 | ppl 1830.61 | wps 42582.1 | ups 2.7 | wpb 15785.1 | bsz 594.2 | num_updates 634 | lr 3.17842e-05 | gnorm 1.927 | clip 0 | train_wall 218 | wall 242
2020-10-13 10:31:09 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=2/shard_epoch=1
2020-10-13 10:31:09 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=2/shard_epoch=2
2020-10-13 10:31:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=12826.33984375Mb; avail=231703.1640625Mb
2020-10-13 10:31:09 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.008581
2020-10-13 10:31:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.080537
2020-10-13 10:31:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=12842.140625Mb; avail=231686.62890625Mb
2020-10-13 10:31:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.002754
2020-10-13 10:31:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=12842.140625Mb; avail=231686.62890625Mb
2020-10-13 10:31:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.499436
2020-10-13 10:31:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.583632
2020-10-13 10:31:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=12851.41015625Mb; avail=231678.36328125Mb
2020-10-13 10:31:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=12842.890625Mb; avail=231686.8828125Mb
2020-10-13 10:31:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.064575
2020-10-13 10:31:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=12880.98046875Mb; avail=231648.79296875Mb
2020-10-13 10:31:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.003682
2020-10-13 10:31:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=12881.5859375Mb; avail=231648.1875Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:31:12 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.516693
2020-10-13 10:31:12 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.585932
2020-10-13 10:31:12 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=12998.3125Mb; avail=231531.34765625Mb
2020-10-13 10:31:12 | INFO | fairseq.trainer | begin training epoch 2
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:31:39 | INFO | train_inner | epoch 002:     66 / 634 loss=9.191, nll_loss=8.261, ppl=306.69, wps=31825.1, ups=1.99, wpb=15961.9, bsz=593, num_updates=700, lr=3.50825e-05, gnorm=1.267, clip=0, train_wall=34, wall=272
2020-10-13 10:32:14 | INFO | train_inner | epoch 002:    166 / 634 loss=9.066, nll_loss=8.109, ppl=276.19, wps=44078.5, ups=2.79, wpb=15816.5, bsz=596.1, num_updates=800, lr=4.008e-05, gnorm=1.334, clip=0, train_wall=34, wall=308
2020-10-13 10:32:50 | INFO | train_inner | epoch 002:    266 / 634 loss=8.825, nll_loss=7.834, ppl=228.23, wps=44181.7, ups=2.8, wpb=15806.1, bsz=574.3, num_updates=900, lr=4.50775e-05, gnorm=1.065, clip=0, train_wall=34, wall=343
2020-10-13 10:33:27 | INFO | train_inner | epoch 002:    366 / 634 loss=8.693, nll_loss=7.683, ppl=205.46, wps=43343.9, ups=2.76, wpb=15732.1, bsz=586.7, num_updates=1000, lr=5.0075e-05, gnorm=1.283, clip=0, train_wall=35, wall=380
2020-10-13 10:34:02 | INFO | train_inner | epoch 002:    466 / 634 loss=8.579, nll_loss=7.552, ppl=187.69, wps=43669.9, ups=2.8, wpb=15594.9, bsz=592.2, num_updates=1100, lr=5.50725e-05, gnorm=1.215, clip=0, train_wall=34, wall=415
2020-10-13 10:34:38 | INFO | train_inner | epoch 002:    566 / 634 loss=8.376, nll_loss=7.323, ppl=160.1, wps=43741.9, ups=2.77, wpb=15771.4, bsz=620, num_updates=1200, lr=6.007e-05, gnorm=1.285, clip=0, train_wall=35, wall=451
2020-10-13 10:35:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 10:35:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13447.421875Mb; avail=231081.7734375Mb
2020-10-13 10:35:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001787
2020-10-13 10:35:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13447.421875Mb; avail=231082.08984375Mb
2020-10-13 10:35:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.129790
2020-10-13 10:35:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13447.10546875Mb; avail=231082.08984375Mb
2020-10-13 10:35:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.096513
2020-10-13 10:35:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.228919
2020-10-13 10:35:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13451.34375Mb; avail=231077.8515625Mb
2020-10-13 10:35:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13452.5546875Mb; avail=231076.640625Mb
2020-10-13 10:35:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001614
2020-10-13 10:35:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13452.5546875Mb; avail=231076.640625Mb
2020-10-13 10:35:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.127464
2020-10-13 10:35:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13447.5703125Mb; avail=231081.625Mb
2020-10-13 10:35:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.097319
2020-10-13 10:35:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.227226
2020-10-13 10:35:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13447.640625Mb; avail=231081.5546875Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:35:09 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.981 | nll_loss 6.831 | ppl 113.89 | wps 91113.7 | wpb 5051.4 | bsz 192.5 | num_updates 1268 | best_loss 7.981
2020-10-13 10:35:09 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:35:15 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/checkpoint_best.pt (epoch 2 @ 1268 updates, score 7.981) (writing took 5.878026834921911 seconds)
2020-10-13 10:35:15 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2020-10-13 10:35:15 | INFO | train | epoch 002 | loss 8.711 | nll_loss 7.705 | ppl 208.71 | wps 40687 | ups 2.58 | wpb 15785.1 | bsz 594.2 | num_updates 1268 | lr 6.34683e-05 | gnorm 1.227 | clip 0 | train_wall 218 | wall 488
2020-10-13 10:35:15 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=3/shard_epoch=2
2020-10-13 10:35:15 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=3/shard_epoch=3
2020-10-13 10:35:15 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13107.34375Mb; avail=231422.09765625Mb
2020-10-13 10:35:15 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.007397
2020-10-13 10:35:15 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.079279
2020-10-13 10:35:15 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13119.4375Mb; avail=231410.00390625Mb
2020-10-13 10:35:15 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.002821
2020-10-13 10:35:15 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13120.04296875Mb; avail=231409.3984375Mb
2020-10-13 10:35:16 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.488222
2020-10-13 10:35:16 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.571222
2020-10-13 10:35:16 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13213.76953125Mb; avail=231315.8828125Mb
2020-10-13 10:35:16 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13192.30859375Mb; avail=231336.9296875Mb
2020-10-13 10:35:17 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.061578
2020-10-13 10:35:17 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13192.30859375Mb; avail=231336.9296875Mb
2020-10-13 10:35:17 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.002785
2020-10-13 10:35:17 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13192.30859375Mb; avail=231336.9296875Mb
2020-10-13 10:35:18 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.476676
2020-10-13 10:35:18 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.541900
2020-10-13 10:35:18 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13197.33203125Mb; avail=231331.890625Mb
2020-10-13 10:35:18 | INFO | fairseq.trainer | begin training epoch 3
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:35:32 | INFO | train_inner | epoch 003:     32 / 634 loss=8.277, nll_loss=7.211, ppl=148.16, wps=29433.1, ups=1.85, wpb=15876.6, bsz=594.3, num_updates=1300, lr=6.50675e-05, gnorm=1.126, clip=0, train_wall=34, wall=505
2020-10-13 10:36:08 | INFO | train_inner | epoch 003:    132 / 634 loss=8.208, nll_loss=7.131, ppl=140.15, wps=43321.6, ups=2.76, wpb=15675, bsz=571.3, num_updates=1400, lr=7.0065e-05, gnorm=1.118, clip=0, train_wall=35, wall=542
2020-10-13 10:36:44 | INFO | train_inner | epoch 003:    232 / 634 loss=8.036, nll_loss=6.936, ppl=122.46, wps=43996, ups=2.79, wpb=15793.7, bsz=639.4, num_updates=1500, lr=7.50625e-05, gnorm=1.171, clip=0, train_wall=34, wall=577
2020-10-13 10:37:20 | INFO | train_inner | epoch 003:    332 / 634 loss=7.996, nll_loss=6.89, ppl=118.62, wps=43959.2, ups=2.78, wpb=15787.5, bsz=576.5, num_updates=1600, lr=8.006e-05, gnorm=1.125, clip=0, train_wall=34, wall=613
2020-10-13 10:37:56 | INFO | train_inner | epoch 003:    432 / 634 loss=7.93, nll_loss=6.814, ppl=112.54, wps=43838.4, ups=2.78, wpb=15757.6, bsz=579.3, num_updates=1700, lr=8.50575e-05, gnorm=1.116, clip=0, train_wall=34, wall=649
2020-10-13 10:38:32 | INFO | train_inner | epoch 003:    532 / 634 loss=7.819, nll_loss=6.688, ppl=103.12, wps=43900.3, ups=2.77, wpb=15845, bsz=571.8, num_updates=1800, lr=9.0055e-05, gnorm=1.105, clip=0, train_wall=35, wall=685
2020-10-13 10:39:09 | INFO | train_inner | epoch 003:    632 / 634 loss=7.758, nll_loss=6.619, ppl=98.28, wps=43663.3, ups=2.76, wpb=15829.7, bsz=618.6, num_updates=1900, lr=9.50525e-05, gnorm=1.062, clip=0, train_wall=35, wall=722
2020-10-13 10:39:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 10:39:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13478.41796875Mb; avail=231050.0390625Mb
2020-10-13 10:39:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001874
2020-10-13 10:39:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13478.41796875Mb; avail=231050.0390625Mb
2020-10-13 10:39:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.130803
2020-10-13 10:39:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13478.65234375Mb; avail=231049.4140625Mb
2020-10-13 10:39:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.098304
2020-10-13 10:39:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.231783
2020-10-13 10:39:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13477.5625Mb; avail=231050.359375Mb
2020-10-13 10:39:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13477.609375Mb; avail=231050.8046875Mb
2020-10-13 10:39:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001688
2020-10-13 10:39:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13477.609375Mb; avail=231050.8046875Mb
2020-10-13 10:39:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.126693
2020-10-13 10:39:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13477.62109375Mb; avail=231050.07421875Mb
2020-10-13 10:39:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.097188
2020-10-13 10:39:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.226360
2020-10-13 10:39:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13487.55078125Mb; avail=231041.35546875Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:39:15 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 7.442 | nll_loss 6.204 | ppl 73.71 | wps 90972.5 | wpb 5051.4 | bsz 192.5 | num_updates 1902 | best_loss 7.442
2020-10-13 10:39:15 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:39:22 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/checkpoint_best.pt (epoch 3 @ 1902 updates, score 7.442) (writing took 6.628308878978714 seconds)
2020-10-13 10:39:22 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2020-10-13 10:39:22 | INFO | train | epoch 003 | loss 7.969 | nll_loss 6.859 | ppl 116.05 | wps 40456.1 | ups 2.56 | wpb 15785.1 | bsz 594.2 | num_updates 1902 | lr 9.51525e-05 | gnorm 1.116 | clip 0 | train_wall 219 | wall 735
2020-10-13 10:39:22 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=4/shard_epoch=3
2020-10-13 10:39:22 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=4/shard_epoch=4
2020-10-13 10:39:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13221.60546875Mb; avail=231307.08984375Mb
2020-10-13 10:39:22 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.006873
2020-10-13 10:39:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.092565
2020-10-13 10:39:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13237.5703125Mb; avail=231290.890625Mb
2020-10-13 10:39:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.003855
2020-10-13 10:39:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13237.5703125Mb; avail=231290.890625Mb
2020-10-13 10:39:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.658597
2020-10-13 10:39:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.756007
2020-10-13 10:39:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13229.57421875Mb; avail=231299.5703125Mb
2020-10-13 10:39:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13218.69921875Mb; avail=231309.71875Mb
2020-10-13 10:39:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.070437
2020-10-13 10:39:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13221.26953125Mb; avail=231307.6484375Mb
2020-10-13 10:39:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.003314
2020-10-13 10:39:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13221.91796875Mb; avail=231307.421875Mb
2020-10-13 10:39:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.537676
2020-10-13 10:39:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.612485
2020-10-13 10:39:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13226.4375Mb; avail=231302.28515625Mb
2020-10-13 10:39:26 | INFO | fairseq.trainer | begin training epoch 4
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:40:04 | INFO | train_inner | epoch 004:     98 / 634 loss=7.643, nll_loss=6.488, ppl=89.73, wps=28491.2, ups=1.8, wpb=15813.2, bsz=594.2, num_updates=2000, lr=0.00010005, gnorm=1.101, clip=0, train_wall=35, wall=777
2020-10-13 10:40:41 | INFO | train_inner | epoch 004:    198 / 634 loss=7.6, nll_loss=6.438, ppl=86.71, wps=42724.2, ups=2.71, wpb=15769.5, bsz=605, num_updates=2100, lr=0.000105048, gnorm=1.077, clip=0, train_wall=35, wall=814
2020-10-13 10:41:17 | INFO | train_inner | epoch 004:    298 / 634 loss=7.573, nll_loss=6.407, ppl=84.86, wps=43618.3, ups=2.74, wpb=15914.1, bsz=597.6, num_updates=2200, lr=0.000110045, gnorm=1.068, clip=0, train_wall=35, wall=851
2020-10-13 10:41:54 | INFO | train_inner | epoch 004:    398 / 634 loss=7.483, nll_loss=6.304, ppl=79.04, wps=44003.6, ups=2.76, wpb=15930, bsz=594.2, num_updates=2300, lr=0.000115043, gnorm=0.949, clip=0, train_wall=35, wall=887
2020-10-13 10:42:30 | INFO | train_inner | epoch 004:    498 / 634 loss=7.481, nll_loss=6.301, ppl=78.87, wps=43779.9, ups=2.78, wpb=15720, bsz=571.8, num_updates=2400, lr=0.00012004, gnorm=1.055, clip=0, train_wall=34, wall=923
2020-10-13 10:43:05 | INFO | train_inner | epoch 004:    598 / 634 loss=7.376, nll_loss=6.182, ppl=72.59, wps=43618.7, ups=2.79, wpb=15635, bsz=625.5, num_updates=2500, lr=0.000125037, gnorm=1.017, clip=0, train_wall=34, wall=958
2020-10-13 10:43:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 10:43:18 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13466.515625Mb; avail=231061.03125Mb
2020-10-13 10:43:18 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001889
2020-10-13 10:43:18 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13467.12109375Mb; avail=231060.91796875Mb
2020-10-13 10:43:18 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.130104
2020-10-13 10:43:18 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13464.7890625Mb; avail=231063.34765625Mb
2020-10-13 10:43:18 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.098018
2020-10-13 10:43:18 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.230925
2020-10-13 10:43:18 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13466.203125Mb; avail=231061.86328125Mb
2020-10-13 10:43:18 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13465.31640625Mb; avail=231063.66015625Mb
2020-10-13 10:43:18 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001700
2020-10-13 10:43:18 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13465.31640625Mb; avail=231063.66015625Mb
2020-10-13 10:43:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.128329
2020-10-13 10:43:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13465.3671875Mb; avail=231063.703125Mb
2020-10-13 10:43:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.098990
2020-10-13 10:43:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.229938
2020-10-13 10:43:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13476.77734375Mb; avail=231051.98046875Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:43:24 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.042 | nll_loss 5.735 | ppl 53.28 | wps 89768.4 | wpb 5051.4 | bsz 192.5 | num_updates 2536 | best_loss 7.042
2020-10-13 10:43:24 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:43:37 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/checkpoint_best.pt (epoch 4 @ 2536 updates, score 7.042) (writing took 12.63247324898839 seconds)
2020-10-13 10:43:37 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2020-10-13 10:43:37 | INFO | train | epoch 004 | loss 7.518 | nll_loss 6.343 | ppl 81.2 | wps 39249.2 | ups 2.49 | wpb 15785.1 | bsz 594.2 | num_updates 2536 | lr 0.000126837 | gnorm 1.038 | clip 0 | train_wall 220 | wall 990
2020-10-13 10:43:37 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=5/shard_epoch=4
2020-10-13 10:43:37 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=5/shard_epoch=5
2020-10-13 10:43:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13228.74609375Mb; avail=231299.83984375Mb
2020-10-13 10:43:37 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.006981
2020-10-13 10:43:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.078474
2020-10-13 10:43:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13231.78515625Mb; avail=231295.66796875Mb
2020-10-13 10:43:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.002789
2020-10-13 10:43:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13231.640625Mb; avail=231295.078125Mb
2020-10-13 10:43:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.512857
2020-10-13 10:43:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.595003
2020-10-13 10:43:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13244.78515625Mb; avail=231282.8671875Mb
2020-10-13 10:43:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13235.62890625Mb; avail=231292.296875Mb
2020-10-13 10:43:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.061613
2020-10-13 10:43:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13235.71875Mb; avail=231292.23828125Mb
2020-10-13 10:43:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.002806
2020-10-13 10:43:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13236.32421875Mb; avail=231292.6171875Mb
2020-10-13 10:43:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.535208
2020-10-13 10:43:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.600507
2020-10-13 10:43:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13241.2890625Mb; avail=231287.94140625Mb
2020-10-13 10:43:40 | INFO | fairseq.trainer | begin training epoch 5
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:44:06 | INFO | train_inner | epoch 005:     64 / 634 loss=7.342, nll_loss=6.143, ppl=70.65, wps=25704.1, ups=1.64, wpb=15659, bsz=568.6, num_updates=2600, lr=0.000130035, gnorm=0.969, clip=0, train_wall=34, wall=1019
2020-10-13 10:44:43 | INFO | train_inner | epoch 005:    164 / 634 loss=7.275, nll_loss=6.067, ppl=67.04, wps=42885.4, ups=2.76, wpb=15556.6, bsz=579.8, num_updates=2700, lr=0.000135032, gnorm=1.01, clip=0, train_wall=35, wall=1056
2020-10-13 10:45:19 | INFO | train_inner | epoch 005:    264 / 634 loss=7.227, nll_loss=6.011, ppl=64.51, wps=43460.6, ups=2.75, wpb=15801.5, bsz=612.5, num_updates=2800, lr=0.00014003, gnorm=0.96, clip=0, train_wall=35, wall=1092
2020-10-13 10:45:55 | INFO | train_inner | epoch 005:    364 / 634 loss=7.154, nll_loss=5.927, ppl=60.86, wps=44265, ups=2.79, wpb=15876.2, bsz=584.5, num_updates=2900, lr=0.000145028, gnorm=0.936, clip=0, train_wall=34, wall=1128
2020-10-13 10:46:31 | INFO | train_inner | epoch 005:    464 / 634 loss=7.089, nll_loss=5.854, ppl=57.84, wps=43265.2, ups=2.75, wpb=15715, bsz=610.3, num_updates=3000, lr=0.000150025, gnorm=1.006, clip=0, train_wall=35, wall=1164
2020-10-13 10:47:07 | INFO | train_inner | epoch 005:    564 / 634 loss=7.025, nll_loss=5.781, ppl=54.99, wps=44352.9, ups=2.78, wpb=15974.2, bsz=560.7, num_updates=3100, lr=0.000155023, gnorm=0.955, clip=0, train_wall=35, wall=1200
2020-10-13 10:47:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 10:47:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13493.83984375Mb; avail=231035.20703125Mb
2020-10-13 10:47:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001767
2020-10-13 10:47:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13493.83984375Mb; avail=231035.20703125Mb
2020-10-13 10:47:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.133679
2020-10-13 10:47:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13499.18359375Mb; avail=231029.86328125Mb
2020-10-13 10:47:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.097107
2020-10-13 10:47:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.233351
2020-10-13 10:47:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13496.875Mb; avail=231032.171875Mb
2020-10-13 10:47:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13499.20703125Mb; avail=231029.83984375Mb
2020-10-13 10:47:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001741
2020-10-13 10:47:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13499.8125Mb; avail=231029.234375Mb
2020-10-13 10:47:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.129516
2020-10-13 10:47:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13494.6875Mb; avail=231034.359375Mb
2020-10-13 10:47:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.097359
2020-10-13 10:47:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.229406
2020-10-13 10:47:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13494.6875Mb; avail=231034.359375Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:47:40 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 6.667 | nll_loss 5.312 | ppl 39.72 | wps 91285.2 | wpb 5051.4 | bsz 192.5 | num_updates 3170 | best_loss 6.667
2020-10-13 10:47:40 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:47:45 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/checkpoint_best.pt (epoch 5 @ 3170 updates, score 6.667) (writing took 5.882374690147117 seconds)
2020-10-13 10:47:46 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2020-10-13 10:47:46 | INFO | train | epoch 005 | loss 7.153 | nll_loss 5.927 | ppl 60.84 | wps 40268.5 | ups 2.55 | wpb 15785.1 | bsz 594.2 | num_updates 3170 | lr 0.000158521 | gnorm 0.975 | clip 0 | train_wall 220 | wall 1239
2020-10-13 10:47:46 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=6/shard_epoch=5
2020-10-13 10:47:46 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=6/shard_epoch=6
2020-10-13 10:47:46 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13172.953125Mb; avail=231356.55078125Mb
2020-10-13 10:47:46 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.006760
2020-10-13 10:47:46 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.080680
2020-10-13 10:47:46 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13170.8828125Mb; avail=231358.62109375Mb
2020-10-13 10:47:46 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.002836
2020-10-13 10:47:46 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13171.48828125Mb; avail=231358.015625Mb
2020-10-13 10:47:47 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.488940
2020-10-13 10:47:47 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.573384
2020-10-13 10:47:47 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13232.51171875Mb; avail=231296.5703125Mb
2020-10-13 10:47:47 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13231.9140625Mb; avail=231297.17578125Mb
2020-10-13 10:47:47 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.061616
2020-10-13 10:47:47 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13236.18359375Mb; avail=231292.9140625Mb
2020-10-13 10:47:47 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.002794
2020-10-13 10:47:47 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13236.7890625Mb; avail=231292.30859375Mb
2020-10-13 10:47:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.497870
2020-10-13 10:47:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.563130
2020-10-13 10:47:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13232.81640625Mb; avail=231296.26171875Mb
2020-10-13 10:47:49 | INFO | fairseq.trainer | begin training epoch 6
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:48:02 | INFO | train_inner | epoch 006:     30 / 634 loss=6.984, nll_loss=5.735, ppl=53.26, wps=29422.1, ups=1.85, wpb=15898.6, bsz=605.4, num_updates=3200, lr=0.00016002, gnorm=0.969, clip=0, train_wall=34, wall=1256
2020-10-13 10:48:39 | INFO | train_inner | epoch 006:    130 / 634 loss=6.886, nll_loss=5.624, ppl=49.3, wps=43778.7, ups=2.76, wpb=15835, bsz=599.6, num_updates=3300, lr=0.000165018, gnorm=0.936, clip=0, train_wall=35, wall=1292
2020-10-13 10:49:15 | INFO | train_inner | epoch 006:    230 / 634 loss=6.844, nll_loss=5.574, ppl=47.65, wps=43679.2, ups=2.76, wpb=15811, bsz=608.6, num_updates=3400, lr=0.000170015, gnorm=0.927, clip=0, train_wall=35, wall=1328
2020-10-13 10:49:51 | INFO | train_inner | epoch 006:    330 / 634 loss=6.794, nll_loss=5.516, ppl=45.77, wps=43631.8, ups=2.78, wpb=15717.1, bsz=567.2, num_updates=3500, lr=0.000175013, gnorm=0.894, clip=0, train_wall=35, wall=1364
2020-10-13 10:50:27 | INFO | train_inner | epoch 006:    430 / 634 loss=6.721, nll_loss=5.433, ppl=43.19, wps=43588.6, ups=2.78, wpb=15684.6, bsz=607.2, num_updates=3600, lr=0.00018001, gnorm=0.971, clip=0, train_wall=34, wall=1400
2020-10-13 10:51:03 | INFO | train_inner | epoch 006:    530 / 634 loss=6.619, nll_loss=5.317, ppl=39.86, wps=43281, ups=2.77, wpb=15630.4, bsz=620.9, num_updates=3700, lr=0.000185008, gnorm=0.913, clip=0, train_wall=35, wall=1436
2020-10-13 10:51:39 | INFO | train_inner | epoch 006:    630 / 634 loss=6.608, nll_loss=5.303, ppl=39.49, wps=44276.1, ups=2.78, wpb=15954.9, bsz=574.8, num_updates=3800, lr=0.000190005, gnorm=0.909, clip=0, train_wall=34, wall=1472
2020-10-13 10:51:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 10:51:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13854.3125Mb; avail=230675.16015625Mb
2020-10-13 10:51:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002014
2020-10-13 10:51:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13854.3125Mb; avail=230675.16015625Mb
2020-10-13 10:51:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.130720
2020-10-13 10:51:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13858.4140625Mb; avail=230671.0703125Mb
2020-10-13 10:51:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.098691
2020-10-13 10:51:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.232309
2020-10-13 10:51:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13871.515625Mb; avail=230657.96875Mb
2020-10-13 10:51:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13874.4296875Mb; avail=230655.0546875Mb
2020-10-13 10:51:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001736
2020-10-13 10:51:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13875.640625Mb; avail=230653.84375Mb
2020-10-13 10:51:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.132647
2020-10-13 10:51:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13893.8359375Mb; avail=230635.6484375Mb
2020-10-13 10:51:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.099516
2020-10-13 10:51:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.234868
2020-10-13 10:51:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13929.21875Mb; avail=230600.26171875Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:51:46 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 6.263 | nll_loss 4.818 | ppl 28.22 | wps 89129.4 | wpb 5051.4 | bsz 192.5 | num_updates 3804 | best_loss 6.263
2020-10-13 10:51:46 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:51:56 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/checkpoint_best.pt (epoch 6 @ 3804 updates, score 6.263) (writing took 9.263326308922842 seconds)
2020-10-13 10:51:56 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2020-10-13 10:51:56 | INFO | train | epoch 006 | loss 6.753 | nll_loss 5.47 | ppl 44.32 | wps 39989.6 | ups 2.53 | wpb 15785.1 | bsz 594.2 | num_updates 3804 | lr 0.000190205 | gnorm 0.926 | clip 0 | train_wall 219 | wall 1489
2020-10-13 10:51:56 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=7/shard_epoch=6
2020-10-13 10:51:56 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=7/shard_epoch=7
2020-10-13 10:51:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13015.8984375Mb; avail=231513.3515625Mb
2020-10-13 10:51:56 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.006125
2020-10-13 10:51:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.080399
2020-10-13 10:51:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13017.8203125Mb; avail=231511.4296875Mb
2020-10-13 10:51:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.002782
2020-10-13 10:51:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13017.8203125Mb; avail=231511.4296875Mb
2020-10-13 10:51:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.490591
2020-10-13 10:51:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.574615
2020-10-13 10:51:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13103.1875Mb; avail=231426.2734375Mb
2020-10-13 10:51:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13107.66796875Mb; avail=231421.79296875Mb
2020-10-13 10:51:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.061611
2020-10-13 10:51:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13117.35546875Mb; avail=231412.10546875Mb
2020-10-13 10:51:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.002811
2020-10-13 10:51:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13117.9609375Mb; avail=231411.5Mb
2020-10-13 10:51:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.496900
2020-10-13 10:51:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.562214
2020-10-13 10:51:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13219.34375Mb; avail=231310.1171875Mb
2020-10-13 10:51:59 | INFO | fairseq.trainer | begin training epoch 7
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:52:37 | INFO | train_inner | epoch 007:     96 / 634 loss=6.46, nll_loss=5.136, ppl=35.16, wps=27546.9, ups=1.73, wpb=15880.3, bsz=613.7, num_updates=3900, lr=0.000195003, gnorm=0.931, clip=0, train_wall=34, wall=1530
2020-10-13 10:53:13 | INFO | train_inner | epoch 007:    196 / 634 loss=6.448, nll_loss=5.121, ppl=34.8, wps=44058.3, ups=2.76, wpb=15934.4, bsz=577.2, num_updates=4000, lr=0.0002, gnorm=0.942, clip=0, train_wall=35, wall=1566
2020-10-13 10:53:49 | INFO | train_inner | epoch 007:    296 / 634 loss=6.365, nll_loss=5.025, ppl=32.56, wps=44166.5, ups=2.78, wpb=15889, bsz=604.7, num_updates=4100, lr=0.000197546, gnorm=0.908, clip=0, train_wall=34, wall=1602
2020-10-13 10:54:24 | INFO | train_inner | epoch 007:    396 / 634 loss=6.315, nll_loss=4.968, ppl=31.3, wps=43733.4, ups=2.8, wpb=15637.2, bsz=581.6, num_updates=4200, lr=0.00019518, gnorm=0.883, clip=0, train_wall=34, wall=1638
2020-10-13 10:55:01 | INFO | train_inner | epoch 007:    496 / 634 loss=6.236, nll_loss=4.878, ppl=29.41, wps=43373.2, ups=2.77, wpb=15640.9, bsz=589.4, num_updates=4300, lr=0.000192897, gnorm=0.889, clip=0, train_wall=34, wall=1674
2020-10-13 10:55:37 | INFO | train_inner | epoch 007:    596 / 634 loss=6.171, nll_loss=4.803, ppl=27.92, wps=43724.6, ups=2.76, wpb=15839.2, bsz=614.1, num_updates=4400, lr=0.000190693, gnorm=0.901, clip=0, train_wall=35, wall=1710
2020-10-13 10:55:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 10:55:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13505.13671875Mb; avail=231024.12890625Mb
2020-10-13 10:55:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001964
2020-10-13 10:55:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13505.13671875Mb; avail=231024.12890625Mb
2020-10-13 10:55:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.133285
2020-10-13 10:55:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13504.796875Mb; avail=231024.734375Mb
2020-10-13 10:55:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.099018
2020-10-13 10:55:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.235066
2020-10-13 10:55:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13504.58203125Mb; avail=231024.39453125Mb
2020-10-13 10:55:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13507.00390625Mb; avail=231021.97265625Mb
2020-10-13 10:55:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001696
2020-10-13 10:55:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13507.00390625Mb; avail=231021.97265625Mb
2020-10-13 10:55:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.129219
2020-10-13 10:55:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13515.25Mb; avail=231013.7265625Mb
2020-10-13 10:55:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.099491
2020-10-13 10:55:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.231216
2020-10-13 10:55:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13513.13671875Mb; avail=231015.83984375Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:55:56 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 5.897 | nll_loss 4.405 | ppl 21.18 | wps 91475.3 | wpb 5051.4 | bsz 192.5 | num_updates 4438 | best_loss 5.897
2020-10-13 10:55:56 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:56:02 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/checkpoint_best.pt (epoch 7 @ 4438 updates, score 5.897) (writing took 5.893781752092764 seconds)
2020-10-13 10:56:02 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2020-10-13 10:56:02 | INFO | train | epoch 007 | loss 6.322 | nll_loss 4.977 | ppl 31.49 | wps 40609.7 | ups 2.57 | wpb 15785.1 | bsz 594.2 | num_updates 4438 | lr 0.000189874 | gnorm 0.903 | clip 0 | train_wall 219 | wall 1735
2020-10-13 10:56:02 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=8/shard_epoch=7
2020-10-13 10:56:02 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=8/shard_epoch=8
2020-10-13 10:56:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13190.5390625Mb; avail=231341.046875Mb
2020-10-13 10:56:02 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.006164
2020-10-13 10:56:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.081685
2020-10-13 10:56:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13188.04296875Mb; avail=231341.4375Mb
2020-10-13 10:56:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.002819
2020-10-13 10:56:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13188.04296875Mb; avail=231341.4375Mb
2020-10-13 10:56:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.485193
2020-10-13 10:56:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.570620
2020-10-13 10:56:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13252.484375Mb; avail=231276.66796875Mb
2020-10-13 10:56:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13251.9921875Mb; avail=231277.16015625Mb
2020-10-13 10:56:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.061376
2020-10-13 10:56:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13251.9765625Mb; avail=231277.17578125Mb
2020-10-13 10:56:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.002795
2020-10-13 10:56:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13251.9765625Mb; avail=231277.17578125Mb
2020-10-13 10:56:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.481634
2020-10-13 10:56:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.546652
2020-10-13 10:56:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13250.7109375Mb; avail=231278.40234375Mb
2020-10-13 10:56:06 | INFO | fairseq.trainer | begin training epoch 8
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:56:30 | INFO | train_inner | epoch 008:     62 / 634 loss=6.116, nll_loss=4.741, ppl=26.74, wps=29093.1, ups=1.86, wpb=15608.2, bsz=560.4, num_updates=4500, lr=0.000188562, gnorm=0.847, clip=0, train_wall=34, wall=1764
2020-10-13 10:57:07 | INFO | train_inner | epoch 008:    162 / 634 loss=5.972, nll_loss=4.578, ppl=23.88, wps=43781.6, ups=2.76, wpb=15882.5, bsz=642.2, num_updates=4600, lr=0.000186501, gnorm=0.903, clip=0, train_wall=35, wall=1800
2020-10-13 10:57:43 | INFO | train_inner | epoch 008:    262 / 634 loss=6.002, nll_loss=4.61, ppl=24.41, wps=44170.7, ups=2.78, wpb=15899.4, bsz=592.2, num_updates=4700, lr=0.000184506, gnorm=0.864, clip=0, train_wall=35, wall=1836
2020-10-13 10:58:19 | INFO | train_inner | epoch 008:    362 / 634 loss=5.952, nll_loss=4.553, ppl=23.47, wps=43822.9, ups=2.78, wpb=15764.4, bsz=569.2, num_updates=4800, lr=0.000182574, gnorm=0.856, clip=0, train_wall=34, wall=1872
2020-10-13 10:58:57 | INFO | train_inner | epoch 008:    462 / 634 loss=5.892, nll_loss=4.485, ppl=22.39, wps=41062.4, ups=2.62, wpb=15681.7, bsz=586.9, num_updates=4900, lr=0.000180702, gnorm=0.856, clip=0, train_wall=36, wall=1910
2020-10-13 10:59:33 | INFO | train_inner | epoch 008:    562 / 634 loss=5.871, nll_loss=4.459, ppl=22, wps=43460.2, ups=2.78, wpb=15637.6, bsz=595.2, num_updates=5000, lr=0.000178885, gnorm=0.863, clip=0, train_wall=34, wall=1946
2020-10-13 10:59:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 10:59:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13510.5546875Mb; avail=231017.99609375Mb
2020-10-13 10:59:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001949
2020-10-13 10:59:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13510.5546875Mb; avail=231017.99609375Mb
2020-10-13 10:59:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.132132
2020-10-13 10:59:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13510.5546875Mb; avail=231017.99609375Mb
2020-10-13 10:59:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.098269
2020-10-13 10:59:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.233136
2020-10-13 10:59:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13510.5546875Mb; avail=231017.99609375Mb
2020-10-13 10:59:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13510.5546875Mb; avail=231017.99609375Mb
2020-10-13 10:59:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001748
2020-10-13 10:59:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13510.5546875Mb; avail=231017.99609375Mb
2020-10-13 10:59:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.129665
2020-10-13 10:59:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13515.2890625Mb; avail=231013.6953125Mb
2020-10-13 10:59:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.098914
2020-10-13 10:59:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.231142
2020-10-13 10:59:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13516.34375Mb; avail=231012.5390625Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:00:05 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 5.586 | nll_loss 4.034 | ppl 16.38 | wps 90950 | wpb 5051.4 | bsz 192.5 | num_updates 5072 | best_loss 5.586
2020-10-13 11:00:05 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:00:11 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/checkpoint_best.pt (epoch 8 @ 5072 updates, score 5.586) (writing took 5.888316484866664 seconds)
2020-10-13 11:00:11 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2020-10-13 11:00:11 | INFO | train | epoch 008 | loss 5.933 | nll_loss 4.532 | ppl 23.13 | wps 40265.7 | ups 2.55 | wpb 15785.1 | bsz 594.2 | num_updates 5072 | lr 0.000177611 | gnorm 0.861 | clip 0 | train_wall 220 | wall 1984
2020-10-13 11:00:11 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=9/shard_epoch=8
2020-10-13 11:00:11 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=9/shard_epoch=9
2020-10-13 11:00:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13181.84765625Mb; avail=231347.33203125Mb
2020-10-13 11:00:11 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.006008
2020-10-13 11:00:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.080858
2020-10-13 11:00:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13187.64453125Mb; avail=231341.53515625Mb
2020-10-13 11:00:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.002824
2020-10-13 11:00:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13187.64453125Mb; avail=231341.53515625Mb
2020-10-13 11:00:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.498343
2020-10-13 11:00:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.582953
2020-10-13 11:00:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13262.65234375Mb; avail=231266.34375Mb
2020-10-13 11:00:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13256.74609375Mb; avail=231272.25Mb
2020-10-13 11:00:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.061566
2020-10-13 11:00:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13256.74609375Mb; avail=231272.25Mb
2020-10-13 11:00:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.002762
2020-10-13 11:00:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13256.74609375Mb; avail=231272.25Mb
2020-10-13 11:00:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.517111
2020-10-13 11:00:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.582311
2020-10-13 11:00:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13256.71484375Mb; avail=231272.33203125Mb
2020-10-13 11:00:14 | INFO | fairseq.trainer | begin training epoch 9
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:00:27 | INFO | train_inner | epoch 009:     28 / 634 loss=5.754, nll_loss=4.327, ppl=20.07, wps=29572, ups=1.85, wpb=15979.8, bsz=598.4, num_updates=5100, lr=0.000177123, gnorm=0.795, clip=0, train_wall=34, wall=2000
2020-10-13 11:01:03 | INFO | train_inner | epoch 009:    128 / 634 loss=5.7, nll_loss=4.266, ppl=19.23, wps=43583.4, ups=2.76, wpb=15815.5, bsz=605, num_updates=5200, lr=0.000175412, gnorm=0.857, clip=0, train_wall=35, wall=2036
2020-10-13 11:01:39 | INFO | train_inner | epoch 009:    228 / 634 loss=5.684, nll_loss=4.245, ppl=18.96, wps=44293.3, ups=2.77, wpb=16015.2, bsz=590.8, num_updates=5300, lr=0.000173749, gnorm=0.808, clip=0, train_wall=35, wall=2072
2020-10-13 11:02:16 | INFO | train_inner | epoch 009:    328 / 634 loss=5.614, nll_loss=4.167, ppl=17.96, wps=43728.6, ups=2.76, wpb=15836.7, bsz=612, num_updates=5400, lr=0.000172133, gnorm=0.876, clip=0, train_wall=35, wall=2109
2020-10-13 11:02:55 | INFO | train_inner | epoch 009:    428 / 634 loss=5.597, nll_loss=4.147, ppl=17.71, wps=40232.9, ups=2.55, wpb=15774.5, bsz=564.6, num_updates=5500, lr=0.000170561, gnorm=0.78, clip=0, train_wall=37, wall=2148
2020-10-13 11:03:36 | INFO | train_inner | epoch 009:    528 / 634 loss=5.613, nll_loss=4.164, ppl=17.92, wps=37881.5, ups=2.42, wpb=15662.5, bsz=578.8, num_updates=5600, lr=0.000169031, gnorm=0.876, clip=0, train_wall=39, wall=2189
2020-10-13 11:04:17 | INFO | train_inner | epoch 009:    628 / 634 loss=5.515, nll_loss=4.053, ppl=16.6, wps=38183.6, ups=2.45, wpb=15582.9, bsz=611.8, num_updates=5700, lr=0.000167542, gnorm=0.8, clip=0, train_wall=38, wall=2230
2020-10-13 11:04:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 11:04:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=21461.2109375Mb; avail=223066.859375Mb
2020-10-13 11:04:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002901
2020-10-13 11:04:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21461.2109375Mb; avail=223066.859375Mb
2020-10-13 11:04:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.294322
2020-10-13 11:04:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21640.03125Mb; avail=222888.0390625Mb
2020-10-13 11:04:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.202897
2020-10-13 11:04:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.501849
2020-10-13 11:04:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21682.6015625Mb; avail=222844.734375Mb
2020-10-13 11:04:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=21692.91015625Mb; avail=222833.734375Mb
2020-10-13 11:04:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003010
2020-10-13 11:04:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21704.8984375Mb; avail=222823.5625Mb
2020-10-13 11:04:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.282210
2020-10-13 11:04:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21777.65625Mb; avail=222750.80859375Mb
2020-10-13 11:04:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.174819
2020-10-13 11:04:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.461600
2020-10-13 11:04:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21870.94140625Mb; avail=222657.5234375Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:04:28 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 5.367 | nll_loss 3.777 | ppl 13.71 | wps 75651.3 | wpb 5051.4 | bsz 192.5 | num_updates 5706 | best_loss 5.367
2020-10-13 11:04:28 | INFO | fairseq_cli.train | begin save checkpoint
2020-10-13 11:04:35 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/checkpoint_best.pt (epoch 9 @ 5706 updates, score 5.367) (writing took 6.708514082944021 seconds)
2020-10-13 11:04:35 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2020-10-13 11:04:35 | INFO | train | epoch 009 | loss 5.623 | nll_loss 4.176 | ppl 18.08 | wps 37833.3 | ups 2.4 | wpb 15785.1 | bsz 594.2 | num_updates 5706 | lr 0.000167453 | gnorm 0.829 | clip 0 | train_wall 230 | wall 2249
2020-10-13 11:04:35 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=10/shard_epoch=9
2020-10-13 11:04:35 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=10/shard_epoch=10
2020-10-13 11:04:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=24463.2421875Mb; avail=220065.42578125Mb
2020-10-13 11:04:36 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.011698
2020-10-13 11:04:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.137583
2020-10-13 11:04:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23283.35546875Mb; avail=221252.203125Mb
2020-10-13 11:04:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.005374
2020-10-13 11:04:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23149.1015625Mb; avail=221384.48828125Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:04:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.849965
2020-10-13 11:04:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.994284
2020-10-13 11:04:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21849.265625Mb; avail=222679.640625Mb
2020-10-13 11:04:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=21840.6328125Mb; avail=222688.2734375Mb
2020-10-13 11:04:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.067574
2020-10-13 11:04:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21894.2265625Mb; avail=222634.6796875Mb
2020-10-13 11:04:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.003950
2020-10-13 11:04:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21895.4375Mb; avail=222633.46875Mb
2020-10-13 11:04:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.550791
2020-10-13 11:04:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.623345
2020-10-13 11:04:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22422.69921875Mb; avail=222105.3125Mb
2020-10-13 11:04:40 | INFO | fairseq.trainer | begin training epoch 10
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:05:22 | INFO | train_inner | epoch 010:     94 / 634 loss=5.481, nll_loss=4.014, ppl=16.16, wps=23971.7, ups=1.53, wpb=15696.2, bsz=559.1, num_updates=5800, lr=0.000166091, gnorm=0.809, clip=0, train_wall=39, wall=2295
2020-10-13 11:06:04 | INFO | train_inner | epoch 010:    194 / 634 loss=5.398, nll_loss=3.92, ppl=15.14, wps=38320, ups=2.41, wpb=15901.5, bsz=600.3, num_updates=5900, lr=0.000164677, gnorm=0.808, clip=0, train_wall=39, wall=2337
2020-10-13 11:06:45 | INFO | train_inner | epoch 010:    294 / 634 loss=5.356, nll_loss=3.871, ppl=14.64, wps=38543.3, ups=2.43, wpb=15851.4, bsz=629.8, num_updates=6000, lr=0.000163299, gnorm=0.777, clip=0, train_wall=39, wall=2378
2020-10-13 11:07:27 | INFO | train_inner | epoch 010:    394 / 634 loss=5.376, nll_loss=3.894, ppl=14.87, wps=38295.6, ups=2.41, wpb=15906.2, bsz=611.5, num_updates=6100, lr=0.000161955, gnorm=0.817, clip=0, train_wall=39, wall=2420
2020-10-13 11:08:07 | INFO | train_inner | epoch 010:    494 / 634 loss=5.358, nll_loss=3.873, ppl=14.65, wps=38726.8, ups=2.44, wpb=15839.2, bsz=574.5, num_updates=6200, lr=0.000160644, gnorm=0.773, clip=0, train_wall=39, wall=2461
2020-10-13 11:08:49 | INFO | train_inner | epoch 010:    594 / 634 loss=5.337, nll_loss=3.849, ppl=14.41, wps=37861.5, ups=2.43, wpb=15559.4, bsz=579.7, num_updates=6300, lr=0.000159364, gnorm=0.796, clip=0, train_wall=39, wall=2502
2020-10-13 11:09:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 11:09:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=23373.765625Mb; avail=221154.23046875Mb
2020-10-13 11:09:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002961
2020-10-13 11:09:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23373.765625Mb; avail=221154.23046875Mb
2020-10-13 11:09:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.276500
2020-10-13 11:09:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23398.18359375Mb; avail=221129.91015625Mb
2020-10-13 11:09:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.130490
2020-10-13 11:09:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.411342
2020-10-13 11:09:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23378.8359375Mb; avail=221149.29296875Mb
2020-10-13 11:09:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=23380.41015625Mb; avail=221148.03515625Mb
2020-10-13 11:09:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002159
2020-10-13 11:09:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23380.41015625Mb; avail=221148.03515625Mb
2020-10-13 11:09:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.136273
2020-10-13 11:09:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23380.41015625Mb; avail=221148.03515625Mb
2020-10-13 11:09:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.099870
2020-10-13 11:09:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.239479
2020-10-13 11:09:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23385.76953125Mb; avail=221142.67578125Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:09:13 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 5.196 | nll_loss 3.572 | ppl 11.89 | wps 78747.9 | wpb 5051.4 | bsz 192.5 | num_updates 6340 | best_loss 5.196
2020-10-13 11:09:13 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:09:20 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/checkpoint_best.pt (epoch 10 @ 6340 updates, score 5.196) (writing took 6.826819888083264 seconds)
2020-10-13 11:09:21 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2020-10-13 11:09:21 | INFO | train | epoch 010 | loss 5.378 | nll_loss 3.896 | ppl 14.89 | wps 35091.3 | ups 2.22 | wpb 15785.1 | bsz 594.2 | num_updates 6340 | lr 0.00015886 | gnorm 0.795 | clip 0 | train_wall 246 | wall 2534
2020-10-13 11:09:21 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=11/shard_epoch=10
2020-10-13 11:09:21 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=11/shard_epoch=11
2020-10-13 11:09:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=22609.45703125Mb; avail=221919.15625Mb
2020-10-13 11:09:21 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.007083
2020-10-13 11:09:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.090496
2020-10-13 11:09:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22614.24609375Mb; avail=221914.3671875Mb
2020-10-13 11:09:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.003897
2020-10-13 11:09:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22614.24609375Mb; avail=221914.3671875Mb
2020-10-13 11:09:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.861753
2020-10-13 11:09:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.957361
2020-10-13 11:09:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21153.9375Mb; avail=223374.53515625Mb
2020-10-13 11:09:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=21153.4453125Mb; avail=223375.02734375Mb
2020-10-13 11:09:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.109544
2020-10-13 11:09:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21153.4453125Mb; avail=223375.02734375Mb
2020-10-13 11:09:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.006862
2020-10-13 11:09:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21153.4453125Mb; avail=223375.02734375Mb
2020-10-13 11:09:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.179873
2020-10-13 11:09:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.298280
2020-10-13 11:09:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21789.50390625Mb; avail=222738.96484375Mb
2020-10-13 11:09:26 | INFO | fairseq.trainer | begin training epoch 11
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:09:55 | INFO | train_inner | epoch 011:     60 / 634 loss=5.25, nll_loss=3.751, ppl=13.46, wps=23735.9, ups=1.5, wpb=15784.6, bsz=605.3, num_updates=6400, lr=0.000158114, gnorm=0.788, clip=0, train_wall=39, wall=2568
2020-10-13 11:10:36 | INFO | train_inner | epoch 011:    160 / 634 loss=5.2, nll_loss=3.693, ppl=12.94, wps=38592, ups=2.45, wpb=15745.7, bsz=610.4, num_updates=6500, lr=0.000156893, gnorm=0.797, clip=0, train_wall=38, wall=2609
2020-10-13 11:11:17 | INFO | train_inner | epoch 011:    260 / 634 loss=5.181, nll_loss=3.672, ppl=12.75, wps=38479.4, ups=2.44, wpb=15777.3, bsz=582.5, num_updates=6600, lr=0.0001557, gnorm=0.762, clip=0, train_wall=39, wall=2650
2020-10-13 11:11:58 | INFO | train_inner | epoch 011:    360 / 634 loss=5.242, nll_loss=3.74, ppl=13.36, wps=38281.5, ups=2.44, wpb=15657.8, bsz=553.1, num_updates=6700, lr=0.000154533, gnorm=0.81, clip=0, train_wall=39, wall=2691
2020-10-13 11:12:39 | INFO | train_inner | epoch 011:    460 / 634 loss=5.165, nll_loss=3.653, ppl=12.58, wps=38619.6, ups=2.41, wpb=16037.9, bsz=620.7, num_updates=6800, lr=0.000153393, gnorm=0.79, clip=0, train_wall=39, wall=2732
2020-10-13 11:13:20 | INFO | train_inner | epoch 011:    560 / 634 loss=5.152, nll_loss=3.639, ppl=12.45, wps=37976.4, ups=2.43, wpb=15618.8, bsz=605.8, num_updates=6900, lr=0.000152277, gnorm=0.765, clip=0, train_wall=39, wall=2774
2020-10-13 11:13:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 11:13:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=23011.1328125Mb; avail=221517.12109375Mb
2020-10-13 11:13:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002725
2020-10-13 11:13:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23010.89453125Mb; avail=221516.625Mb
2020-10-13 11:13:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.147761
2020-10-13 11:13:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23000.55859375Mb; avail=221526.9609375Mb
2020-10-13 11:13:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.100121
2020-10-13 11:13:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.251910
2020-10-13 11:13:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23000.55859375Mb; avail=221526.9609375Mb
2020-10-13 11:13:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=23004.83984375Mb; avail=221523.921875Mb
2020-10-13 11:13:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001936
2020-10-13 11:13:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23004.83984375Mb; avail=221523.921875Mb
2020-10-13 11:13:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.126008
2020-10-13 11:13:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23005.640625Mb; avail=221522.80859375Mb
2020-10-13 11:13:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.127090
2020-10-13 11:13:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.256094
2020-10-13 11:13:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23006.73046875Mb; avail=221521.71875Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:13:59 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 5.091 | nll_loss 3.459 | ppl 10.99 | wps 61586.5 | wpb 5051.4 | bsz 192.5 | num_updates 6974 | best_loss 5.091
2020-10-13 11:13:59 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:14:06 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/checkpoint_best.pt (epoch 11 @ 6974 updates, score 5.091) (writing took 6.323275836883113 seconds)
2020-10-13 11:14:06 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2020-10-13 11:14:06 | INFO | train | epoch 011 | loss 5.186 | nll_loss 3.677 | ppl 12.79 | wps 35058.9 | ups 2.22 | wpb 15785.1 | bsz 594.2 | num_updates 6974 | lr 0.000151467 | gnorm 0.784 | clip 0 | train_wall 246 | wall 2819
2020-10-13 11:14:06 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=12/shard_epoch=11
2020-10-13 11:14:06 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=12/shard_epoch=12
2020-10-13 11:14:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=22700.0546875Mb; avail=221826.65625Mb
2020-10-13 11:14:06 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.007944
2020-10-13 11:14:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.100881
2020-10-13 11:14:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22728.3125Mb; avail=221799.5625Mb
2020-10-13 11:14:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.004692
2020-10-13 11:14:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22728.3125Mb; avail=221799.5625Mb
2020-10-13 11:14:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.186893
2020-10-13 11:14:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.293775
2020-10-13 11:14:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22893.6171875Mb; avail=221635.28515625Mb
2020-10-13 11:14:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=22883.7734375Mb; avail=221645.12890625Mb
2020-10-13 11:14:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.097842
2020-10-13 11:14:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22885.58984375Mb; avail=221643.3125Mb
2020-10-13 11:14:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.006497
2020-10-13 11:14:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22886.1953125Mb; avail=221642.70703125Mb
2020-10-13 11:14:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.205685
2020-10-13 11:14:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.311581
2020-10-13 11:14:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21127.58984375Mb; avail=223400.890625Mb
2020-10-13 11:14:11 | INFO | fairseq.trainer | begin training epoch 12
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:14:26 | INFO | train_inner | epoch 012:     26 / 634 loss=5.112, nll_loss=3.594, ppl=12.07, wps=24171.5, ups=1.53, wpb=15823.6, bsz=603.8, num_updates=7000, lr=0.000151186, gnorm=0.765, clip=0, train_wall=39, wall=2839
2020-10-13 11:15:07 | INFO | train_inner | epoch 012:    126 / 634 loss=5.041, nll_loss=3.513, ppl=11.41, wps=38247.4, ups=2.42, wpb=15836.2, bsz=610.2, num_updates=7100, lr=0.000150117, gnorm=0.787, clip=0, train_wall=39, wall=2880
2020-10-13 11:15:49 | INFO | train_inner | epoch 012:    226 / 634 loss=5.074, nll_loss=3.55, ppl=11.71, wps=38323, ups=2.42, wpb=15829.3, bsz=577.7, num_updates=7200, lr=0.000149071, gnorm=0.793, clip=0, train_wall=39, wall=2922
2020-10-13 11:16:30 | INFO | train_inner | epoch 012:    326 / 634 loss=5.056, nll_loss=3.528, ppl=11.54, wps=38436.8, ups=2.44, wpb=15774.1, bsz=559.4, num_updates=7300, lr=0.000148047, gnorm=0.769, clip=0, train_wall=39, wall=2963
2020-10-13 11:17:11 | INFO | train_inner | epoch 012:    426 / 634 loss=5.02, nll_loss=3.488, ppl=11.22, wps=38087.7, ups=2.42, wpb=15724.3, bsz=612.7, num_updates=7400, lr=0.000147043, gnorm=0.761, clip=0, train_wall=39, wall=3004
2020-10-13 11:17:52 | INFO | train_inner | epoch 012:    526 / 634 loss=4.99, nll_loss=3.455, ppl=10.96, wps=38133.5, ups=2.42, wpb=15757.9, bsz=613.4, num_updates=7500, lr=0.000146059, gnorm=0.758, clip=0, train_wall=39, wall=3045
2020-10-13 11:18:34 | INFO | train_inner | epoch 012:    626 / 634 loss=5.019, nll_loss=3.487, ppl=11.21, wps=38233.9, ups=2.42, wpb=15795.1, bsz=581.8, num_updates=7600, lr=0.000145095, gnorm=0.734, clip=0, train_wall=39, wall=3087
2020-10-13 11:18:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 11:18:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=22281.05859375Mb; avail=222247.34375Mb
2020-10-13 11:18:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003059
2020-10-13 11:18:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22281.05859375Mb; avail=222247.34375Mb
2020-10-13 11:18:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.291055
2020-10-13 11:18:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22275.71484375Mb; avail=222252.6875Mb
2020-10-13 11:18:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.219724
2020-10-13 11:18:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.515667
2020-10-13 11:18:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22275.71484375Mb; avail=222252.6875Mb
2020-10-13 11:18:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=22275.08984375Mb; avail=222252.9296875Mb
2020-10-13 11:18:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003186
2020-10-13 11:18:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22275.08984375Mb; avail=222252.9296875Mb
2020-10-13 11:18:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.291132
2020-10-13 11:18:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21628.8671875Mb; avail=222899.71875Mb
2020-10-13 11:18:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.206302
2020-10-13 11:18:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.502371
2020-10-13 11:18:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21390.28515625Mb; avail=223138.30078125Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:18:45 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 4.984 | nll_loss 3.342 | ppl 10.14 | wps 74751.6 | wpb 5051.4 | bsz 192.5 | num_updates 7608 | best_loss 4.984
2020-10-13 11:18:45 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:18:52 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/checkpoint_best.pt (epoch 12 @ 7608 updates, score 4.984) (writing took 6.675422525964677 seconds)
2020-10-13 11:18:52 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2020-10-13 11:18:52 | INFO | train | epoch 012 | loss 5.033 | nll_loss 3.503 | ppl 11.34 | wps 34979.4 | ups 2.22 | wpb 15785.1 | bsz 594.2 | num_updates 7608 | lr 0.000145019 | gnorm 0.769 | clip 0 | train_wall 247 | wall 3105
2020-10-13 11:18:52 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=13/shard_epoch=12
2020-10-13 11:18:52 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=13/shard_epoch=13
2020-10-13 11:18:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=21046.01171875Mb; avail=223482.82421875Mb
2020-10-13 11:18:52 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.007913
2020-10-13 11:18:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.091616
2020-10-13 11:18:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21059.23828125Mb; avail=223468.35546875Mb
2020-10-13 11:18:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.004229
2020-10-13 11:18:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21059.84375Mb; avail=223468.35546875Mb
2020-10-13 11:18:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.667763
2020-10-13 11:18:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.764738
2020-10-13 11:18:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=19709.90234375Mb; avail=224819.1171875Mb
2020-10-13 11:18:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=19709.90234375Mb; avail=224819.1171875Mb
2020-10-13 11:18:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.067383
2020-10-13 11:18:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=19714.07421875Mb; avail=224814.9453125Mb
2020-10-13 11:18:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.004376
2020-10-13 11:18:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=19714.6796875Mb; avail=224814.33984375Mb
2020-10-13 11:18:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.804536
2020-10-13 11:18:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.877421
2020-10-13 11:18:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=20240.79296875Mb; avail=224287.83203125Mb
2020-10-13 11:18:57 | INFO | fairseq.trainer | begin training epoch 13
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:19:39 | INFO | train_inner | epoch 013:     92 / 634 loss=4.938, nll_loss=3.395, ppl=10.52, wps=23656.3, ups=1.52, wpb=15531.1, bsz=590.9, num_updates=7700, lr=0.00014415, gnorm=0.803, clip=0, train_wall=38, wall=3152
2020-10-13 11:20:20 | INFO | train_inner | epoch 013:    192 / 634 loss=4.945, nll_loss=3.403, ppl=10.58, wps=38530.2, ups=2.46, wpb=15673.5, bsz=572.2, num_updates=7800, lr=0.000143223, gnorm=0.737, clip=0, train_wall=38, wall=3193
2020-10-13 11:20:59 | INFO | train_inner | epoch 013:    292 / 634 loss=4.884, nll_loss=3.334, ppl=10.09, wps=40836.8, ups=2.56, wpb=15952.3, bsz=617.6, num_updates=7900, lr=0.000142314, gnorm=0.737, clip=0, train_wall=37, wall=3232
2020-10-13 11:21:39 | INFO | train_inner | epoch 013:    392 / 634 loss=4.896, nll_loss=3.348, ppl=10.18, wps=39211.3, ups=2.48, wpb=15812.2, bsz=593.8, num_updates=8000, lr=0.000141421, gnorm=0.752, clip=0, train_wall=38, wall=3272
2020-10-13 11:22:20 | INFO | train_inner | epoch 013:    492 / 634 loss=4.895, nll_loss=3.346, ppl=10.17, wps=38438.7, ups=2.43, wpb=15830, bsz=609.6, num_updates=8100, lr=0.000140546, gnorm=0.766, clip=0, train_wall=39, wall=3314
2020-10-13 11:23:01 | INFO | train_inner | epoch 013:    592 / 634 loss=4.917, nll_loss=3.371, ppl=10.35, wps=38605.1, ups=2.44, wpb=15837.6, bsz=555.4, num_updates=8200, lr=0.000139686, gnorm=0.731, clip=0, train_wall=39, wall=3355
2020-10-13 11:23:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 11:23:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28679.39453125Mb; avail=215848.9609375Mb
2020-10-13 11:23:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003248
2020-10-13 11:23:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28679.5Mb; avail=215848.99609375Mb
2020-10-13 11:23:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.288987
2020-10-13 11:23:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28713.06640625Mb; avail=215816.05859375Mb
2020-10-13 11:23:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.205947
2020-10-13 11:23:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.499875
2020-10-13 11:23:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28717.87890625Mb; avail=215810.7890625Mb
2020-10-13 11:23:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28722.37109375Mb; avail=215806.09765625Mb
2020-10-13 11:23:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002995
2020-10-13 11:23:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28722.37109375Mb; avail=215806.09765625Mb
2020-10-13 11:23:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.279164
2020-10-13 11:23:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28003.6953125Mb; avail=216524.89453125Mb
2020-10-13 11:23:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.245237
2020-10-13 11:23:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.529926
2020-10-13 11:23:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28035.890625Mb; avail=216492.4296875Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:23:28 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 4.883 | nll_loss 3.215 | ppl 9.28 | wps 75315.3 | wpb 5051.4 | bsz 192.5 | num_updates 8242 | best_loss 4.883
2020-10-13 11:23:28 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:23:34 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/checkpoint_best.pt (epoch 13 @ 8242 updates, score 4.883) (writing took 6.841522204922512 seconds)
2020-10-13 11:23:35 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2020-10-13 11:23:35 | INFO | train | epoch 013 | loss 4.905 | nll_loss 3.358 | ppl 10.25 | wps 35411.9 | ups 2.24 | wpb 15785.1 | bsz 594.2 | num_updates 8242 | lr 0.00013933 | gnorm 0.752 | clip 0 | train_wall 243 | wall 3388
2020-10-13 11:23:35 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=14/shard_epoch=13
2020-10-13 11:23:35 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=14/shard_epoch=14
2020-10-13 11:23:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28554.359375Mb; avail=215974.4296875Mb
2020-10-13 11:23:35 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.015351
2020-10-13 11:23:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.152671
2020-10-13 11:23:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28565.15234375Mb; avail=215963.63671875Mb
2020-10-13 11:23:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.004533
2020-10-13 11:23:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28565.7578125Mb; avail=215963.03125Mb
2020-10-13 11:23:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.068911
2020-10-13 11:23:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.227358
2020-10-13 11:23:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28672.515625Mb; avail=215855.8828125Mb
2020-10-13 11:23:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28674.4453125Mb; avail=215853.953125Mb
2020-10-13 11:23:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.077445
2020-10-13 11:23:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28678.578125Mb; avail=215849.8203125Mb
2020-10-13 11:23:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.005884
2020-10-13 11:23:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28678.578125Mb; avail=215849.8203125Mb
2020-10-13 11:23:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.720100
2020-10-13 11:23:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.804590
2020-10-13 11:23:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27441.9375Mb; avail=217086.3984375Mb
2020-10-13 11:23:39 | INFO | fairseq.trainer | begin training epoch 14
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:24:07 | INFO | train_inner | epoch 014:     58 / 634 loss=4.833, nll_loss=3.277, ppl=9.69, wps=24235.5, ups=1.53, wpb=15836.2, bsz=600.4, num_updates=8300, lr=0.000138842, gnorm=0.737, clip=0, train_wall=39, wall=3420
2020-10-13 11:24:48 | INFO | train_inner | epoch 014:    158 / 634 loss=4.806, nll_loss=3.246, ppl=9.49, wps=38442.1, ups=2.43, wpb=15818.4, bsz=600.8, num_updates=8400, lr=0.000138013, gnorm=0.766, clip=0, train_wall=39, wall=3461
2020-10-13 11:25:29 | INFO | train_inner | epoch 014:    258 / 634 loss=4.802, nll_loss=3.24, ppl=9.45, wps=38068.2, ups=2.41, wpb=15777.4, bsz=620.4, num_updates=8500, lr=0.000137199, gnorm=0.721, clip=0, train_wall=39, wall=3503
2020-10-13 11:26:10 | INFO | train_inner | epoch 014:    358 / 634 loss=4.804, nll_loss=3.242, ppl=9.46, wps=38556.8, ups=2.43, wpb=15836, bsz=604.6, num_updates=8600, lr=0.000136399, gnorm=0.734, clip=0, train_wall=39, wall=3544
2020-10-13 11:26:52 | INFO | train_inner | epoch 014:    458 / 634 loss=4.799, nll_loss=3.237, ppl=9.43, wps=38537, ups=2.43, wpb=15870.2, bsz=580.1, num_updates=8700, lr=0.000135613, gnorm=0.715, clip=0, train_wall=39, wall=3585
2020-10-13 11:27:33 | INFO | train_inner | epoch 014:    558 / 634 loss=4.788, nll_loss=3.225, ppl=9.35, wps=38108.2, ups=2.43, wpb=15670.3, bsz=577.4, num_updates=8800, lr=0.00013484, gnorm=0.739, clip=0, train_wall=39, wall=3626
2020-10-13 11:28:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 11:28:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27138.33203125Mb; avail=217389.796875Mb
2020-10-13 11:28:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002000
2020-10-13 11:28:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27138.33203125Mb; avail=217389.796875Mb
2020-10-13 11:28:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.144994
2020-10-13 11:28:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27299.54296875Mb; avail=217228.5859375Mb
2020-10-13 11:28:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.109675
2020-10-13 11:28:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.257798
2020-10-13 11:28:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27349.33984375Mb; avail=217179.20703125Mb
2020-10-13 11:28:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27352.24609375Mb; avail=217176.30078125Mb
2020-10-13 11:28:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002945
2020-10-13 11:28:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27352.24609375Mb; avail=217176.30078125Mb
2020-10-13 11:28:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.165900
2020-10-13 11:28:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27394.80078125Mb; avail=217133.25Mb
2020-10-13 11:28:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.105826
2020-10-13 11:28:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.275878
2020-10-13 11:28:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27439.54296875Mb; avail=217088.80859375Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:28:12 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 4.814 | nll_loss 3.142 | ppl 8.83 | wps 61272.2 | wpb 5051.4 | bsz 192.5 | num_updates 8876 | best_loss 4.814
2020-10-13 11:28:12 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:28:18 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/checkpoint_best.pt (epoch 14 @ 8876 updates, score 4.814) (writing took 6.218273212900385 seconds)
2020-10-13 11:28:19 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2020-10-13 11:28:19 | INFO | train | epoch 014 | loss 4.799 | nll_loss 3.237 | ppl 9.43 | wps 35202.4 | ups 2.23 | wpb 15785.1 | bsz 594.2 | num_updates 8876 | lr 0.000134261 | gnorm 0.736 | clip 0 | train_wall 246 | wall 3672
2020-10-13 11:28:19 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=15/shard_epoch=14
2020-10-13 11:28:19 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=15/shard_epoch=15
2020-10-13 11:28:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27660.3203125Mb; avail=216868.125Mb
2020-10-13 11:28:19 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.014791
2020-10-13 11:28:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.160803
2020-10-13 11:28:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27100.30859375Mb; avail=217427.94921875Mb
2020-10-13 11:28:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.003906
2020-10-13 11:28:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27100.83203125Mb; avail=217427.640625Mb
2020-10-13 11:28:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.577739
2020-10-13 11:28:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.743486
2020-10-13 11:28:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27210.78515625Mb; avail=217318.01171875Mb
2020-10-13 11:28:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27223.23046875Mb; avail=217306.05859375Mb
2020-10-13 11:28:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.092948
2020-10-13 11:28:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27253.15234375Mb; avail=217275.64453125Mb
2020-10-13 11:28:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.007774
2020-10-13 11:28:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27253.15234375Mb; avail=217274.43359375Mb
2020-10-13 11:28:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.107578
2020-10-13 11:28:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.210051
2020-10-13 11:28:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28558.21875Mb; avail=215969.38671875Mb
2020-10-13 11:28:24 | INFO | fairseq.trainer | begin training epoch 15
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:28:38 | INFO | train_inner | epoch 015:     24 / 634 loss=4.756, nll_loss=3.188, ppl=9.11, wps=24046.9, ups=1.53, wpb=15722.4, bsz=601.8, num_updates=8900, lr=0.00013408, gnorm=0.739, clip=0, train_wall=38, wall=3691
2020-10-13 11:29:19 | INFO | train_inner | epoch 015:    124 / 634 loss=4.723, nll_loss=3.152, ppl=8.89, wps=38032.1, ups=2.42, wpb=15695.7, bsz=586.2, num_updates=9000, lr=0.000133333, gnorm=0.752, clip=0, train_wall=39, wall=3733
2020-10-13 11:30:00 | INFO | train_inner | epoch 015:    224 / 634 loss=4.713, nll_loss=3.139, ppl=8.81, wps=38619.2, ups=2.45, wpb=15776.2, bsz=586.6, num_updates=9100, lr=0.000132599, gnorm=0.729, clip=0, train_wall=38, wall=3773
2020-10-13 11:30:41 | INFO | train_inner | epoch 015:    324 / 634 loss=4.703, nll_loss=3.129, ppl=8.75, wps=38642.7, ups=2.44, wpb=15822.9, bsz=595.8, num_updates=9200, lr=0.000131876, gnorm=0.741, clip=0, train_wall=39, wall=3814
2020-10-13 11:31:22 | INFO | train_inner | epoch 015:    424 / 634 loss=4.718, nll_loss=3.146, ppl=8.85, wps=38095, ups=2.44, wpb=15616.7, bsz=584.6, num_updates=9300, lr=0.000131165, gnorm=0.717, clip=0, train_wall=39, wall=3855
2020-10-13 11:32:04 | INFO | train_inner | epoch 015:    524 / 634 loss=4.69, nll_loss=3.114, ppl=8.66, wps=38380.9, ups=2.42, wpb=15869, bsz=607.8, num_updates=9400, lr=0.000130466, gnorm=0.749, clip=0, train_wall=39, wall=3897
2020-10-13 11:32:45 | INFO | train_inner | epoch 015:    624 / 634 loss=4.698, nll_loss=3.122, ppl=8.71, wps=38490.8, ups=2.42, wpb=15895.1, bsz=601.8, num_updates=9500, lr=0.000129777, gnorm=0.71, clip=0, train_wall=39, wall=3938
2020-10-13 11:32:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 11:32:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27166.21484375Mb; avail=217362.15234375Mb
2020-10-13 11:32:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002772
2020-10-13 11:32:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27166.21484375Mb; avail=217362.15234375Mb
2020-10-13 11:32:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.282344
2020-10-13 11:32:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27230.3203125Mb; avail=217297.42578125Mb
2020-10-13 11:32:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.202087
2020-10-13 11:32:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.488730
2020-10-13 11:32:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27318.11328125Mb; avail=217209.6328125Mb
2020-10-13 11:32:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27318.11328125Mb; avail=217209.6328125Mb
2020-10-13 11:32:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002873
2020-10-13 11:32:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27318.11328125Mb; avail=217209.6328125Mb
2020-10-13 11:32:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.283656
2020-10-13 11:32:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27408.78125Mb; avail=217118.359375Mb
2020-10-13 11:32:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.202373
2020-10-13 11:32:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.490458
2020-10-13 11:32:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27488.8828125Mb; avail=217039.421875Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:32:58 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 4.764 | nll_loss 3.081 | ppl 8.46 | wps 62254.3 | wpb 5051.4 | bsz 192.5 | num_updates 9510 | best_loss 4.764
2020-10-13 11:32:58 | INFO | fairseq_cli.train | begin save checkpoint
2020-10-13 11:33:04 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/checkpoint_best.pt (epoch 15 @ 9510 updates, score 4.764) (writing took 6.445467210840434 seconds)
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:33:05 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2020-10-13 11:33:05 | INFO | train | epoch 015 | loss 4.708 | nll_loss 3.134 | ppl 8.78 | wps 35054.9 | ups 2.22 | wpb 15785.1 | bsz 594.2 | num_updates 9510 | lr 0.000129709 | gnorm 0.732 | clip 0 | train_wall 246 | wall 3958
2020-10-13 11:33:05 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=16/shard_epoch=15
2020-10-13 11:33:05 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=16/shard_epoch=16
2020-10-13 11:33:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=26694.88671875Mb; avail=217833.59765625Mb
2020-10-13 11:33:05 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.008088
2020-10-13 11:33:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.143057
2020-10-13 11:33:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26702.703125Mb; avail=217825.78125Mb
2020-10-13 11:33:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.006523
2020-10-13 11:33:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26703.30859375Mb; avail=217825.17578125Mb
2020-10-13 11:33:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:03.084190
2020-10-13 11:33:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:03.235264
2020-10-13 11:33:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28135.6484375Mb; avail=216393.234375Mb
2020-10-13 11:33:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28247.671875Mb; avail=216283.17578125Mb
2020-10-13 11:33:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.109697
2020-10-13 11:33:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28252.42578125Mb; avail=216276.453125Mb
2020-10-13 11:33:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.009222
2020-10-13 11:33:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28253.03125Mb; avail=216275.84765625Mb
2020-10-13 11:33:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.808474
2020-10-13 11:33:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.929345
2020-10-13 11:33:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29038.17578125Mb; avail=215490.15234375Mb
2020-10-13 11:33:11 | INFO | fairseq.trainer | begin training epoch 16
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:33:52 | INFO | train_inner | epoch 016:     90 / 634 loss=4.637, nll_loss=3.054, ppl=8.31, wps=23529.6, ups=1.5, wpb=15723.2, bsz=591.4, num_updates=9600, lr=0.000129099, gnorm=0.716, clip=0, train_wall=39, wall=4005
2020-10-13 11:34:33 | INFO | train_inner | epoch 016:    190 / 634 loss=4.632, nll_loss=3.048, ppl=8.27, wps=37954.2, ups=2.41, wpb=15745.9, bsz=599.5, num_updates=9700, lr=0.000128432, gnorm=0.723, clip=0, train_wall=39, wall=4046
2020-10-13 11:35:14 | INFO | train_inner | epoch 016:    290 / 634 loss=4.636, nll_loss=3.053, ppl=8.3, wps=38676.4, ups=2.43, wpb=15922.7, bsz=592.1, num_updates=9800, lr=0.000127775, gnorm=0.706, clip=0, train_wall=39, wall=4087
2020-10-13 11:35:55 | INFO | train_inner | epoch 016:    390 / 634 loss=4.612, nll_loss=3.025, ppl=8.14, wps=38545.4, ups=2.43, wpb=15847.8, bsz=612.5, num_updates=9900, lr=0.000127128, gnorm=0.74, clip=0, train_wall=39, wall=4129
2020-10-13 11:36:37 | INFO | train_inner | epoch 016:    490 / 634 loss=4.614, nll_loss=3.027, ppl=8.15, wps=38514, ups=2.43, wpb=15840.1, bsz=602.5, num_updates=10000, lr=0.000126491, gnorm=0.719, clip=0, train_wall=39, wall=4170
2020-10-13 11:37:18 | INFO | train_inner | epoch 016:    590 / 634 loss=4.639, nll_loss=3.055, ppl=8.31, wps=38381.9, ups=2.43, wpb=15783, bsz=575.7, num_updates=10100, lr=0.000125863, gnorm=0.73, clip=0, train_wall=39, wall=4211
2020-10-13 11:37:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 11:37:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=19966.55859375Mb; avail=224561.47265625Mb
2020-10-13 11:37:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003097
2020-10-13 11:37:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=19966.55859375Mb; avail=224561.47265625Mb
2020-10-13 11:37:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.238535
2020-10-13 11:37:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=19967.30078125Mb; avail=224560.73046875Mb
2020-10-13 11:37:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.099541
2020-10-13 11:37:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.342544
2020-10-13 11:37:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=19967.44140625Mb; avail=224561.0078125Mb
2020-10-13 11:37:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=19967.44140625Mb; avail=224561.0078125Mb
2020-10-13 11:37:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001946
2020-10-13 11:37:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=19967.44140625Mb; avail=224561.0078125Mb
2020-10-13 11:37:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.280301
2020-10-13 11:37:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=19968.3203125Mb; avail=224559.2890625Mb
2020-10-13 11:37:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.213422
2020-10-13 11:37:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.497087
2020-10-13 11:37:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=19972.87890625Mb; avail=224555.5703125Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:37:44 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 4.726 | nll_loss 3.052 | ppl 8.29 | wps 74212.7 | wpb 5051.4 | bsz 192.5 | num_updates 10144 | best_loss 4.726
2020-10-13 11:37:44 | INFO | fairseq_cli.train | begin save checkpoint
2020-10-13 11:37:51 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/checkpoint_best.pt (epoch 16 @ 10144 updates, score 4.726) (writing took 6.501058209920302 seconds)
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:37:51 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2020-10-13 11:37:51 | INFO | train | epoch 016 | loss 4.63 | nll_loss 3.046 | ppl 8.26 | wps 34907.2 | ups 2.21 | wpb 15785.1 | bsz 594.2 | num_updates 10144 | lr 0.00012559 | gnorm 0.726 | clip 0 | train_wall 246 | wall 4244
2020-10-13 11:37:51 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=17/shard_epoch=16
2020-10-13 11:37:51 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=17/shard_epoch=17
2020-10-13 11:37:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=20114.0859375Mb; avail=224414.6171875Mb
2020-10-13 11:37:51 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.007810
2020-10-13 11:37:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.088618
2020-10-13 11:37:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=20124.53515625Mb; avail=224404.1796875Mb
2020-10-13 11:37:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.004662
2020-10-13 11:37:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=20125.140625Mb; avail=224403.57421875Mb
2020-10-13 11:37:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.624146
2020-10-13 11:37:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.718550
2020-10-13 11:37:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=20325.5234375Mb; avail=224203.49609375Mb
2020-10-13 11:37:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=20319.67578125Mb; avail=224209.34375Mb
2020-10-13 11:37:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.075947
2020-10-13 11:37:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=20321.296875Mb; avail=224207.53125Mb
2020-10-13 11:37:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.004381
2020-10-13 11:37:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=20321.296875Mb; avail=224207.53125Mb
2020-10-13 11:37:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.229481
2020-10-13 11:37:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.311059
2020-10-13 11:37:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21039.5859375Mb; avail=223489.16015625Mb
2020-10-13 11:37:56 | INFO | fairseq.trainer | begin training epoch 17
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:38:23 | INFO | train_inner | epoch 017:     56 / 634 loss=4.612, nll_loss=3.025, ppl=8.14, wps=23922.3, ups=1.53, wpb=15655.8, bsz=571.2, num_updates=10200, lr=0.000125245, gnorm=0.729, clip=0, train_wall=38, wall=4276
2020-10-13 11:39:04 | INFO | train_inner | epoch 017:    156 / 634 loss=4.557, nll_loss=2.963, ppl=7.8, wps=38964.1, ups=2.47, wpb=15775.7, bsz=612.5, num_updates=10300, lr=0.000124635, gnorm=0.712, clip=0, train_wall=38, wall=4317
2020-10-13 11:39:40 | INFO | train_inner | epoch 017:    256 / 634 loss=4.565, nll_loss=2.973, ppl=7.85, wps=43760.9, ups=2.77, wpb=15801.5, bsz=585, num_updates=10400, lr=0.000124035, gnorm=0.704, clip=0, train_wall=35, wall=4353
2020-10-13 11:40:19 | INFO | train_inner | epoch 017:    356 / 634 loss=4.565, nll_loss=2.972, ppl=7.85, wps=39803.1, ups=2.53, wpb=15723.6, bsz=586.2, num_updates=10500, lr=0.000123443, gnorm=0.731, clip=0, train_wall=37, wall=4392
2020-10-13 11:41:00 | INFO | train_inner | epoch 017:    456 / 634 loss=4.566, nll_loss=2.973, ppl=7.85, wps=38983.5, ups=2.46, wpb=15830, bsz=573.8, num_updates=10600, lr=0.000122859, gnorm=0.693, clip=0, train_wall=38, wall=4433
2020-10-13 11:41:41 | INFO | train_inner | epoch 017:    556 / 634 loss=4.549, nll_loss=2.954, ppl=7.75, wps=38234.2, ups=2.42, wpb=15791, bsz=598.7, num_updates=10700, lr=0.000122284, gnorm=0.712, clip=0, train_wall=39, wall=4474
2020-10-13 11:42:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 11:42:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27826.41015625Mb; avail=216701.99609375Mb
2020-10-13 11:42:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002995
2020-10-13 11:42:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27826.9140625Mb; avail=216701.4921875Mb
2020-10-13 11:42:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.235389
2020-10-13 11:42:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27810.796875Mb; avail=216717.40234375Mb
2020-10-13 11:42:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.153249
2020-10-13 11:42:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.392989
2020-10-13 11:42:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27943.390625Mb; avail=216584.80859375Mb
2020-10-13 11:42:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28028.76171875Mb; avail=216499.4375Mb
2020-10-13 11:42:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002716
2020-10-13 11:42:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28028.76171875Mb; avail=216499.4375Mb
2020-10-13 11:42:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.197140
2020-10-13 11:42:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28161.30859375Mb; avail=216366.890625Mb
2020-10-13 11:42:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.146964
2020-10-13 11:42:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.348294
2020-10-13 11:42:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28207.46875Mb; avail=216320.6328125Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:42:22 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 4.683 | nll_loss 2.993 | ppl 7.96 | wps 68078.6 | wpb 5051.4 | bsz 192.5 | num_updates 10778 | best_loss 4.683
2020-10-13 11:42:22 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:42:28 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/checkpoint_best.pt (epoch 17 @ 10778 updates, score 4.683) (writing took 6.247917542932555 seconds)
2020-10-13 11:42:28 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2020-10-13 11:42:28 | INFO | train | epoch 017 | loss 4.559 | nll_loss 2.965 | ppl 7.81 | wps 36118.3 | ups 2.29 | wpb 15785.1 | bsz 594.2 | num_updates 10778 | lr 0.00012184 | gnorm 0.709 | clip 0 | train_wall 239 | wall 4521
2020-10-13 11:42:28 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=18/shard_epoch=17
2020-10-13 11:42:28 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=18/shard_epoch=18
2020-10-13 11:42:28 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28037.14453125Mb; avail=216491.3125Mb
2020-10-13 11:42:28 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.015635
2020-10-13 11:42:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.181885
2020-10-13 11:42:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27093.6328125Mb; avail=217434.14453125Mb
2020-10-13 11:42:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.007197
2020-10-13 11:42:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27094.23828125Mb; avail=217433.5390625Mb
2020-10-13 11:42:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:03.161024
2020-10-13 11:42:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:03.351921
2020-10-13 11:42:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28093.640625Mb; avail=216434.6328125Mb
2020-10-13 11:42:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28197.60546875Mb; avail=216330.66796875Mb
2020-10-13 11:42:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.074357
2020-10-13 11:42:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28229.63671875Mb; avail=216298.63671875Mb
2020-10-13 11:42:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.004165
2020-10-13 11:42:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28229.63671875Mb; avail=216298.63671875Mb
2020-10-13 11:42:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.715747
2020-10-13 11:42:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.795474
2020-10-13 11:42:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28610.46484375Mb; avail=215917.8359375Mb
2020-10-13 11:42:35 | INFO | fairseq.trainer | begin training epoch 18
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:42:48 | INFO | train_inner | epoch 018:     22 / 634 loss=4.532, nll_loss=2.935, ppl=7.64, wps=23650.2, ups=1.5, wpb=15789.6, bsz=615, num_updates=10800, lr=0.000121716, gnorm=0.707, clip=0, train_wall=39, wall=4541
2020-10-13 11:43:29 | INFO | train_inner | epoch 018:    122 / 634 loss=4.48, nll_loss=2.876, ppl=7.34, wps=38157.4, ups=2.44, wpb=15646.5, bsz=631.6, num_updates=10900, lr=0.000121157, gnorm=0.722, clip=0, train_wall=39, wall=4582
2020-10-13 11:44:10 | INFO | train_inner | epoch 018:    222 / 634 loss=4.519, nll_loss=2.92, ppl=7.57, wps=38441.9, ups=2.45, wpb=15695.7, bsz=572.1, num_updates=11000, lr=0.000120605, gnorm=0.716, clip=0, train_wall=39, wall=4623
2020-10-13 11:44:51 | INFO | train_inner | epoch 018:    322 / 634 loss=4.489, nll_loss=2.886, ppl=7.39, wps=38360.3, ups=2.43, wpb=15804.9, bsz=588.9, num_updates=11100, lr=0.00012006, gnorm=0.705, clip=0, train_wall=39, wall=4664
2020-10-13 11:45:32 | INFO | train_inner | epoch 018:    422 / 634 loss=4.487, nll_loss=2.884, ppl=7.38, wps=38153.6, ups=2.42, wpb=15772.5, bsz=611.2, num_updates=11200, lr=0.000119523, gnorm=0.704, clip=0, train_wall=39, wall=4705
2020-10-13 11:46:13 | INFO | train_inner | epoch 018:    522 / 634 loss=4.493, nll_loss=2.891, ppl=7.42, wps=38903.6, ups=2.43, wpb=15993.4, bsz=586.7, num_updates=11300, lr=0.000118993, gnorm=0.727, clip=0, train_wall=39, wall=4747
2020-10-13 11:46:55 | INFO | train_inner | epoch 018:    622 / 634 loss=4.509, nll_loss=2.909, ppl=7.51, wps=38297.1, ups=2.42, wpb=15823.5, bsz=587.2, num_updates=11400, lr=0.00011847, gnorm=0.703, clip=0, train_wall=39, wall=4788
2020-10-13 11:47:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 11:47:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27717.38671875Mb; avail=216810.81640625Mb
2020-10-13 11:47:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002032
2020-10-13 11:47:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27717.38671875Mb; avail=216810.81640625Mb
2020-10-13 11:47:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.139154
2020-10-13 11:47:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27717.38671875Mb; avail=216810.81640625Mb
2020-10-13 11:47:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.110993
2020-10-13 11:47:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.253250
2020-10-13 11:47:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27717.38671875Mb; avail=216810.81640625Mb
2020-10-13 11:47:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27717.38671875Mb; avail=216810.81640625Mb
2020-10-13 11:47:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001971
2020-10-13 11:47:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27717.38671875Mb; avail=216810.81640625Mb
2020-10-13 11:47:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.132991
2020-10-13 11:47:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27717.1484375Mb; avail=216810.9453125Mb
2020-10-13 11:47:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.103394
2020-10-13 11:47:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.239365
2020-10-13 11:47:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27721.92578125Mb; avail=216806.16796875Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:47:09 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 4.652 | nll_loss 2.952 | ppl 7.74 | wps 53828.4 | wpb 5051.4 | bsz 192.5 | num_updates 11412 | best_loss 4.652
2020-10-13 11:47:09 | INFO | fairseq_cli.train | begin save checkpoint
2020-10-13 11:47:15 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/checkpoint_best.pt (epoch 18 @ 11412 updates, score 4.652) (writing took 6.406817812006921 seconds)
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:47:16 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2020-10-13 11:47:16 | INFO | train | epoch 018 | loss 4.498 | nll_loss 2.896 | ppl 7.45 | wps 34851.1 | ups 2.21 | wpb 15785.1 | bsz 594.2 | num_updates 11412 | lr 0.000118407 | gnorm 0.712 | clip 0 | train_wall 246 | wall 4809
2020-10-13 11:47:16 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=19/shard_epoch=18
2020-10-13 11:47:16 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=19/shard_epoch=19
2020-10-13 11:47:16 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27552.16015625Mb; avail=216976.21484375Mb
2020-10-13 11:47:16 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.015068
2020-10-13 11:47:16 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.144495
2020-10-13 11:47:16 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27603.67578125Mb; avail=216924.69921875Mb
2020-10-13 11:47:16 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.007113
2020-10-13 11:47:16 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27603.67578125Mb; avail=216924.69921875Mb
2020-10-13 11:47:18 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.072743
2020-10-13 11:47:18 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.225990
2020-10-13 11:47:18 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28349.078125Mb; avail=216179.55078125Mb
2020-10-13 11:47:18 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28391.40234375Mb; avail=216137.2265625Mb
2020-10-13 11:47:18 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.071225
2020-10-13 11:47:18 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28427.67578125Mb; avail=216100.953125Mb
2020-10-13 11:47:18 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.006514
2020-10-13 11:47:18 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28428.28125Mb; avail=216100.34765625Mb
2020-10-13 11:47:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.122719
2020-10-13 11:47:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.202107
2020-10-13 11:47:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28768.921875Mb; avail=215759.49609375Mb
2020-10-13 11:47:20 | INFO | fairseq.trainer | begin training epoch 19
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:48:01 | INFO | train_inner | epoch 019:     88 / 634 loss=4.461, nll_loss=2.854, ppl=7.23, wps=23948.1, ups=1.52, wpb=15796.4, bsz=592.1, num_updates=11500, lr=0.000117954, gnorm=0.734, clip=0, train_wall=39, wall=4854
2020-10-13 11:48:42 | INFO | train_inner | epoch 019:    188 / 634 loss=4.449, nll_loss=2.84, ppl=7.16, wps=38538.7, ups=2.43, wpb=15867.9, bsz=580.9, num_updates=11600, lr=0.000117444, gnorm=0.698, clip=0, train_wall=39, wall=4895
2020-10-13 11:49:23 | INFO | train_inner | epoch 019:    288 / 634 loss=4.457, nll_loss=2.85, ppl=7.21, wps=38321.8, ups=2.45, wpb=15609.7, bsz=574.6, num_updates=11700, lr=0.000116941, gnorm=0.713, clip=0, train_wall=39, wall=4936
2020-10-13 11:50:04 | INFO | train_inner | epoch 019:    388 / 634 loss=4.43, nll_loss=2.819, ppl=7.06, wps=38310.8, ups=2.45, wpb=15663.7, bsz=631.4, num_updates=11800, lr=0.000116445, gnorm=0.713, clip=0, train_wall=39, wall=4977
2020-10-13 11:50:44 | INFO | train_inner | epoch 019:    488 / 634 loss=4.447, nll_loss=2.837, ppl=7.15, wps=38889.9, ups=2.45, wpb=15898.5, bsz=588.9, num_updates=11900, lr=0.000115954, gnorm=0.717, clip=0, train_wall=39, wall=5018
2020-10-13 11:51:26 | INFO | train_inner | epoch 019:    588 / 634 loss=4.422, nll_loss=2.81, ppl=7.01, wps=38674.8, ups=2.43, wpb=15903.3, bsz=611.5, num_updates=12000, lr=0.00011547, gnorm=0.689, clip=0, train_wall=39, wall=5059
2020-10-13 11:51:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 11:51:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=29486.734375Mb; avail=215041.4140625Mb
2020-10-13 11:51:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003118
2020-10-13 11:51:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29487.4296875Mb; avail=215040.9296875Mb
2020-10-13 11:51:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.297245
2020-10-13 11:51:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29484.7578125Mb; avail=215043.40234375Mb
2020-10-13 11:51:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.206734
2020-10-13 11:51:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.508583
2020-10-13 11:51:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29474.41796875Mb; avail=215053.7421875Mb
2020-10-13 11:51:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=29474.41796875Mb; avail=215053.7421875Mb
2020-10-13 11:51:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002869
2020-10-13 11:51:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29474.41796875Mb; avail=215053.7421875Mb
2020-10-13 11:51:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.291623
2020-10-13 11:51:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29474.0390625Mb; avail=215053.66796875Mb
2020-10-13 11:51:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.204349
2020-10-13 11:51:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.500378
2020-10-13 11:51:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29478.0703125Mb; avail=215050.1953125Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:51:53 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 4.622 | nll_loss 2.924 | ppl 7.59 | wps 76093.8 | wpb 5051.4 | bsz 192.5 | num_updates 12046 | best_loss 4.622
2020-10-13 11:51:53 | INFO | fairseq_cli.train | begin save checkpoint
2020-10-13 11:52:00 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/checkpoint_best.pt (epoch 19 @ 12046 updates, score 4.622) (writing took 6.662941089132801 seconds)
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:52:00 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2020-10-13 11:52:00 | INFO | train | epoch 019 | loss 4.443 | nll_loss 2.834 | ppl 7.13 | wps 35144.8 | ups 2.23 | wpb 15785.1 | bsz 594.2 | num_updates 12046 | lr 0.000115249 | gnorm 0.713 | clip 0 | train_wall 245 | wall 5093
2020-10-13 11:52:00 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=20/shard_epoch=19
2020-10-13 11:52:00 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=20/shard_epoch=20
2020-10-13 11:52:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28176.74609375Mb; avail=216351.07421875Mb
2020-10-13 11:52:00 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.006235
2020-10-13 11:52:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.090300
2020-10-13 11:52:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28306.09765625Mb; avail=216222.45703125Mb
2020-10-13 11:52:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.004781
2020-10-13 11:52:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28306.09765625Mb; avail=216222.45703125Mb
2020-10-13 11:52:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.298295
2020-10-13 11:52:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.394578
2020-10-13 11:52:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28539.43359375Mb; avail=215989.23046875Mb
2020-10-13 11:52:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28541.734375Mb; avail=215986.9296875Mb
2020-10-13 11:52:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.064769
2020-10-13 11:52:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27975.32421875Mb; avail=216555.80078125Mb
2020-10-13 11:52:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.003199
2020-10-13 11:52:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27909.37109375Mb; avail=216621.26171875Mb
2020-10-13 11:52:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.837939
2020-10-13 11:52:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.906886
2020-10-13 11:52:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27232.84765625Mb; avail=217295.31640625Mb
2020-10-13 11:52:05 | INFO | fairseq.trainer | begin training epoch 20
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:52:31 | INFO | train_inner | epoch 020:     54 / 634 loss=4.414, nll_loss=2.802, ppl=6.98, wps=24014.1, ups=1.53, wpb=15728.6, bsz=587.3, num_updates=12100, lr=0.000114992, gnorm=0.715, clip=0, train_wall=39, wall=5124
2020-10-13 11:53:12 | INFO | train_inner | epoch 020:    154 / 634 loss=4.405, nll_loss=2.791, ppl=6.92, wps=37774.9, ups=2.44, wpb=15472.3, bsz=581.8, num_updates=12200, lr=0.00011452, gnorm=0.726, clip=0, train_wall=39, wall=5165
2020-10-13 11:53:53 | INFO | train_inner | epoch 020:    254 / 634 loss=4.379, nll_loss=2.761, ppl=6.78, wps=38551.5, ups=2.43, wpb=15836.1, bsz=612.2, num_updates=12300, lr=0.000114053, gnorm=0.697, clip=0, train_wall=39, wall=5206
2020-10-13 11:54:34 | INFO | train_inner | epoch 020:    354 / 634 loss=4.396, nll_loss=2.78, ppl=6.87, wps=38080.7, ups=2.42, wpb=15718, bsz=589.5, num_updates=12400, lr=0.000113592, gnorm=0.693, clip=0, train_wall=39, wall=5247
2020-10-13 11:55:15 | INFO | train_inner | epoch 020:    454 / 634 loss=4.396, nll_loss=2.781, ppl=6.87, wps=39107.5, ups=2.46, wpb=15921.6, bsz=596.9, num_updates=12500, lr=0.000113137, gnorm=0.693, clip=0, train_wall=38, wall=5288
2020-10-13 11:55:56 | INFO | train_inner | epoch 020:    554 / 634 loss=4.402, nll_loss=2.787, ppl=6.9, wps=38923.1, ups=2.43, wpb=16033.6, bsz=587.1, num_updates=12600, lr=0.000112687, gnorm=0.702, clip=0, train_wall=39, wall=5329
2020-10-13 11:56:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 11:56:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28341.0546875Mb; avail=216187.375Mb
2020-10-13 11:56:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003025
2020-10-13 11:56:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28341.0546875Mb; avail=216187.375Mb
2020-10-13 11:56:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.292115
2020-10-13 11:56:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28444.66796875Mb; avail=216083.76171875Mb
2020-10-13 11:56:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.213391
2020-10-13 11:56:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.510236
2020-10-13 11:56:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28447.58984375Mb; avail=216080.83984375Mb
2020-10-13 11:56:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28451.22265625Mb; avail=216077.20703125Mb
2020-10-13 11:56:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003130
2020-10-13 11:56:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28451.828125Mb; avail=216076.6015625Mb
2020-10-13 11:56:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.128982
2020-10-13 11:56:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28449.79296875Mb; avail=216078.796875Mb
2020-10-13 11:56:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.097942
2020-10-13 11:56:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.231328
2020-10-13 11:56:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28460.6015625Mb; avail=216067.98828125Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:56:38 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 4.593 | nll_loss 2.893 | ppl 7.43 | wps 75418.9 | wpb 5051.4 | bsz 192.5 | num_updates 12680 | best_loss 4.593
2020-10-13 11:56:38 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:56:44 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/checkpoint_best.pt (epoch 20 @ 12680 updates, score 4.593) (writing took 6.251266698120162 seconds)
2020-10-13 11:56:45 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2020-10-13 11:56:45 | INFO | train | epoch 020 | loss 4.393 | nll_loss 2.778 | ppl 6.86 | wps 35154.1 | ups 2.23 | wpb 15785.1 | bsz 594.2 | num_updates 12680 | lr 0.000112331 | gnorm 0.7 | clip 0 | train_wall 245 | wall 5378
2020-10-13 11:56:45 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=21/shard_epoch=20
2020-10-13 11:56:45 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=21/shard_epoch=21
2020-10-13 11:56:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=20414.2890625Mb; avail=224113.50390625Mb
2020-10-13 11:56:45 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.013396
2020-10-13 11:56:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.138021
2020-10-13 11:56:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=20462.89453125Mb; avail=224065.04296875Mb
2020-10-13 11:56:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.006294
2020-10-13 11:56:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=20463.5Mb; avail=224064.4375Mb
2020-10-13 11:56:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.745151
2020-10-13 11:56:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.891026
2020-10-13 11:56:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21683.1484375Mb; avail=222845.640625Mb
2020-10-13 11:56:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=21689.53125Mb; avail=222839.2578125Mb
2020-10-13 11:56:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.094586
2020-10-13 11:56:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21680.90625Mb; avail=222847.8828125Mb
2020-10-13 11:56:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.005752
2020-10-13 11:56:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21680.90625Mb; avail=222847.8828125Mb
2020-10-13 11:56:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.972665
2020-10-13 11:56:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.074680
2020-10-13 11:56:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21720.3515625Mb; avail=222807.87109375Mb
2020-10-13 11:56:50 | INFO | fairseq.trainer | begin training epoch 21
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:57:03 | INFO | train_inner | epoch 021:     20 / 634 loss=4.383, nll_loss=2.767, ppl=6.81, wps=23704.6, ups=1.51, wpb=15723.3, bsz=582.9, num_updates=12700, lr=0.000112243, gnorm=0.691, clip=0, train_wall=39, wall=5396
2020-10-13 11:57:43 | INFO | train_inner | epoch 021:    120 / 634 loss=4.353, nll_loss=2.731, ppl=6.64, wps=39044.2, ups=2.46, wpb=15889.9, bsz=585.5, num_updates=12800, lr=0.000111803, gnorm=0.69, clip=0, train_wall=38, wall=5436
2020-10-13 11:58:23 | INFO | train_inner | epoch 021:    220 / 634 loss=4.355, nll_loss=2.734, ppl=6.65, wps=39857.4, ups=2.54, wpb=15701.4, bsz=591.4, num_updates=12900, lr=0.000111369, gnorm=0.695, clip=0, train_wall=37, wall=5476
2020-10-13 11:59:00 | INFO | train_inner | epoch 021:    320 / 634 loss=4.34, nll_loss=2.717, ppl=6.57, wps=43035.2, ups=2.71, wpb=15864.8, bsz=613.8, num_updates=13000, lr=0.00011094, gnorm=0.688, clip=0, train_wall=35, wall=5513
2020-10-13 11:59:39 | INFO | train_inner | epoch 021:    420 / 634 loss=4.344, nll_loss=2.722, ppl=6.6, wps=39566.9, ups=2.54, wpb=15549.4, bsz=573.2, num_updates=13100, lr=0.000110516, gnorm=0.687, clip=0, train_wall=37, wall=5552
2020-10-13 12:00:20 | INFO | train_inner | epoch 021:    520 / 634 loss=4.348, nll_loss=2.726, ppl=6.62, wps=38898.5, ups=2.46, wpb=15824.2, bsz=591, num_updates=13200, lr=0.000110096, gnorm=0.718, clip=0, train_wall=38, wall=5593
2020-10-13 12:01:01 | INFO | train_inner | epoch 021:    620 / 634 loss=4.341, nll_loss=2.718, ppl=6.58, wps=38596.9, ups=2.43, wpb=15910.8, bsz=621.1, num_updates=13300, lr=0.000109682, gnorm=0.698, clip=0, train_wall=39, wall=5634
2020-10-13 12:01:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 12:01:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27262.2734375Mb; avail=217265.70703125Mb
2020-10-13 12:01:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002939
2020-10-13 12:01:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27262.2734375Mb; avail=217265.70703125Mb
2020-10-13 12:01:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.309828
2020-10-13 12:01:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27268.69921875Mb; avail=217259.28125Mb
2020-10-13 12:01:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.222522
2020-10-13 12:01:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.536877
2020-10-13 12:01:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27263.37109375Mb; avail=217264.609375Mb
2020-10-13 12:01:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27262.66015625Mb; avail=217264.5859375Mb
2020-10-13 12:01:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003040
2020-10-13 12:01:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27262.66015625Mb; avail=217264.5859375Mb
2020-10-13 12:01:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.234146
2020-10-13 12:01:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27272.97265625Mb; avail=217254.578125Mb
2020-10-13 12:01:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.183918
2020-10-13 12:01:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.422410
2020-10-13 12:01:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27271.2734375Mb; avail=217256.8515625Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:01:16 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 4.567 | nll_loss 2.856 | ppl 7.24 | wps 67411.1 | wpb 5051.4 | bsz 192.5 | num_updates 13314 | best_loss 4.567
2020-10-13 12:01:16 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:01:22 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/checkpoint_best.pt (epoch 21 @ 13314 updates, score 4.567) (writing took 6.545593767892569 seconds)
2020-10-13 12:01:23 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2020-10-13 12:01:23 | INFO | train | epoch 021 | loss 4.347 | nll_loss 2.725 | ppl 6.61 | wps 36045.9 | ups 2.28 | wpb 15785.1 | bsz 594.2 | num_updates 13314 | lr 0.000109624 | gnorm 0.697 | clip 0 | train_wall 238 | wall 5656
2020-10-13 12:01:23 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=22/shard_epoch=21
2020-10-13 12:01:23 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=22/shard_epoch=22
2020-10-13 12:01:23 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=26881.5390625Mb; avail=217646.85546875Mb
2020-10-13 12:01:23 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.006164
2020-10-13 12:01:23 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.110462
2020-10-13 12:01:23 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26894.59375Mb; avail=217633.80078125Mb
2020-10-13 12:01:23 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.007179
2020-10-13 12:01:23 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26894.59375Mb; avail=217633.80078125Mb
2020-10-13 12:01:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.424442
2020-10-13 12:01:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.544246
2020-10-13 12:01:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27046.86328125Mb; avail=217481.47265625Mb
2020-10-13 12:01:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27070.34765625Mb; avail=217451.93359375Mb
2020-10-13 12:01:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.067093
2020-10-13 12:01:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27107.6640625Mb; avail=217420.13671875Mb
2020-10-13 12:01:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.004836
2020-10-13 12:01:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27122.1953125Mb; avail=217405.60546875Mb
2020-10-13 12:01:27 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.082648
2020-10-13 12:01:27 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.155861
2020-10-13 12:01:27 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27774.9375Mb; avail=216753.21875Mb
2020-10-13 12:01:27 | INFO | fairseq.trainer | begin training epoch 22
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:02:07 | INFO | train_inner | epoch 022:     86 / 634 loss=4.292, nll_loss=2.663, ppl=6.33, wps=23882.1, ups=1.5, wpb=15896.6, bsz=624, num_updates=13400, lr=0.000109272, gnorm=0.677, clip=0, train_wall=39, wall=5700
2020-10-13 12:02:48 | INFO | train_inner | epoch 022:    186 / 634 loss=4.313, nll_loss=2.687, ppl=6.44, wps=38408.1, ups=2.44, wpb=15744.9, bsz=579.2, num_updates=13500, lr=0.000108866, gnorm=0.724, clip=0, train_wall=39, wall=5741
2020-10-13 12:03:29 | INFO | train_inner | epoch 022:    286 / 634 loss=4.315, nll_loss=2.688, ppl=6.44, wps=38246, ups=2.43, wpb=15720.5, bsz=572.1, num_updates=13600, lr=0.000108465, gnorm=0.696, clip=0, train_wall=39, wall=5783
2020-10-13 12:04:10 | INFO | train_inner | epoch 022:    386 / 634 loss=4.32, nll_loss=2.694, ppl=6.47, wps=38463.6, ups=2.44, wpb=15760.7, bsz=581.4, num_updates=13700, lr=0.000108069, gnorm=0.72, clip=0, train_wall=39, wall=5823
2020-10-13 12:04:51 | INFO | train_inner | epoch 022:    486 / 634 loss=4.302, nll_loss=2.675, ppl=6.39, wps=38299.8, ups=2.43, wpb=15730.4, bsz=593.2, num_updates=13800, lr=0.000107676, gnorm=0.686, clip=0, train_wall=39, wall=5865
2020-10-13 12:05:32 | INFO | train_inner | epoch 022:    586 / 634 loss=4.314, nll_loss=2.688, ppl=6.44, wps=38612.3, ups=2.45, wpb=15744.1, bsz=584.1, num_updates=13900, lr=0.000107288, gnorm=0.743, clip=0, train_wall=39, wall=5905
2020-10-13 12:05:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 12:05:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27190.6484375Mb; avail=217337.34765625Mb
2020-10-13 12:05:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002430
2020-10-13 12:05:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27190.6484375Mb; avail=217337.34765625Mb
2020-10-13 12:05:53 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.277836
2020-10-13 12:05:53 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27190.578125Mb; avail=217337.51953125Mb
2020-10-13 12:05:53 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.208141
2020-10-13 12:05:53 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.489859
2020-10-13 12:05:53 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27211.46875Mb; avail=217316.58203125Mb
2020-10-13 12:05:53 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27201.625Mb; avail=217326.42578125Mb
2020-10-13 12:05:53 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002881
2020-10-13 12:05:53 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27201.625Mb; avail=217326.42578125Mb
2020-10-13 12:05:53 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.296463
2020-10-13 12:05:53 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27192.171875Mb; avail=217335.87890625Mb
2020-10-13 12:05:53 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.213791
2020-10-13 12:05:53 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.514721
2020-10-13 12:05:53 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27192.171875Mb; avail=217335.87890625Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:06:01 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 4.551 | nll_loss 2.841 | ppl 7.17 | wps 70947.4 | wpb 5051.4 | bsz 192.5 | num_updates 13948 | best_loss 4.551
2020-10-13 12:06:01 | INFO | fairseq_cli.train | begin save checkpoint
2020-10-13 12:06:07 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/checkpoint_best.pt (epoch 22 @ 13948 updates, score 4.551) (writing took 6.141372617799789 seconds)
2020-10-13 12:06:07 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2020-10-13 12:06:07 | INFO | train | epoch 022 | loss 4.306 | nll_loss 2.679 | ppl 6.4 | wps 35158.3 | ups 2.23 | wpb 15785.1 | bsz 594.2 | num_updates 13948 | lr 0.000107104 | gnorm 0.706 | clip 0 | train_wall 246 | wall 5940
2020-10-13 12:06:07 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=23/shard_epoch=22
2020-10-13 12:06:07 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=23/shard_epoch=23
2020-10-13 12:06:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=26690.66796875Mb; avail=217837.5859375Mb
2020-10-13 12:06:07 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.013516
2020-10-13 12:06:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.152210
2020-10-13 12:06:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26703.6484375Mb; avail=217824.92578125Mb
2020-10-13 12:06:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.006753
2020-10-13 12:06:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26706.0703125Mb; avail=217821.8984375Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:06:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.584287
2020-10-13 12:06:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.744814
2020-10-13 12:06:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27395.28515625Mb; avail=217133.5078125Mb
2020-10-13 12:06:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27407.90625Mb; avail=217120.5546875Mb
2020-10-13 12:06:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.076781
2020-10-13 12:06:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27442.5390625Mb; avail=217085.921875Mb
2020-10-13 12:06:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.004674
2020-10-13 12:06:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27443.14453125Mb; avail=217085.31640625Mb
2020-10-13 12:06:12 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.771079
2020-10-13 12:06:12 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.853771
2020-10-13 12:06:12 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27865.703125Mb; avail=216661.69921875Mb
2020-10-13 12:06:12 | INFO | fairseq.trainer | begin training epoch 23
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:06:37 | INFO | train_inner | epoch 023:     52 / 634 loss=4.275, nll_loss=2.644, ppl=6.25, wps=24402.9, ups=1.54, wpb=15893.1, bsz=604.9, num_updates=14000, lr=0.000106904, gnorm=0.689, clip=0, train_wall=39, wall=5970
2020-10-13 12:07:18 | INFO | train_inner | epoch 023:    152 / 634 loss=4.254, nll_loss=2.62, ppl=6.15, wps=38303.1, ups=2.45, wpb=15664, bsz=629.6, num_updates=14100, lr=0.000106525, gnorm=0.682, clip=0, train_wall=38, wall=6011
2020-10-13 12:07:59 | INFO | train_inner | epoch 023:    252 / 634 loss=4.27, nll_loss=2.638, ppl=6.22, wps=38422.8, ups=2.44, wpb=15765.2, bsz=577, num_updates=14200, lr=0.000106149, gnorm=0.709, clip=0, train_wall=39, wall=6052
2020-10-13 12:08:40 | INFO | train_inner | epoch 023:    352 / 634 loss=4.289, nll_loss=2.658, ppl=6.31, wps=38347.2, ups=2.45, wpb=15667, bsz=554.4, num_updates=14300, lr=0.000105777, gnorm=0.727, clip=0, train_wall=39, wall=6093
2020-10-13 12:09:21 | INFO | train_inner | epoch 023:    452 / 634 loss=4.278, nll_loss=2.646, ppl=6.26, wps=38541.9, ups=2.43, wpb=15844.8, bsz=583, num_updates=14400, lr=0.000105409, gnorm=0.7, clip=0, train_wall=39, wall=6134
2020-10-13 12:10:02 | INFO | train_inner | epoch 023:    552 / 634 loss=4.265, nll_loss=2.633, ppl=6.2, wps=38693, ups=2.43, wpb=15902.7, bsz=587.4, num_updates=14500, lr=0.000105045, gnorm=0.689, clip=0, train_wall=39, wall=6175
2020-10-13 12:10:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 12:10:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27191.671875Mb; avail=217335.97265625Mb
2020-10-13 12:10:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002744
2020-10-13 12:10:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27191.671875Mb; avail=217335.97265625Mb
2020-10-13 12:10:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.148795
2020-10-13 12:10:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27195.796875Mb; avail=217331.734375Mb
2020-10-13 12:10:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.107277
2020-10-13 12:10:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.260182
2020-10-13 12:10:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27204.453125Mb; avail=217322.75390625Mb
2020-10-13 12:10:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27198.94140625Mb; avail=217328.484375Mb
2020-10-13 12:10:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002642
2020-10-13 12:10:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27198.94140625Mb; avail=217328.484375Mb
2020-10-13 12:10:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.203246
2020-10-13 12:10:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27195.16796875Mb; avail=217333.07421875Mb
2020-10-13 12:10:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.207888
2020-10-13 12:10:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.415319
2020-10-13 12:10:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27194.3046875Mb; avail=217333.9375Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:10:45 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 4.534 | nll_loss 2.826 | ppl 7.09 | wps 60042.4 | wpb 5051.4 | bsz 192.5 | num_updates 14582 | best_loss 4.534
2020-10-13 12:10:45 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:10:51 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/checkpoint_best.pt (epoch 23 @ 14582 updates, score 4.534) (writing took 6.220577906118706 seconds)
2020-10-13 12:10:52 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2020-10-13 12:10:52 | INFO | train | epoch 023 | loss 4.268 | nll_loss 2.635 | ppl 6.21 | wps 35205.7 | ups 2.23 | wpb 15785.1 | bsz 594.2 | num_updates 14582 | lr 0.000104749 | gnorm 0.703 | clip 0 | train_wall 246 | wall 6225
2020-10-13 12:10:52 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=24/shard_epoch=23
2020-10-13 12:10:52 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=24/shard_epoch=24
2020-10-13 12:10:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=26772.84765625Mb; avail=217755.37109375Mb
2020-10-13 12:10:52 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.006347
2020-10-13 12:10:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.091805
2020-10-13 12:10:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26776.46875Mb; avail=217751.75Mb
2020-10-13 12:10:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.006021
2020-10-13 12:10:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26776.46875Mb; avail=217751.75Mb
2020-10-13 12:10:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.104217
2020-10-13 12:10:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.203378
2020-10-13 12:10:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27161.1640625Mb; avail=217367.34765625Mb
2020-10-13 12:10:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27177.8515625Mb; avail=217350.66015625Mb
2020-10-13 12:10:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.066176
2020-10-13 12:10:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27210.66796875Mb; avail=217317.84375Mb
2020-10-13 12:10:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.004670
2020-10-13 12:10:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27210.66796875Mb; avail=217317.84375Mb
2020-10-13 12:10:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.761690
2020-10-13 12:10:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.833786
2020-10-13 12:10:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27819.47265625Mb; avail=216708.6328125Mb
2020-10-13 12:10:57 | INFO | fairseq.trainer | begin training epoch 24
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:11:09 | INFO | train_inner | epoch 024:     18 / 634 loss=4.239, nll_loss=2.603, ppl=6.08, wps=23817.9, ups=1.5, wpb=15869, bsz=657.1, num_updates=14600, lr=0.000104685, gnorm=0.71, clip=0, train_wall=39, wall=6242
2020-10-13 12:11:50 | INFO | train_inner | epoch 024:    118 / 634 loss=4.231, nll_loss=2.593, ppl=6.03, wps=38068.2, ups=2.42, wpb=15725.9, bsz=595.8, num_updates=14700, lr=0.000104328, gnorm=0.694, clip=0, train_wall=39, wall=6283
2020-10-13 12:12:31 | INFO | train_inner | epoch 024:    218 / 634 loss=4.237, nll_loss=2.6, ppl=6.06, wps=38627.3, ups=2.44, wpb=15859.1, bsz=567.7, num_updates=14800, lr=0.000103975, gnorm=0.687, clip=0, train_wall=39, wall=6324
2020-10-13 12:13:13 | INFO | train_inner | epoch 024:    318 / 634 loss=4.232, nll_loss=2.595, ppl=6.04, wps=38031, ups=2.42, wpb=15744.8, bsz=595.4, num_updates=14900, lr=0.000103626, gnorm=0.702, clip=0, train_wall=39, wall=6366
2020-10-13 12:13:53 | INFO | train_inner | epoch 024:    418 / 634 loss=4.247, nll_loss=2.611, ppl=6.11, wps=38814.1, ups=2.46, wpb=15794, bsz=569.8, num_updates=15000, lr=0.00010328, gnorm=0.699, clip=0, train_wall=39, wall=6407
2020-10-13 12:14:34 | INFO | train_inner | epoch 024:    518 / 634 loss=4.228, nll_loss=2.59, ppl=6.02, wps=38393.8, ups=2.44, wpb=15706.3, bsz=610.7, num_updates=15100, lr=0.000102937, gnorm=0.712, clip=0, train_wall=39, wall=6447
2020-10-13 12:15:15 | INFO | train_inner | epoch 024:    618 / 634 loss=4.214, nll_loss=2.575, ppl=5.96, wps=38852.6, ups=2.45, wpb=15874.7, bsz=635.1, num_updates=15200, lr=0.000102598, gnorm=0.719, clip=0, train_wall=38, wall=6488
2020-10-13 12:15:22 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 12:15:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28538.56640625Mb; avail=215988.81640625Mb
2020-10-13 12:15:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003212
2020-10-13 12:15:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28538.56640625Mb; avail=215988.81640625Mb
2020-10-13 12:15:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.242390
2020-10-13 12:15:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28538.828125Mb; avail=215988.98046875Mb
2020-10-13 12:15:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.100281
2020-10-13 12:15:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.347208
2020-10-13 12:15:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28538.828125Mb; avail=215988.98046875Mb
2020-10-13 12:15:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28539.12890625Mb; avail=215988.88671875Mb
2020-10-13 12:15:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002518
2020-10-13 12:15:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28539.12890625Mb; avail=215988.88671875Mb
2020-10-13 12:15:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.169471
2020-10-13 12:15:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27805.9765625Mb; avail=216722.0390625Mb
2020-10-13 12:15:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.137893
2020-10-13 12:15:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.312157
2020-10-13 12:15:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27802.60546875Mb; avail=216725.41015625Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:15:30 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 4.527 | nll_loss 2.817 | ppl 7.05 | wps 57524.9 | wpb 5051.4 | bsz 192.5 | num_updates 15216 | best_loss 4.527
2020-10-13 12:15:30 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:15:36 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/checkpoint_best.pt (epoch 24 @ 15216 updates, score 4.527) (writing took 6.304489333182573 seconds)
2020-10-13 12:15:37 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2020-10-13 12:15:37 | INFO | train | epoch 024 | loss 4.233 | nll_loss 2.595 | ppl 6.04 | wps 35063.9 | ups 2.22 | wpb 15785.1 | bsz 594.2 | num_updates 15216 | lr 0.000102544 | gnorm 0.701 | clip 0 | train_wall 246 | wall 6510
2020-10-13 12:15:37 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=25/shard_epoch=24
2020-10-13 12:15:37 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=25/shard_epoch=25
2020-10-13 12:15:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27735.37890625Mb; avail=216792.76953125Mb
2020-10-13 12:15:37 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.006415
2020-10-13 12:15:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.090187
2020-10-13 12:15:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27741.96875Mb; avail=216786.1796875Mb
2020-10-13 12:15:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.004302
2020-10-13 12:15:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27741.5234375Mb; avail=216786.4296875Mb
2020-10-13 12:15:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.788342
2020-10-13 12:15:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.883925
2020-10-13 12:15:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23758.9453125Mb; avail=220772.6640625Mb
2020-10-13 12:15:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=22891.21484375Mb; avail=221637.44140625Mb
2020-10-13 12:15:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.067906
2020-10-13 12:15:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21948.40234375Mb; avail=222580.25390625Mb
2020-10-13 12:15:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.005355
2020-10-13 12:15:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21886.3203125Mb; avail=222644.2890625Mb
2020-10-13 12:15:42 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.590071
2020-10-13 12:15:42 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.664612
2020-10-13 12:15:42 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=20219.4921875Mb; avail=224308.27734375Mb
2020-10-13 12:15:42 | INFO | fairseq.trainer | begin training epoch 25
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:16:21 | INFO | train_inner | epoch 025:     84 / 634 loss=4.208, nll_loss=2.566, ppl=5.92, wps=23903.5, ups=1.52, wpb=15680.6, bsz=563.9, num_updates=15300, lr=0.000102262, gnorm=0.672, clip=0, train_wall=39, wall=6554
2020-10-13 12:17:02 | INFO | train_inner | epoch 025:    184 / 634 loss=4.156, nll_loss=2.51, ppl=5.7, wps=38157.2, ups=2.45, wpb=15557, bsz=643.4, num_updates=15400, lr=0.000101929, gnorm=0.697, clip=0, train_wall=38, wall=6595
2020-10-13 12:17:39 | INFO | train_inner | epoch 025:    284 / 634 loss=4.192, nll_loss=2.55, ppl=5.85, wps=42366, ups=2.64, wpb=16021, bsz=602.7, num_updates=15500, lr=0.0001016, gnorm=0.696, clip=0, train_wall=36, wall=6633
2020-10-13 12:18:17 | INFO | train_inner | epoch 025:    384 / 634 loss=4.229, nll_loss=2.59, ppl=6.02, wps=41668.8, ups=2.64, wpb=15766.9, bsz=556.7, num_updates=15600, lr=0.000101274, gnorm=0.705, clip=0, train_wall=36, wall=6670
2020-10-13 12:18:57 | INFO | train_inner | epoch 025:    484 / 634 loss=4.207, nll_loss=2.566, ppl=5.92, wps=39842.9, ups=2.49, wpb=15970.9, bsz=596.3, num_updates=15700, lr=0.000100951, gnorm=0.694, clip=0, train_wall=38, wall=6710
2020-10-13 12:19:38 | INFO | train_inner | epoch 025:    584 / 634 loss=4.212, nll_loss=2.572, ppl=5.95, wps=38069.8, ups=2.43, wpb=15647.4, bsz=582.6, num_updates=15800, lr=0.000100631, gnorm=0.711, clip=0, train_wall=39, wall=6752
2020-10-13 12:19:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 12:19:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28357.48046875Mb; avail=216169.39453125Mb
2020-10-13 12:19:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003042
2020-10-13 12:19:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28357.48046875Mb; avail=216169.39453125Mb
2020-10-13 12:19:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.255399
2020-10-13 12:19:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28425.0703125Mb; avail=216102.73046875Mb
2020-10-13 12:20:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.209858
2020-10-13 12:20:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.469731
2020-10-13 12:20:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28422.875Mb; avail=216104.92578125Mb
2020-10-13 12:20:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28422.875Mb; avail=216104.92578125Mb
2020-10-13 12:20:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003023
2020-10-13 12:20:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28422.875Mb; avail=216104.92578125Mb
2020-10-13 12:20:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.190394
2020-10-13 12:20:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28423.1171875Mb; avail=216104.68359375Mb
2020-10-13 12:20:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.098482
2020-10-13 12:20:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.293233
2020-10-13 12:20:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28432.64453125Mb; avail=216095.15625Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:20:07 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 4.513 | nll_loss 2.8 | ppl 6.96 | wps 67354.9 | wpb 5051.4 | bsz 192.5 | num_updates 15850 | best_loss 4.513
2020-10-13 12:20:07 | INFO | fairseq_cli.train | begin save checkpoint
2020-10-13 12:20:14 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/checkpoint_best.pt (epoch 25 @ 15850 updates, score 4.513) (writing took 6.20425863401033 seconds)
2020-10-13 12:20:14 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2020-10-13 12:20:14 | INFO | train | epoch 025 | loss 4.199 | nll_loss 2.557 | ppl 5.88 | wps 36111.4 | ups 2.29 | wpb 15785.1 | bsz 594.2 | num_updates 15850 | lr 0.000100472 | gnorm 0.694 | clip 0 | train_wall 239 | wall 6787
2020-10-13 12:20:14 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=26/shard_epoch=25
2020-10-13 12:20:14 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=26/shard_epoch=26
2020-10-13 12:20:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27217.3984375Mb; avail=217310.1015625Mb
2020-10-13 12:20:14 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.013247
2020-10-13 12:20:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.145024
2020-10-13 12:20:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27219.73046875Mb; avail=217307.77734375Mb
2020-10-13 12:20:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.007676
2020-10-13 12:20:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27220.45703125Mb; avail=217307.05078125Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:20:16 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.042294
2020-10-13 12:20:16 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.196779
2020-10-13 12:20:16 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27397.98828125Mb; avail=217129.99609375Mb
2020-10-13 12:20:16 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27410.984375Mb; avail=217117.4921875Mb
2020-10-13 12:20:17 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.087453
2020-10-13 12:20:17 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27402.16015625Mb; avail=217126.31640625Mb
2020-10-13 12:20:17 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.005572
2020-10-13 12:20:17 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27402.16015625Mb; avail=217126.31640625Mb
2020-10-13 12:20:18 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.866816
2020-10-13 12:20:18 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.961022
2020-10-13 12:20:18 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27350.5390625Mb; avail=217177.22265625Mb
2020-10-13 12:20:18 | INFO | fairseq.trainer | begin training epoch 26
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:20:43 | INFO | train_inner | epoch 026:     50 / 634 loss=4.177, nll_loss=2.533, ppl=5.79, wps=24537.3, ups=1.55, wpb=15852.9, bsz=598.8, num_updates=15900, lr=0.000100314, gnorm=0.677, clip=0, train_wall=39, wall=6816
2020-10-13 12:21:24 | INFO | train_inner | epoch 026:    150 / 634 loss=4.171, nll_loss=2.525, ppl=5.75, wps=38577.7, ups=2.43, wpb=15876.5, bsz=585.7, num_updates=16000, lr=0.0001, gnorm=0.714, clip=0, train_wall=39, wall=6857
2020-10-13 12:22:05 | INFO | train_inner | epoch 026:    250 / 634 loss=4.156, nll_loss=2.508, ppl=5.69, wps=38411.5, ups=2.43, wpb=15799.1, bsz=632.2, num_updates=16100, lr=9.9689e-05, gnorm=0.685, clip=0, train_wall=39, wall=6898
2020-10-13 12:22:46 | INFO | train_inner | epoch 026:    350 / 634 loss=4.155, nll_loss=2.508, ppl=5.69, wps=38219, ups=2.43, wpb=15704.1, bsz=601, num_updates=16200, lr=9.93808e-05, gnorm=0.682, clip=0, train_wall=39, wall=6940
2020-10-13 12:23:27 | INFO | train_inner | epoch 026:    450 / 634 loss=4.174, nll_loss=2.529, ppl=5.77, wps=38597.1, ups=2.44, wpb=15848.6, bsz=594.9, num_updates=16300, lr=9.90755e-05, gnorm=0.697, clip=0, train_wall=39, wall=6981
2020-10-13 12:24:09 | INFO | train_inner | epoch 026:    550 / 634 loss=4.183, nll_loss=2.539, ppl=5.81, wps=38194.2, ups=2.43, wpb=15685.6, bsz=574.4, num_updates=16400, lr=9.8773e-05, gnorm=0.704, clip=0, train_wall=39, wall=7022
2020-10-13 12:24:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 12:24:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27954.453125Mb; avail=216573.234375Mb
2020-10-13 12:24:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001909
2020-10-13 12:24:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27954.453125Mb; avail=216573.234375Mb
2020-10-13 12:24:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.149175
2020-10-13 12:24:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27958.36328125Mb; avail=216569.32421875Mb
2020-10-13 12:24:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.199462
2020-10-13 12:24:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.351990
2020-10-13 12:24:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27948.55859375Mb; avail=216579.53515625Mb
2020-10-13 12:24:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27948.390625Mb; avail=216579.58984375Mb
2020-10-13 12:24:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002630
2020-10-13 12:24:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27948.390625Mb; avail=216579.58984375Mb
2020-10-13 12:24:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.308076
2020-10-13 12:24:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27953.5078125Mb; avail=216574.46484375Mb
2020-10-13 12:24:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.212716
2020-10-13 12:24:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.524961
2020-10-13 12:24:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27951.921875Mb; avail=216576.05078125Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:24:52 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 4.5 | nll_loss 2.786 | ppl 6.9 | wps 76413.5 | wpb 5051.4 | bsz 192.5 | num_updates 16484 | best_loss 4.5
2020-10-13 12:24:52 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:24:58 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/checkpoint_best.pt (epoch 26 @ 16484 updates, score 4.5) (writing took 6.455752269830555 seconds)
2020-10-13 12:24:59 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2020-10-13 12:24:59 | INFO | train | epoch 026 | loss 4.168 | nll_loss 2.522 | ppl 5.74 | wps 35180.3 | ups 2.23 | wpb 15785.1 | bsz 594.2 | num_updates 16484 | lr 9.8521e-05 | gnorm 0.694 | clip 0 | train_wall 246 | wall 7072
2020-10-13 12:24:59 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=27/shard_epoch=26
2020-10-13 12:24:59 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=27/shard_epoch=27
2020-10-13 12:24:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27560.45703125Mb; avail=216967.82421875Mb
2020-10-13 12:24:59 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.012557
2020-10-13 12:24:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.143100
2020-10-13 12:24:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27560.26171875Mb; avail=216968.01953125Mb
2020-10-13 12:24:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.007186
2020-10-13 12:24:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27560.8671875Mb; avail=216967.4140625Mb
2020-10-13 12:25:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.192643
2020-10-13 12:25:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.344970
2020-10-13 12:25:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27795.50390625Mb; avail=216732.68359375Mb
2020-10-13 12:25:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27774.80859375Mb; avail=216753.37890625Mb
2020-10-13 12:25:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.107059
2020-10-13 12:25:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27779.20703125Mb; avail=216748.57421875Mb
2020-10-13 12:25:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.006851
2020-10-13 12:25:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27779.20703125Mb; avail=216748.57421875Mb
2020-10-13 12:25:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:03.212611
2020-10-13 12:25:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:03.328347
2020-10-13 12:25:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28274.6484375Mb; avail=216253.0234375Mb
2020-10-13 12:25:04 | INFO | fairseq.trainer | begin training epoch 27
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:25:15 | INFO | train_inner | epoch 027:     16 / 634 loss=4.17, nll_loss=2.525, ppl=5.75, wps=23763.1, ups=1.5, wpb=15819, bsz=574.6, num_updates=16500, lr=9.84732e-05, gnorm=0.683, clip=0, train_wall=39, wall=7088
2020-10-13 12:25:56 | INFO | train_inner | epoch 027:    116 / 634 loss=4.11, nll_loss=2.456, ppl=5.49, wps=38483.5, ups=2.43, wpb=15827.5, bsz=617.5, num_updates=16600, lr=9.81761e-05, gnorm=0.701, clip=0, train_wall=39, wall=7129
2020-10-13 12:26:37 | INFO | train_inner | epoch 027:    216 / 634 loss=4.144, nll_loss=2.494, ppl=5.63, wps=38177, ups=2.44, wpb=15672.3, bsz=597.8, num_updates=16700, lr=9.78818e-05, gnorm=0.715, clip=0, train_wall=39, wall=7170
2020-10-13 12:27:19 | INFO | train_inner | epoch 027:    316 / 634 loss=4.148, nll_loss=2.499, ppl=5.65, wps=38503.5, ups=2.43, wpb=15868.3, bsz=568.1, num_updates=16800, lr=9.759e-05, gnorm=0.722, clip=0, train_wall=39, wall=7212
2020-10-13 12:27:59 | INFO | train_inner | epoch 027:    416 / 634 loss=4.147, nll_loss=2.497, ppl=5.65, wps=38804.9, ups=2.44, wpb=15890.6, bsz=603, num_updates=16900, lr=9.73009e-05, gnorm=0.697, clip=0, train_wall=39, wall=7253
2020-10-13 12:28:41 | INFO | train_inner | epoch 027:    516 / 634 loss=4.141, nll_loss=2.491, ppl=5.62, wps=37952.3, ups=2.41, wpb=15734.3, bsz=602.2, num_updates=17000, lr=9.70143e-05, gnorm=0.68, clip=0, train_wall=39, wall=7294
2020-10-13 12:29:22 | INFO | train_inner | epoch 027:    616 / 634 loss=4.146, nll_loss=2.497, ppl=5.65, wps=38569.4, ups=2.44, wpb=15782.2, bsz=580.1, num_updates=17100, lr=9.67302e-05, gnorm=0.692, clip=0, train_wall=39, wall=7335
2020-10-13 12:29:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 12:29:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28162.05078125Mb; avail=216365.72265625Mb
2020-10-13 12:29:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002994
2020-10-13 12:29:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28162.05078125Mb; avail=216365.72265625Mb
2020-10-13 12:29:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.268401
2020-10-13 12:29:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28164.95703125Mb; avail=216363.23046875Mb
2020-10-13 12:29:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.099012
2020-10-13 12:29:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.371695
2020-10-13 12:29:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28165.1640625Mb; avail=216363.23046875Mb
2020-10-13 12:29:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28165.1640625Mb; avail=216363.23046875Mb
2020-10-13 12:29:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001884
2020-10-13 12:29:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28165.1640625Mb; avail=216363.23046875Mb
2020-10-13 12:29:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.131128
2020-10-13 12:29:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28164.67578125Mb; avail=216363.71875Mb
2020-10-13 12:29:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.098558
2020-10-13 12:29:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.232547
2020-10-13 12:29:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28168.82421875Mb; avail=216359.5703125Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:29:37 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 4.507 | nll_loss 2.791 | ppl 6.92 | wps 64748.2 | wpb 5051.4 | bsz 192.5 | num_updates 17118 | best_loss 4.5
2020-10-13 12:29:37 | INFO | fairseq_cli.train | begin save checkpoint
2020-10-13 12:29:41 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/checkpoint_last.pt (epoch 27 @ 17118 updates, score 4.507) (writing took 3.6025633960962296 seconds)
2020-10-13 12:29:42 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2020-10-13 12:29:42 | INFO | train | epoch 027 | loss 4.139 | nll_loss 2.489 | ppl 5.61 | wps 35348.8 | ups 2.24 | wpb 15785.1 | bsz 594.2 | num_updates 17118 | lr 9.66793e-05 | gnorm 0.7 | clip 0 | train_wall 246 | wall 7355
2020-10-13 12:29:42 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=28/shard_epoch=27
2020-10-13 12:29:42 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=28/shard_epoch=28
2020-10-13 12:29:42 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27459.46484375Mb; avail=217068.55859375Mb
2020-10-13 12:29:42 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.012106
2020-10-13 12:29:42 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.150767
2020-10-13 12:29:42 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27462.046875Mb; avail=217066.15234375Mb
2020-10-13 12:29:42 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.007296
2020-10-13 12:29:42 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27462.046875Mb; avail=217066.15234375Mb
2020-10-13 12:29:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.550176
2020-10-13 12:29:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.709974
2020-10-13 12:29:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27477.61328125Mb; avail=217050.4921875Mb
2020-10-13 12:29:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27462.265625Mb; avail=217066.16796875Mb
2020-10-13 12:29:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.085462
2020-10-13 12:29:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27462.265625Mb; avail=217066.16796875Mb
2020-10-13 12:29:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.006439
2020-10-13 12:29:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27462.265625Mb; avail=217066.16796875Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:29:46 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.890252
2020-10-13 12:29:46 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.983856
2020-10-13 12:29:46 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27894.8984375Mb; avail=216633.3203125Mb
2020-10-13 12:29:46 | INFO | fairseq.trainer | begin training epoch 28
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:30:24 | INFO | train_inner | epoch 028:     82 / 634 loss=4.128, nll_loss=2.476, ppl=5.56, wps=25190.5, ups=1.61, wpb=15670.7, bsz=566.3, num_updates=17200, lr=9.64486e-05, gnorm=0.707, clip=0, train_wall=39, wall=7397
2020-10-13 12:31:05 | INFO | train_inner | epoch 028:    182 / 634 loss=4.114, nll_loss=2.46, ppl=5.5, wps=38253.6, ups=2.45, wpb=15596.3, bsz=612.8, num_updates=17300, lr=9.61694e-05, gnorm=0.698, clip=0, train_wall=38, wall=7438
2020-10-13 12:31:46 | INFO | train_inner | epoch 028:    282 / 634 loss=4.099, nll_loss=2.444, ppl=5.44, wps=39135.7, ups=2.45, wpb=15962.2, bsz=589.3, num_updates=17400, lr=9.58927e-05, gnorm=0.683, clip=0, train_wall=38, wall=7479
2020-10-13 12:32:27 | INFO | train_inner | epoch 028:    382 / 634 loss=4.105, nll_loss=2.45, ppl=5.46, wps=38398.9, ups=2.42, wpb=15873.9, bsz=599.3, num_updates=17500, lr=9.56183e-05, gnorm=0.705, clip=0, train_wall=39, wall=7520
2020-10-13 12:33:08 | INFO | train_inner | epoch 028:    482 / 634 loss=4.13, nll_loss=2.478, ppl=5.57, wps=38365.8, ups=2.43, wpb=15774.9, bsz=577.7, num_updates=17600, lr=9.53463e-05, gnorm=0.701, clip=0, train_wall=39, wall=7561
2020-10-13 12:33:49 | INFO | train_inner | epoch 028:    582 / 634 loss=4.109, nll_loss=2.455, ppl=5.48, wps=38270, ups=2.44, wpb=15709.9, bsz=584, num_updates=17700, lr=9.50765e-05, gnorm=0.681, clip=0, train_wall=39, wall=7602
2020-10-13 12:34:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 12:34:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27947.9375Mb; avail=216579.9765625Mb
2020-10-13 12:34:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003056
2020-10-13 12:34:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27947.9375Mb; avail=216579.9765625Mb
2020-10-13 12:34:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.295922
2020-10-13 12:34:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27961.41796875Mb; avail=216566.70703125Mb
2020-10-13 12:34:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.222268
2020-10-13 12:34:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.522909
2020-10-13 12:34:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27956.9765625Mb; avail=216570.31640625Mb
2020-10-13 12:34:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27959.28515625Mb; avail=216568.0078125Mb
2020-10-13 12:34:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002887
2020-10-13 12:34:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27959.28515625Mb; avail=216568.0078125Mb
2020-10-13 12:34:12 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.283295
2020-10-13 12:34:12 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27949.04296875Mb; avail=216578.890625Mb
2020-10-13 12:34:12 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.207670
2020-10-13 12:34:12 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.495342
2020-10-13 12:34:12 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27954.89453125Mb; avail=216573.0390625Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:34:19 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 4.485 | nll_loss 2.771 | ppl 6.82 | wps 72925.5 | wpb 5051.4 | bsz 192.5 | num_updates 17752 | best_loss 4.485
2020-10-13 12:34:19 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:34:26 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/checkpoint_best.pt (epoch 28 @ 17752 updates, score 4.485) (writing took 6.6670695981010795 seconds)
2020-10-13 12:34:26 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2020-10-13 12:34:26 | INFO | train | epoch 028 | loss 4.111 | nll_loss 2.457 | ppl 5.49 | wps 35144.1 | ups 2.23 | wpb 15785.1 | bsz 594.2 | num_updates 17752 | lr 9.49372e-05 | gnorm 0.694 | clip 0 | train_wall 246 | wall 7640
2020-10-13 12:34:26 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=29/shard_epoch=28
2020-10-13 12:34:26 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=29/shard_epoch=29
2020-10-13 12:34:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27547.13671875Mb; avail=216981.13671875Mb
2020-10-13 12:34:26 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.012192
2020-10-13 12:34:27 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.147336
2020-10-13 12:34:27 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27580.6015625Mb; avail=216947.671875Mb
2020-10-13 12:34:27 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.006345
2020-10-13 12:34:27 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27581.20703125Mb; avail=216947.06640625Mb
2020-10-13 12:34:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.460621
2020-10-13 12:34:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.615773
2020-10-13 12:34:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27711.3671875Mb; avail=216816.3203125Mb
2020-10-13 12:34:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27691.4375Mb; avail=216836.25Mb
2020-10-13 12:34:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.095842
2020-10-13 12:34:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27691.4375Mb; avail=216836.25Mb
2020-10-13 12:34:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.009406
2020-10-13 12:34:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27691.4375Mb; avail=216836.25Mb
2020-10-13 12:34:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.544899
2020-10-13 12:34:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.651979
2020-10-13 12:34:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27895.24609375Mb; avail=216632.66796875Mb
2020-10-13 12:34:32 | INFO | fairseq.trainer | begin training epoch 29
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:34:56 | INFO | train_inner | epoch 029:     48 / 634 loss=4.074, nll_loss=2.415, ppl=5.33, wps=23777.9, ups=1.5, wpb=15876.5, bsz=639.6, num_updates=17800, lr=9.48091e-05, gnorm=0.672, clip=0, train_wall=39, wall=7669
2020-10-13 12:35:37 | INFO | train_inner | epoch 029:    148 / 634 loss=4.074, nll_loss=2.415, ppl=5.33, wps=38070, ups=2.43, wpb=15665.8, bsz=590.6, num_updates=17900, lr=9.45439e-05, gnorm=0.703, clip=0, train_wall=39, wall=7710
2020-10-13 12:36:17 | INFO | train_inner | epoch 029:    248 / 634 loss=4.082, nll_loss=2.424, ppl=5.37, wps=39310.5, ups=2.51, wpb=15633.5, bsz=576.2, num_updates=18000, lr=9.42809e-05, gnorm=0.719, clip=0, train_wall=38, wall=7750
2020-10-13 12:36:53 | INFO | train_inner | epoch 029:    348 / 634 loss=4.082, nll_loss=2.424, ppl=5.36, wps=43672.1, ups=2.74, wpb=15944, bsz=598, num_updates=18100, lr=9.40201e-05, gnorm=0.69, clip=0, train_wall=35, wall=7786
2020-10-13 12:37:33 | INFO | train_inner | epoch 029:    448 / 634 loss=4.087, nll_loss=2.43, ppl=5.39, wps=40130.7, ups=2.55, wpb=15734.2, bsz=587.9, num_updates=18200, lr=9.37614e-05, gnorm=0.714, clip=0, train_wall=37, wall=7826
2020-10-13 12:38:13 | INFO | train_inner | epoch 029:    548 / 634 loss=4.098, nll_loss=2.441, ppl=5.43, wps=38726, ups=2.45, wpb=15785.9, bsz=615.7, num_updates=18300, lr=9.35049e-05, gnorm=0.694, clip=0, train_wall=38, wall=7866
2020-10-13 12:38:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 12:38:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=29014.4296875Mb; avail=215513.4296875Mb
2020-10-13 12:38:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002777
2020-10-13 12:38:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29014.4296875Mb; avail=215513.4296875Mb
2020-10-13 12:38:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.177942
2020-10-13 12:38:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29009.80859375Mb; avail=215518.05078125Mb
2020-10-13 12:38:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.105478
2020-10-13 12:38:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.287485
2020-10-13 12:38:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29009.80859375Mb; avail=215518.05078125Mb
2020-10-13 12:38:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=29009.80859375Mb; avail=215518.05078125Mb
2020-10-13 12:38:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001985
2020-10-13 12:38:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29009.80859375Mb; avail=215518.05078125Mb
2020-10-13 12:38:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.129389
2020-10-13 12:38:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29009.80859375Mb; avail=215518.05078125Mb
2020-10-13 12:38:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.099182
2020-10-13 12:38:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.231572
2020-10-13 12:38:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29018.83984375Mb; avail=215509.453125Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:38:57 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 4.477 | nll_loss 2.764 | ppl 6.79 | wps 73660.2 | wpb 5051.4 | bsz 192.5 | num_updates 18386 | best_loss 4.477
2020-10-13 12:38:57 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:39:03 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/checkpoint_best.pt (epoch 29 @ 18386 updates, score 4.477) (writing took 6.501498222118244 seconds)
2020-10-13 12:39:04 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2020-10-13 12:39:04 | INFO | train | epoch 029 | loss 4.085 | nll_loss 2.428 | ppl 5.38 | wps 36074 | ups 2.29 | wpb 15785.1 | bsz 594.2 | num_updates 18386 | lr 9.3286e-05 | gnorm 0.7 | clip 0 | train_wall 239 | wall 7917
2020-10-13 12:39:04 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=30/shard_epoch=29
2020-10-13 12:39:04 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=30/shard_epoch=30
2020-10-13 12:39:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28950.46875Mb; avail=215575.14453125Mb
2020-10-13 12:39:04 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.012975
2020-10-13 12:39:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.146452
2020-10-13 12:39:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29181.7109375Mb; avail=215346.32421875Mb
2020-10-13 12:39:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.004914
2020-10-13 12:39:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29182.31640625Mb; avail=215345.71875Mb
2020-10-13 12:39:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.903536
2020-10-13 12:39:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:03.056116
2020-10-13 12:39:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29394.58203125Mb; avail=215132.41796875Mb
2020-10-13 12:39:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=29400.53125Mb; avail=215126.46875Mb
2020-10-13 12:39:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.066935
2020-10-13 12:39:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29405.4375Mb; avail=215122.109375Mb
2020-10-13 12:39:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.004546
2020-10-13 12:39:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29405.140625Mb; avail=215122.4765625Mb
2020-10-13 12:39:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.118256
2020-10-13 12:39:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.190892
2020-10-13 12:39:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28427.08984375Mb; avail=216101.05078125Mb
2020-10-13 12:39:09 | INFO | fairseq.trainer | begin training epoch 30
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:39:19 | INFO | train_inner | epoch 030:     14 / 634 loss=4.101, nll_loss=2.446, ppl=5.45, wps=24257.6, ups=1.52, wpb=15952.8, bsz=569.6, num_updates=18400, lr=9.32505e-05, gnorm=0.689, clip=0, train_wall=39, wall=7932
2020-10-13 12:40:00 | INFO | train_inner | epoch 030:    114 / 634 loss=4.042, nll_loss=2.379, ppl=5.2, wps=38153.9, ups=2.43, wpb=15723.6, bsz=614.6, num_updates=18500, lr=9.29981e-05, gnorm=0.694, clip=0, train_wall=39, wall=7973
2020-10-13 12:40:42 | INFO | train_inner | epoch 030:    214 / 634 loss=4.057, nll_loss=2.395, ppl=5.26, wps=38518.4, ups=2.42, wpb=15911, bsz=587.1, num_updates=18600, lr=9.27478e-05, gnorm=0.709, clip=0, train_wall=39, wall=8015
2020-10-13 12:41:23 | INFO | train_inner | epoch 030:    314 / 634 loss=4.063, nll_loss=2.402, ppl=5.29, wps=38317.7, ups=2.42, wpb=15859, bsz=595.8, num_updates=18700, lr=9.24995e-05, gnorm=0.71, clip=0, train_wall=39, wall=8056
2020-10-13 12:42:04 | INFO | train_inner | epoch 030:    414 / 634 loss=4.055, nll_loss=2.393, ppl=5.25, wps=38696.3, ups=2.45, wpb=15794.2, bsz=603.3, num_updates=18800, lr=9.22531e-05, gnorm=0.71, clip=0, train_wall=39, wall=8097
2020-10-13 12:42:45 | INFO | train_inner | epoch 030:    514 / 634 loss=4.073, nll_loss=2.413, ppl=5.33, wps=37929.2, ups=2.42, wpb=15694.6, bsz=575.5, num_updates=18900, lr=9.20087e-05, gnorm=0.717, clip=0, train_wall=39, wall=8138
2020-10-13 12:43:26 | INFO | train_inner | epoch 030:    614 / 634 loss=4.084, nll_loss=2.426, ppl=5.37, wps=38192.7, ups=2.44, wpb=15636.4, bsz=585.3, num_updates=19000, lr=9.17663e-05, gnorm=0.713, clip=0, train_wall=39, wall=8179
2020-10-13 12:43:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 12:43:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28684.65625Mb; avail=215843.09765625Mb
2020-10-13 12:43:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002317
2020-10-13 12:43:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28684.65625Mb; avail=215843.09765625Mb
2020-10-13 12:43:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.143750
2020-10-13 12:43:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28685.09375Mb; avail=215843.1015625Mb
2020-10-13 12:43:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.105624
2020-10-13 12:43:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.253186
2020-10-13 12:43:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28688.67578125Mb; avail=215839.203125Mb
2020-10-13 12:43:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28690.4921875Mb; avail=215837.38671875Mb
2020-10-13 12:43:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001912
2020-10-13 12:43:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28690.4921875Mb; avail=215837.38671875Mb
2020-10-13 12:43:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.137307
2020-10-13 12:43:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28685.29296875Mb; avail=215842.5859375Mb
2020-10-13 12:43:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.100346
2020-10-13 12:43:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.240741
2020-10-13 12:43:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28685.29296875Mb; avail=215842.5859375Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:43:43 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 4.467 | nll_loss 2.746 | ppl 6.71 | wps 57585.6 | wpb 5051.4 | bsz 192.5 | num_updates 19020 | best_loss 4.467
2020-10-13 12:43:43 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:43:50 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/checkpoint_best.pt (epoch 30 @ 19020 updates, score 4.467) (writing took 6.416694663930684 seconds)
2020-10-13 12:43:50 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2020-10-13 12:43:50 | INFO | train | epoch 030 | loss 4.062 | nll_loss 2.401 | ppl 5.28 | wps 34965 | ups 2.22 | wpb 15785.1 | bsz 594.2 | num_updates 19020 | lr 9.1718e-05 | gnorm 0.708 | clip 0 | train_wall 246 | wall 8203
2020-10-13 12:43:50 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=31/shard_epoch=30
2020-10-13 12:43:50 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=31/shard_epoch=31
2020-10-13 12:43:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=29926.046875Mb; avail=214602.25390625Mb
2020-10-13 12:43:50 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.012744
2020-10-13 12:43:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.109026
2020-10-13 12:43:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29921.6015625Mb; avail=214606.69921875Mb
2020-10-13 12:43:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.005079
2020-10-13 12:43:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29921.6015625Mb; avail=214606.69921875Mb
2020-10-13 12:43:53 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:03.243835
2020-10-13 12:43:53 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:03.359718
2020-10-13 12:43:53 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28437.55859375Mb; avail=216090.34765625Mb
2020-10-13 12:43:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28437.5546875Mb; avail=216090.34765625Mb
2020-10-13 12:43:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.075644
2020-10-13 12:43:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28439.28125Mb; avail=216088.62109375Mb
2020-10-13 12:43:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.004144
2020-10-13 12:43:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28439.88671875Mb; avail=216088.015625Mb
2020-10-13 12:43:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.726697
2020-10-13 12:43:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.807691
2020-10-13 12:43:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28569.6015625Mb; avail=215958.29296875Mb
2020-10-13 12:43:56 | INFO | fairseq.trainer | begin training epoch 31
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:44:33 | INFO | train_inner | epoch 031:     80 / 634 loss=4.018, nll_loss=2.352, ppl=5.1, wps=23437, ups=1.49, wpb=15768.6, bsz=625.7, num_updates=19100, lr=9.15258e-05, gnorm=0.686, clip=0, train_wall=39, wall=8247
2020-10-13 12:45:15 | INFO | train_inner | epoch 031:    180 / 634 loss=4.037, nll_loss=2.372, ppl=5.18, wps=38422.1, ups=2.43, wpb=15807.6, bsz=569.8, num_updates=19200, lr=9.12871e-05, gnorm=0.682, clip=0, train_wall=39, wall=8288
2020-10-13 12:45:55 | INFO | train_inner | epoch 031:    280 / 634 loss=4.028, nll_loss=2.363, ppl=5.14, wps=38902, ups=2.45, wpb=15907.8, bsz=606.7, num_updates=19300, lr=9.10503e-05, gnorm=0.686, clip=0, train_wall=39, wall=8329
2020-10-13 12:46:37 | INFO | train_inner | epoch 031:    380 / 634 loss=4.049, nll_loss=2.386, ppl=5.23, wps=38220, ups=2.43, wpb=15722.6, bsz=578.6, num_updates=19400, lr=9.08153e-05, gnorm=0.698, clip=0, train_wall=39, wall=8370
2020-10-13 12:47:18 | INFO | train_inner | epoch 031:    480 / 634 loss=4.056, nll_loss=2.395, ppl=5.26, wps=38183.7, ups=2.43, wpb=15681.3, bsz=567.8, num_updates=19500, lr=9.05822e-05, gnorm=0.693, clip=0, train_wall=39, wall=8411
2020-10-13 12:47:59 | INFO | train_inner | epoch 031:    580 / 634 loss=4.036, nll_loss=2.372, ppl=5.18, wps=38518.9, ups=2.43, wpb=15874.8, bsz=610.8, num_updates=19600, lr=9.03508e-05, gnorm=0.696, clip=0, train_wall=39, wall=8452
2020-10-13 12:48:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 12:48:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28680.4609375Mb; avail=215846.95703125Mb
2020-10-13 12:48:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.004203
2020-10-13 12:48:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28680.4609375Mb; avail=215846.95703125Mb
2020-10-13 12:48:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.196293
2020-10-13 12:48:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28696.94140625Mb; avail=215829.796875Mb
2020-10-13 12:48:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.100923
2020-10-13 12:48:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.303527
2020-10-13 12:48:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28681.6484375Mb; avail=215845.5078125Mb
2020-10-13 12:48:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28681.6484375Mb; avail=215845.5078125Mb
2020-10-13 12:48:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002083
2020-10-13 12:48:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28681.6484375Mb; avail=215845.5078125Mb
2020-10-13 12:48:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.217896
2020-10-13 12:48:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28682.14453125Mb; avail=215845.69921875Mb
2020-10-13 12:48:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.101464
2020-10-13 12:48:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.322907
2020-10-13 12:48:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28687.53515625Mb; avail=215840.30859375Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:48:30 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 4.467 | nll_loss 2.752 | ppl 6.74 | wps 66155.4 | wpb 5051.4 | bsz 192.5 | num_updates 19654 | best_loss 4.467
2020-10-13 12:48:30 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:48:36 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/checkpoint_best.pt (epoch 31 @ 19654 updates, score 4.467) (writing took 6.289581459015608 seconds)
2020-10-13 12:48:36 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2020-10-13 12:48:36 | INFO | train | epoch 031 | loss 4.038 | nll_loss 2.374 | ppl 5.18 | wps 34946.1 | ups 2.21 | wpb 15785.1 | bsz 594.2 | num_updates 19654 | lr 9.02266e-05 | gnorm 0.691 | clip 0 | train_wall 246 | wall 8490
2020-10-13 12:48:36 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=32/shard_epoch=31
2020-10-13 12:48:37 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=32/shard_epoch=32
2020-10-13 12:48:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28415.00390625Mb; avail=216112.65234375Mb
2020-10-13 12:48:37 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.006255
2020-10-13 12:48:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.092558
2020-10-13 12:48:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28426.41796875Mb; avail=216101.23828125Mb
2020-10-13 12:48:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.004329
2020-10-13 12:48:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28426.41796875Mb; avail=216101.23828125Mb
2020-10-13 12:48:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.782406
2020-10-13 12:48:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.880713
2020-10-13 12:48:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28456.3359375Mb; avail=216071.0703125Mb
2020-10-13 12:48:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28463.28125Mb; avail=216064.125Mb
2020-10-13 12:48:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.105738
2020-10-13 12:48:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28453.9296875Mb; avail=216073.4765625Mb
2020-10-13 12:48:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.007221
2020-10-13 12:48:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28453.9296875Mb; avail=216073.4765625Mb
2020-10-13 12:48:42 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.887070
2020-10-13 12:48:42 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:03.001751
2020-10-13 12:48:42 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28868.3828125Mb; avail=215659.98046875Mb
2020-10-13 12:48:42 | INFO | fairseq.trainer | begin training epoch 32
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:49:05 | INFO | train_inner | epoch 032:     46 / 634 loss=4.041, nll_loss=2.377, ppl=5.19, wps=23698.3, ups=1.51, wpb=15664.9, bsz=587.2, num_updates=19700, lr=9.01212e-05, gnorm=0.703, clip=0, train_wall=38, wall=8518
2020-10-13 12:49:46 | INFO | train_inner | epoch 032:    146 / 634 loss=4.004, nll_loss=2.336, ppl=5.05, wps=38886.6, ups=2.45, wpb=15901.9, bsz=587, num_updates=19800, lr=8.98933e-05, gnorm=0.68, clip=0, train_wall=39, wall=8559
2020-10-13 12:50:27 | INFO | train_inner | epoch 032:    246 / 634 loss=4.014, nll_loss=2.346, ppl=5.09, wps=38741.5, ups=2.45, wpb=15809.9, bsz=594.5, num_updates=19900, lr=8.96672e-05, gnorm=0.694, clip=0, train_wall=38, wall=8600
2020-10-13 12:51:08 | INFO | train_inner | epoch 032:    346 / 634 loss=4.001, nll_loss=2.332, ppl=5.03, wps=38319.1, ups=2.42, wpb=15822, bsz=642.2, num_updates=20000, lr=8.94427e-05, gnorm=0.696, clip=0, train_wall=39, wall=8641
2020-10-13 12:51:49 | INFO | train_inner | epoch 032:    446 / 634 loss=4.011, nll_loss=2.344, ppl=5.08, wps=38325.5, ups=2.42, wpb=15823.7, bsz=605.8, num_updates=20100, lr=8.92199e-05, gnorm=0.711, clip=0, train_wall=39, wall=8682
2020-10-13 12:52:30 | INFO | train_inner | epoch 032:    546 / 634 loss=4.034, nll_loss=2.368, ppl=5.16, wps=38193.5, ups=2.43, wpb=15727.1, bsz=561, num_updates=20200, lr=8.89988e-05, gnorm=0.699, clip=0, train_wall=39, wall=8724
2020-10-13 12:53:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 12:53:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28704.44921875Mb; avail=215823.24609375Mb
2020-10-13 12:53:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003065
2020-10-13 12:53:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28703.91015625Mb; avail=215823.68359375Mb
2020-10-13 12:53:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.292509
2020-10-13 12:53:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28704.3203125Mb; avail=215823.21484375Mb
2020-10-13 12:53:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.209871
2020-10-13 12:53:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.506978
2020-10-13 12:53:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28704.3203125Mb; avail=215823.21484375Mb
2020-10-13 12:53:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28707.86328125Mb; avail=215819.671875Mb
2020-10-13 12:53:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002839
2020-10-13 12:53:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28707.86328125Mb; avail=215819.671875Mb
2020-10-13 12:53:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.229613
2020-10-13 12:53:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28705.83984375Mb; avail=215821.90625Mb
2020-10-13 12:53:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.154591
2020-10-13 12:53:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.388320
2020-10-13 12:53:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28719.640625Mb; avail=215808.4453125Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:53:15 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 4.464 | nll_loss 2.746 | ppl 6.71 | wps 72343.8 | wpb 5051.4 | bsz 192.5 | num_updates 20288 | best_loss 4.464
2020-10-13 12:53:15 | INFO | fairseq_cli.train | begin save checkpoint
2020-10-13 12:53:21 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/checkpoint_best.pt (epoch 32 @ 20288 updates, score 4.464) (writing took 6.425091888988391 seconds)
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:53:22 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2020-10-13 12:53:22 | INFO | train | epoch 032 | loss 4.015 | nll_loss 2.348 | ppl 5.09 | wps 35096 | ups 2.22 | wpb 15785.1 | bsz 594.2 | num_updates 20288 | lr 8.88056e-05 | gnorm 0.701 | clip 0 | train_wall 245 | wall 8775
2020-10-13 12:53:22 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=33/shard_epoch=32
2020-10-13 12:53:22 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=33/shard_epoch=33
2020-10-13 12:53:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28769.734375Mb; avail=215758.27734375Mb
2020-10-13 12:53:22 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.011063
2020-10-13 12:53:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.145583
2020-10-13 12:53:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28767.99609375Mb; avail=215760.015625Mb
2020-10-13 12:53:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.007849
2020-10-13 12:53:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28767.99609375Mb; avail=215760.015625Mb
2020-10-13 12:53:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:03.269470
2020-10-13 12:53:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:03.424643
2020-10-13 12:53:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28438.6875Mb; avail=216089.609375Mb
2020-10-13 12:53:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28466.75390625Mb; avail=216060.93359375Mb
2020-10-13 12:53:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.101858
2020-10-13 12:53:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28477.8125Mb; avail=216050.3828125Mb
2020-10-13 12:53:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.006961
2020-10-13 12:53:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28478.41796875Mb; avail=216049.77734375Mb
2020-10-13 12:53:27 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.079140
2020-10-13 12:53:27 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.189634
2020-10-13 12:53:27 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28957.30078125Mb; avail=215570.4765625Mb
2020-10-13 12:53:27 | INFO | fairseq.trainer | begin training epoch 33
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:53:37 | INFO | train_inner | epoch 033:     12 / 634 loss=4.011, nll_loss=2.344, ppl=5.08, wps=23714.9, ups=1.51, wpb=15735.7, bsz=603.8, num_updates=20300, lr=8.87794e-05, gnorm=0.721, clip=0, train_wall=38, wall=8790
2020-10-13 12:54:18 | INFO | train_inner | epoch 033:    112 / 634 loss=3.982, nll_loss=2.31, ppl=4.96, wps=38429.3, ups=2.42, wpb=15894.1, bsz=597.3, num_updates=20400, lr=8.85615e-05, gnorm=0.683, clip=0, train_wall=39, wall=8831
2020-10-13 12:54:59 | INFO | train_inner | epoch 033:    212 / 634 loss=3.991, nll_loss=2.321, ppl=5, wps=38995.1, ups=2.47, wpb=15802.9, bsz=588.8, num_updates=20500, lr=8.83452e-05, gnorm=0.7, clip=0, train_wall=38, wall=8872
2020-10-13 12:55:36 | INFO | train_inner | epoch 033:    312 / 634 loss=3.985, nll_loss=2.314, ppl=4.97, wps=42393.4, ups=2.69, wpb=15754, bsz=626.2, num_updates=20600, lr=8.81305e-05, gnorm=0.728, clip=0, train_wall=35, wall=8909
2020-10-13 12:56:14 | INFO | train_inner | epoch 033:    412 / 634 loss=3.998, nll_loss=2.328, ppl=5.02, wps=41176, ups=2.61, wpb=15765.4, bsz=576.3, num_updates=20700, lr=8.79174e-05, gnorm=0.695, clip=0, train_wall=36, wall=8947
2020-10-13 12:56:54 | INFO | train_inner | epoch 033:    512 / 634 loss=4.01, nll_loss=2.342, ppl=5.07, wps=39183.2, ups=2.5, wpb=15697.2, bsz=577.2, num_updates=20800, lr=8.77058e-05, gnorm=0.706, clip=0, train_wall=38, wall=8987
2020-10-13 12:57:36 | INFO | train_inner | epoch 033:    612 / 634 loss=3.998, nll_loss=2.329, ppl=5.02, wps=37944.1, ups=2.42, wpb=15698.8, bsz=605.9, num_updates=20900, lr=8.74957e-05, gnorm=0.693, clip=0, train_wall=39, wall=9029
2020-10-13 12:57:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 12:57:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=29171.5703125Mb; avail=215357.671875Mb
2020-10-13 12:57:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002781
2020-10-13 12:57:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29095.7734375Mb; avail=215431.9921875Mb
2020-10-13 12:57:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.209443
2020-10-13 12:57:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29065.87109375Mb; avail=215461.89453125Mb
2020-10-13 12:57:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.099917
2020-10-13 12:57:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.313496
2020-10-13 12:57:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29056.02734375Mb; avail=215471.73828125Mb
2020-10-13 12:57:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=29056.02734375Mb; avail=215471.73828125Mb
2020-10-13 12:57:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002014
2020-10-13 12:57:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29056.02734375Mb; avail=215471.73828125Mb
2020-10-13 12:57:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.127980
2020-10-13 12:57:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29056.01171875Mb; avail=215471.75390625Mb
2020-10-13 12:57:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.099406
2020-10-13 12:57:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.230572
2020-10-13 12:57:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29055.51953125Mb; avail=215472.24609375Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:57:52 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 4.457 | nll_loss 2.738 | ppl 6.67 | wps 75183.6 | wpb 5051.4 | bsz 192.5 | num_updates 20922 | best_loss 4.457
2020-10-13 12:57:52 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:57:59 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/checkpoint_best.pt (epoch 33 @ 20922 updates, score 4.457) (writing took 6.384780347114429 seconds)
2020-10-13 12:57:59 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2020-10-13 12:57:59 | INFO | train | epoch 033 | loss 3.994 | nll_loss 2.324 | ppl 5.01 | wps 36065.5 | ups 2.28 | wpb 15785.1 | bsz 594.2 | num_updates 20922 | lr 8.74497e-05 | gnorm 0.7 | clip 0 | train_wall 239 | wall 9052
2020-10-13 12:57:59 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=34/shard_epoch=33
2020-10-13 12:57:59 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=34/shard_epoch=34
2020-10-13 12:57:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28770.98046875Mb; avail=215757.0078125Mb
2020-10-13 12:57:59 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.011229
2020-10-13 12:57:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.142494
2020-10-13 12:57:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28775.62890625Mb; avail=215752.359375Mb
2020-10-13 12:57:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.009945
2020-10-13 12:57:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28776.234375Mb; avail=215751.75390625Mb
2020-10-13 12:58:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.014409
2020-10-13 12:58:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.168575
2020-10-13 12:58:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29219.65625Mb; avail=215308.4140625Mb
2020-10-13 12:58:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=29225.90625Mb; avail=215302.65625Mb
2020-10-13 12:58:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.067486
2020-10-13 12:58:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29228.765625Mb; avail=215299.6875Mb
2020-10-13 12:58:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.004465
2020-10-13 12:58:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29228.8359375Mb; avail=215299.6171875Mb
2020-10-13 12:58:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.678584
2020-10-13 12:58:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.752149
2020-10-13 12:58:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28941.7734375Mb; avail=215586.24609375Mb
2020-10-13 12:58:03 | INFO | fairseq.trainer | begin training epoch 34
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:58:40 | INFO | train_inner | epoch 034:     78 / 634 loss=3.979, nll_loss=2.306, ppl=4.95, wps=24915.4, ups=1.56, wpb=15943.5, bsz=572.4, num_updates=21000, lr=8.72872e-05, gnorm=0.695, clip=0, train_wall=39, wall=9093
2020-10-13 12:59:21 | INFO | train_inner | epoch 034:    178 / 634 loss=3.974, nll_loss=2.301, ppl=4.93, wps=38568.2, ups=2.44, wpb=15805.8, bsz=568.8, num_updates=21100, lr=8.70801e-05, gnorm=0.71, clip=0, train_wall=39, wall=9134
2020-10-13 13:00:02 | INFO | train_inner | epoch 034:    278 / 634 loss=3.969, nll_loss=2.296, ppl=4.91, wps=38124, ups=2.43, wpb=15681.9, bsz=601.7, num_updates=21200, lr=8.68744e-05, gnorm=0.696, clip=0, train_wall=39, wall=9175
2020-10-13 13:00:43 | INFO | train_inner | epoch 034:    378 / 634 loss=3.973, nll_loss=2.299, ppl=4.92, wps=38688.2, ups=2.41, wpb=16074.2, bsz=626.7, num_updates=21300, lr=8.66703e-05, gnorm=0.695, clip=0, train_wall=39, wall=9216
2020-10-13 13:01:24 | INFO | train_inner | epoch 034:    478 / 634 loss=3.983, nll_loss=2.311, ppl=4.96, wps=38028.3, ups=2.44, wpb=15594.3, bsz=583, num_updates=21400, lr=8.64675e-05, gnorm=0.715, clip=0, train_wall=39, wall=9257
2020-10-13 13:02:05 | INFO | train_inner | epoch 034:    578 / 634 loss=3.992, nll_loss=2.321, ppl=5, wps=38039.8, ups=2.43, wpb=15682.5, bsz=578.2, num_updates=21500, lr=8.62662e-05, gnorm=0.705, clip=0, train_wall=39, wall=9299
2020-10-13 13:02:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 13:02:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=29275.6015625Mb; avail=215252.55078125Mb
2020-10-13 13:02:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002751
2020-10-13 13:02:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29275.6015625Mb; avail=215252.55078125Mb
2020-10-13 13:02:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.284753
2020-10-13 13:02:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29291.50390625Mb; avail=215236.6484375Mb
2020-10-13 13:02:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.260245
2020-10-13 13:02:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.549892
2020-10-13 13:02:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29309.16015625Mb; avail=215218.9921875Mb
2020-10-13 13:02:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=29310.4765625Mb; avail=215217.67578125Mb
2020-10-13 13:02:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003381
2020-10-13 13:02:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29310.4765625Mb; avail=215217.67578125Mb
2020-10-13 13:02:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.305499
2020-10-13 13:02:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29012.6953125Mb; avail=215515.47265625Mb
2020-10-13 13:02:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.225759
2020-10-13 13:02:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.537080
2020-10-13 13:02:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29036.875Mb; avail=215491.29296875Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:02:37 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 4.453 | nll_loss 2.729 | ppl 6.63 | wps 78034.6 | wpb 5051.4 | bsz 192.5 | num_updates 21556 | best_loss 4.453
2020-10-13 13:02:37 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:02:43 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/checkpoint_best.pt (epoch 34 @ 21556 updates, score 4.453) (writing took 6.246816266095266 seconds)
2020-10-13 13:02:43 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2020-10-13 13:02:43 | INFO | train | epoch 034 | loss 3.974 | nll_loss 2.301 | ppl 4.93 | wps 35192.9 | ups 2.23 | wpb 15785.1 | bsz 594.2 | num_updates 21556 | lr 8.61541e-05 | gnorm 0.703 | clip 0 | train_wall 246 | wall 9337
2020-10-13 13:02:43 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=35/shard_epoch=34
2020-10-13 13:02:43 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=35/shard_epoch=35
2020-10-13 13:02:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=29060.35546875Mb; avail=215467.546875Mb
2020-10-13 13:02:44 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.006194
2020-10-13 13:02:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.087951
2020-10-13 13:02:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29071.69140625Mb; avail=215456.2109375Mb
2020-10-13 13:02:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.003906
2020-10-13 13:02:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29071.69140625Mb; avail=215456.2109375Mb
2020-10-13 13:02:46 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.963776
2020-10-13 13:02:46 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.056646
2020-10-13 13:02:46 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29165.84765625Mb; avail=215362.125Mb
2020-10-13 13:02:46 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=29152.37890625Mb; avail=215375.59375Mb
2020-10-13 13:02:46 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.090528
2020-10-13 13:02:46 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29153.92578125Mb; avail=215374.51171875Mb
2020-10-13 13:02:46 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.004321
2020-10-13 13:02:46 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29153.92578125Mb; avail=215374.51171875Mb
2020-10-13 13:02:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.143527
2020-10-13 13:02:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.239523
2020-10-13 13:02:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28870.0703125Mb; avail=215657.6796875Mb
2020-10-13 13:02:48 | INFO | fairseq.trainer | begin training epoch 35
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:03:11 | INFO | train_inner | epoch 035:     44 / 634 loss=3.945, nll_loss=2.269, ppl=4.82, wps=24299.8, ups=1.54, wpb=15813.3, bsz=616.3, num_updates=21600, lr=8.60663e-05, gnorm=0.697, clip=0, train_wall=39, wall=9364
2020-10-13 13:03:52 | INFO | train_inner | epoch 035:    144 / 634 loss=3.942, nll_loss=2.265, ppl=4.81, wps=38167.5, ups=2.43, wpb=15676.3, bsz=587.5, num_updates=21700, lr=8.58678e-05, gnorm=0.705, clip=0, train_wall=39, wall=9405
2020-10-13 13:04:33 | INFO | train_inner | epoch 035:    244 / 634 loss=3.947, nll_loss=2.271, ppl=4.83, wps=38691.9, ups=2.42, wpb=16006.9, bsz=607.7, num_updates=21800, lr=8.56706e-05, gnorm=0.706, clip=0, train_wall=39, wall=9446
2020-10-13 13:05:14 | INFO | train_inner | epoch 035:    344 / 634 loss=3.968, nll_loss=2.293, ppl=4.9, wps=38455.7, ups=2.43, wpb=15851.8, bsz=580.1, num_updates=21900, lr=8.54748e-05, gnorm=0.7, clip=0, train_wall=39, wall=9487
2020-10-13 13:05:56 | INFO | train_inner | epoch 035:    444 / 634 loss=3.948, nll_loss=2.271, ppl=4.83, wps=38458.2, ups=2.42, wpb=15924, bsz=626.8, num_updates=22000, lr=8.52803e-05, gnorm=0.706, clip=0, train_wall=39, wall=9529
2020-10-13 13:06:37 | INFO | train_inner | epoch 035:    544 / 634 loss=3.971, nll_loss=2.296, ppl=4.91, wps=37777.9, ups=2.43, wpb=15525.7, bsz=575, num_updates=22100, lr=8.50871e-05, gnorm=0.722, clip=0, train_wall=39, wall=9570
2020-10-13 13:07:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 13:07:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=29071.09765625Mb; avail=215456.66015625Mb
2020-10-13 13:07:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002164
2020-10-13 13:07:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29071.09765625Mb; avail=215456.66015625Mb
2020-10-13 13:07:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.132162
2020-10-13 13:07:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29071.09765625Mb; avail=215456.66015625Mb
2020-10-13 13:07:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.099422
2020-10-13 13:07:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.234869
2020-10-13 13:07:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29071.09765625Mb; avail=215456.66015625Mb
2020-10-13 13:07:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=29071.09765625Mb; avail=215456.66015625Mb
2020-10-13 13:07:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003007
2020-10-13 13:07:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29071.09765625Mb; avail=215456.66015625Mb
2020-10-13 13:07:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.303465
2020-10-13 13:07:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29083.40234375Mb; avail=215443.87109375Mb
2020-10-13 13:07:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.106769
2020-10-13 13:07:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.414656
2020-10-13 13:07:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29082.546875Mb; avail=215445.421875Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:07:22 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 4.456 | nll_loss 2.738 | ppl 6.67 | wps 59457.1 | wpb 5051.4 | bsz 192.5 | num_updates 22190 | best_loss 4.453
2020-10-13 13:07:22 | INFO | fairseq_cli.train | begin save checkpoint
2020-10-13 13:07:26 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/checkpoint_last.pt (epoch 35 @ 22190 updates, score 4.456) (writing took 3.526660099159926 seconds)
2020-10-13 13:07:26 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2020-10-13 13:07:26 | INFO | train | epoch 035 | loss 3.956 | nll_loss 2.28 | ppl 4.86 | wps 35392.5 | ups 2.24 | wpb 15785.1 | bsz 594.2 | num_updates 22190 | lr 8.49144e-05 | gnorm 0.711 | clip 0 | train_wall 246 | wall 9619
2020-10-13 13:07:26 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=36/shard_epoch=35
2020-10-13 13:07:26 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=36/shard_epoch=36
2020-10-13 13:07:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28598.99609375Mb; avail=215928.8984375Mb
2020-10-13 13:07:26 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.013480
2020-10-13 13:07:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.124236
2020-10-13 13:07:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28600.72265625Mb; avail=215927.171875Mb
2020-10-13 13:07:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.003895
2020-10-13 13:07:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28600.72265625Mb; avail=215927.171875Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:07:28 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.999754
2020-10-13 13:07:28 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.128970
2020-10-13 13:07:28 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28683.1015625Mb; avail=215844.62890625Mb
2020-10-13 13:07:28 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28680.9375Mb; avail=215847.25390625Mb
2020-10-13 13:07:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.086550
2020-10-13 13:07:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28670.70703125Mb; avail=215857.484375Mb
2020-10-13 13:07:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.004485
2020-10-13 13:07:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28670.828125Mb; avail=215857.36328125Mb
2020-10-13 13:07:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.358385
2020-10-13 13:07:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.450691
2020-10-13 13:07:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29207.3984375Mb; avail=215320.77734375Mb
2020-10-13 13:07:31 | INFO | fairseq.trainer | begin training epoch 36
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:07:40 | INFO | train_inner | epoch 036:     10 / 634 loss=3.961, nll_loss=2.286, ppl=4.88, wps=24774.6, ups=1.58, wpb=15656.4, bsz=586.6, num_updates=22200, lr=8.48953e-05, gnorm=0.729, clip=0, train_wall=39, wall=9633
2020-10-13 13:08:21 | INFO | train_inner | epoch 036:    110 / 634 loss=3.919, nll_loss=2.238, ppl=4.72, wps=38243.5, ups=2.44, wpb=15704, bsz=591.9, num_updates=22300, lr=8.47047e-05, gnorm=0.708, clip=0, train_wall=39, wall=9674
2020-10-13 13:09:02 | INFO | train_inner | epoch 036:    210 / 634 loss=3.925, nll_loss=2.245, ppl=4.74, wps=38489.4, ups=2.44, wpb=15805.1, bsz=606.2, num_updates=22400, lr=8.45154e-05, gnorm=0.716, clip=0, train_wall=39, wall=9715
2020-10-13 13:09:43 | INFO | train_inner | epoch 036:    310 / 634 loss=3.95, nll_loss=2.273, ppl=4.83, wps=38556.5, ups=2.44, wpb=15830.5, bsz=567.1, num_updates=22500, lr=8.43274e-05, gnorm=0.712, clip=0, train_wall=39, wall=9756
2020-10-13 13:10:24 | INFO | train_inner | epoch 036:    410 / 634 loss=3.932, nll_loss=2.253, ppl=4.77, wps=38770.4, ups=2.43, wpb=15971.1, bsz=611.6, num_updates=22600, lr=8.41406e-05, gnorm=0.708, clip=0, train_wall=39, wall=9797
2020-10-13 13:11:05 | INFO | train_inner | epoch 036:    510 / 634 loss=3.952, nll_loss=2.276, ppl=4.84, wps=38069.1, ups=2.43, wpb=15655.8, bsz=587, num_updates=22700, lr=8.39551e-05, gnorm=0.71, clip=0, train_wall=39, wall=9839
2020-10-13 13:11:46 | INFO | train_inner | epoch 036:    610 / 634 loss=3.952, nll_loss=2.276, ppl=4.84, wps=38529.7, ups=2.44, wpb=15811.8, bsz=592, num_updates=22800, lr=8.37708e-05, gnorm=0.714, clip=0, train_wall=39, wall=9880
2020-10-13 13:11:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 13:11:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=29083.9140625Mb; avail=215443.82421875Mb
2020-10-13 13:11:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003042
2020-10-13 13:11:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29083.9140625Mb; avail=215443.82421875Mb
2020-10-13 13:11:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.291754
2020-10-13 13:11:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29093.6015625Mb; avail=215434.13671875Mb
2020-10-13 13:11:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.141111
2020-10-13 13:11:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.437410
2020-10-13 13:11:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29083.015625Mb; avail=215444.72265625Mb
2020-10-13 13:11:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=29083.015625Mb; avail=215444.72265625Mb
2020-10-13 13:11:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001864
2020-10-13 13:11:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29083.015625Mb; avail=215444.72265625Mb
2020-10-13 13:11:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.129951
2020-10-13 13:11:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29083.015625Mb; avail=215444.72265625Mb
2020-10-13 13:11:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.098087
2020-10-13 13:11:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.230963
2020-10-13 13:11:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29083.015625Mb; avail=215444.72265625Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:12:05 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 4.441 | nll_loss 2.721 | ppl 6.59 | wps 67984.2 | wpb 5051.4 | bsz 192.5 | num_updates 22824 | best_loss 4.441
2020-10-13 13:12:05 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:12:11 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/checkpoint_best.pt (epoch 36 @ 22824 updates, score 4.441) (writing took 6.172527658985928 seconds)
2020-10-13 13:12:11 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2020-10-13 13:12:11 | INFO | train | epoch 036 | loss 3.937 | nll_loss 2.259 | ppl 4.79 | wps 35115.6 | ups 2.22 | wpb 15785.1 | bsz 594.2 | num_updates 22824 | lr 8.37267e-05 | gnorm 0.71 | clip 0 | train_wall 246 | wall 9904
2020-10-13 13:12:11 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=37/shard_epoch=36
2020-10-13 13:12:11 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=37/shard_epoch=37
2020-10-13 13:12:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28660.91796875Mb; avail=215867.08203125Mb
2020-10-13 13:12:11 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.013090
2020-10-13 13:12:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.142961
2020-10-13 13:12:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28666.1796875Mb; avail=215862.0859375Mb
2020-10-13 13:12:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.007346
2020-10-13 13:12:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28666.1953125Mb; avail=215861.828125Mb
2020-10-13 13:12:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.855314
2020-10-13 13:12:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:03.007403
2020-10-13 13:12:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29258.609375Mb; avail=215268.2890625Mb
2020-10-13 13:12:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=29286.671875Mb; avail=215241.2421875Mb
2020-10-13 13:12:15 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.112957
2020-10-13 13:12:15 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29301.73046875Mb; avail=215226.72265625Mb
2020-10-13 13:12:15 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.008377
2020-10-13 13:12:15 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29304.7421875Mb; avail=215223.7109375Mb
2020-10-13 13:12:17 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.834838
2020-10-13 13:12:17 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.957962
2020-10-13 13:12:17 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29369.09765625Mb; avail=215158.81640625Mb
2020-10-13 13:12:17 | INFO | fairseq.trainer | begin training epoch 37
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:12:53 | INFO | train_inner | epoch 037:     76 / 634 loss=3.903, nll_loss=2.22, ppl=4.66, wps=23823.3, ups=1.51, wpb=15801.6, bsz=596.5, num_updates=22900, lr=8.35877e-05, gnorm=0.675, clip=0, train_wall=39, wall=9946
2020-10-13 13:13:34 | INFO | train_inner | epoch 037:    176 / 634 loss=3.887, nll_loss=2.203, ppl=4.6, wps=38498.3, ups=2.41, wpb=15972.6, bsz=640.3, num_updates=23000, lr=8.34058e-05, gnorm=0.685, clip=0, train_wall=39, wall=9987
2020-10-13 13:14:14 | INFO | train_inner | epoch 037:    276 / 634 loss=3.933, nll_loss=2.254, ppl=4.77, wps=40057.6, ups=2.55, wpb=15726, bsz=550.5, num_updates=23100, lr=8.3225e-05, gnorm=0.699, clip=0, train_wall=37, wall=10027
2020-10-13 13:14:50 | INFO | train_inner | epoch 037:    376 / 634 loss=3.931, nll_loss=2.252, ppl=4.76, wps=42075.1, ups=2.71, wpb=15540.4, bsz=570.4, num_updates=23200, lr=8.30455e-05, gnorm=0.718, clip=0, train_wall=35, wall=10064
2020-10-13 13:15:30 | INFO | train_inner | epoch 037:    476 / 634 loss=3.921, nll_loss=2.241, ppl=4.73, wps=40067.2, ups=2.52, wpb=15882.2, bsz=623.6, num_updates=23300, lr=8.28671e-05, gnorm=0.706, clip=0, train_wall=37, wall=10103
2020-10-13 13:16:11 | INFO | train_inner | epoch 037:    576 / 634 loss=3.925, nll_loss=2.245, ppl=4.74, wps=39045, ups=2.45, wpb=15914.9, bsz=604.6, num_updates=23400, lr=8.26898e-05, gnorm=0.704, clip=0, train_wall=38, wall=10144
2020-10-13 13:16:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 13:16:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28963.46875Mb; avail=215564.1640625Mb
2020-10-13 13:16:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002127
2020-10-13 13:16:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28963.46875Mb; avail=215564.1640625Mb
2020-10-13 13:16:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.150471
2020-10-13 13:16:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28968.22265625Mb; avail=215559.41015625Mb
2020-10-13 13:16:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.172191
2020-10-13 13:16:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.326202
2020-10-13 13:16:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28964.4296875Mb; avail=215563.203125Mb
2020-10-13 13:16:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28964.4296875Mb; avail=215563.203125Mb
2020-10-13 13:16:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003102
2020-10-13 13:16:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28964.4296875Mb; avail=215563.203125Mb
2020-10-13 13:16:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.217467
2020-10-13 13:16:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28888.80859375Mb; avail=215638.82421875Mb
2020-10-13 13:16:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.105524
2020-10-13 13:16:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.328136
2020-10-13 13:16:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28884.37109375Mb; avail=215642.9375Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:16:43 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 4.444 | nll_loss 2.722 | ppl 6.6 | wps 69220.6 | wpb 5051.4 | bsz 192.5 | num_updates 23458 | best_loss 4.441
2020-10-13 13:16:43 | INFO | fairseq_cli.train | begin save checkpoint
2020-10-13 13:16:47 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/checkpoint_last.pt (epoch 37 @ 23458 updates, score 4.444) (writing took 4.041434048907831 seconds)
2020-10-13 13:16:47 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2020-10-13 13:16:47 | INFO | train | epoch 037 | loss 3.919 | nll_loss 2.238 | ppl 4.72 | wps 36237.7 | ups 2.3 | wpb 15785.1 | bsz 594.2 | num_updates 23458 | lr 8.25875e-05 | gnorm 0.702 | clip 0 | train_wall 240 | wall 10181
2020-10-13 13:16:47 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=38/shard_epoch=37
2020-10-13 13:16:47 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=38/shard_epoch=38
2020-10-13 13:16:47 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28508.125Mb; avail=216019.76171875Mb
2020-10-13 13:16:47 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.013229
2020-10-13 13:16:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.143838
2020-10-13 13:16:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28547.7734375Mb; avail=215980.1640625Mb
2020-10-13 13:16:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.007915
2020-10-13 13:16:48 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28547.7734375Mb; avail=215980.1640625Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:16:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.387995
2020-10-13 13:16:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.541489
2020-10-13 13:16:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29333.73046875Mb; avail=215194.359375Mb
2020-10-13 13:16:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=29343.97265625Mb; avail=215184.1171875Mb
2020-10-13 13:16:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.089133
2020-10-13 13:16:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29355.22265625Mb; avail=215172.7578125Mb
2020-10-13 13:16:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.004160
2020-10-13 13:16:50 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29355.46484375Mb; avail=215172.515625Mb
2020-10-13 13:16:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.720954
2020-10-13 13:16:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.815566
2020-10-13 13:16:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29422.49609375Mb; avail=215105.64453125Mb
2020-10-13 13:16:52 | INFO | fairseq.trainer | begin training epoch 38
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:17:14 | INFO | train_inner | epoch 038:     42 / 634 loss=3.909, nll_loss=2.227, ppl=4.68, wps=24971.8, ups=1.59, wpb=15705.7, bsz=599.8, num_updates=23500, lr=8.25137e-05, gnorm=0.712, clip=0, train_wall=39, wall=10207
2020-10-13 13:17:55 | INFO | train_inner | epoch 038:    142 / 634 loss=3.902, nll_loss=2.218, ppl=4.65, wps=38653.3, ups=2.44, wpb=15857.5, bsz=573.9, num_updates=23600, lr=8.23387e-05, gnorm=0.721, clip=0, train_wall=39, wall=10248
2020-10-13 13:18:36 | INFO | train_inner | epoch 038:    242 / 634 loss=3.884, nll_loss=2.198, ppl=4.59, wps=38398.9, ups=2.42, wpb=15861.4, bsz=620.6, num_updates=23700, lr=8.21648e-05, gnorm=0.711, clip=0, train_wall=39, wall=10289
2020-10-13 13:19:18 | INFO | train_inner | epoch 038:    342 / 634 loss=3.905, nll_loss=2.222, ppl=4.67, wps=37395.7, ups=2.41, wpb=15492, bsz=605.8, num_updates=23800, lr=8.1992e-05, gnorm=0.736, clip=0, train_wall=39, wall=10331
2020-10-13 13:19:59 | INFO | train_inner | epoch 038:    442 / 634 loss=3.903, nll_loss=2.22, ppl=4.66, wps=38212.8, ups=2.42, wpb=15793.6, bsz=587.7, num_updates=23900, lr=8.18203e-05, gnorm=0.709, clip=0, train_wall=39, wall=10372
2020-10-13 13:20:40 | INFO | train_inner | epoch 038:    542 / 634 loss=3.912, nll_loss=2.23, ppl=4.69, wps=38921.7, ups=2.43, wpb=16013.5, bsz=601.8, num_updates=24000, lr=8.16497e-05, gnorm=0.696, clip=0, train_wall=39, wall=10413
2020-10-13 13:21:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 13:21:18 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=29763.5859375Mb; avail=214763.75390625Mb
2020-10-13 13:21:18 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003099
2020-10-13 13:21:18 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29763.5859375Mb; avail=214763.75390625Mb
2020-10-13 13:21:18 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.290736
2020-10-13 13:21:18 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29774.0078125Mb; avail=214753.53515625Mb
2020-10-13 13:21:18 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.215087
2020-10-13 13:21:18 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.510615
2020-10-13 13:21:18 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29766.6015625Mb; avail=214760.9453125Mb
2020-10-13 13:21:18 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=29766.46875Mb; avail=214761.203125Mb
2020-10-13 13:21:18 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003011
2020-10-13 13:21:18 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29766.46875Mb; avail=214761.203125Mb
2020-10-13 13:21:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.292691
2020-10-13 13:21:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29787.92578125Mb; avail=214739.60546875Mb
2020-10-13 13:21:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.207905
2020-10-13 13:21:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.505255
2020-10-13 13:21:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29796.58984375Mb; avail=214730.94140625Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:21:27 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 4.442 | nll_loss 2.72 | ppl 6.59 | wps 71144.1 | wpb 5051.4 | bsz 192.5 | num_updates 24092 | best_loss 4.441
2020-10-13 13:21:27 | INFO | fairseq_cli.train | begin save checkpoint
2020-10-13 13:21:30 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/checkpoint_last.pt (epoch 38 @ 24092 updates, score 4.442) (writing took 3.629551772028208 seconds)
2020-10-13 13:21:31 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2020-10-13 13:21:31 | INFO | train | epoch 038 | loss 3.903 | nll_loss 2.219 | ppl 4.66 | wps 35319.3 | ups 2.24 | wpb 15785.1 | bsz 594.2 | num_updates 24092 | lr 8.14936e-05 | gnorm 0.712 | clip 0 | train_wall 247 | wall 10464
2020-10-13 13:21:31 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=39/shard_epoch=38
2020-10-13 13:21:31 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=39/shard_epoch=39
2020-10-13 13:21:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28407.9375Mb; avail=216120.265625Mb
2020-10-13 13:21:31 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.012532
2020-10-13 13:21:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.150618
2020-10-13 13:21:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28417.4453125Mb; avail=216110.7578125Mb
2020-10-13 13:21:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.006850
2020-10-13 13:21:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28420.47265625Mb; avail=216107.73046875Mb
2020-10-13 13:21:33 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.073509
2020-10-13 13:21:33 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.232716
2020-10-13 13:21:33 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28441.9765625Mb; avail=216086.1015625Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:21:33 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28447.65234375Mb; avail=216080.42578125Mb
2020-10-13 13:21:33 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.088169
2020-10-13 13:21:33 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28453.84765625Mb; avail=216074.13671875Mb
2020-10-13 13:21:33 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.004081
2020-10-13 13:21:33 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28453.84765625Mb; avail=216074.13671875Mb
2020-10-13 13:21:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:03.248433
2020-10-13 13:21:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:03.341777
2020-10-13 13:21:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28571.09765625Mb; avail=215958.00390625Mb
2020-10-13 13:21:36 | INFO | fairseq.trainer | begin training epoch 39
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:21:44 | INFO | train_inner | epoch 039:      8 / 634 loss=3.925, nll_loss=2.245, ppl=4.74, wps=24267.2, ups=1.55, wpb=15637.7, bsz=558.9, num_updates=24100, lr=8.14801e-05, gnorm=0.713, clip=0, train_wall=39, wall=10478
2020-10-13 13:22:25 | INFO | train_inner | epoch 039:    108 / 634 loss=3.868, nll_loss=2.18, ppl=4.53, wps=38465.7, ups=2.44, wpb=15754.1, bsz=600.7, num_updates=24200, lr=8.13116e-05, gnorm=0.705, clip=0, train_wall=39, wall=10518
2020-10-13 13:23:07 | INFO | train_inner | epoch 039:    208 / 634 loss=3.885, nll_loss=2.199, ppl=4.59, wps=38412.5, ups=2.42, wpb=15847.3, bsz=596.6, num_updates=24300, lr=8.11441e-05, gnorm=0.714, clip=0, train_wall=39, wall=10560
2020-10-13 13:23:48 | INFO | train_inner | epoch 039:    308 / 634 loss=3.886, nll_loss=2.201, ppl=4.6, wps=38425.2, ups=2.43, wpb=15828.9, bsz=578, num_updates=24400, lr=8.09776e-05, gnorm=0.705, clip=0, train_wall=39, wall=10601
2020-10-13 13:24:29 | INFO | train_inner | epoch 039:    408 / 634 loss=3.889, nll_loss=2.204, ppl=4.61, wps=38283.5, ups=2.41, wpb=15895.9, bsz=613.4, num_updates=24500, lr=8.08122e-05, gnorm=0.704, clip=0, train_wall=39, wall=10642
2020-10-13 13:25:10 | INFO | train_inner | epoch 039:    508 / 634 loss=3.903, nll_loss=2.219, ppl=4.66, wps=38622.1, ups=2.45, wpb=15785.4, bsz=572.9, num_updates=24600, lr=8.06478e-05, gnorm=0.721, clip=0, train_wall=39, wall=10683
2020-10-13 13:25:51 | INFO | train_inner | epoch 039:    608 / 634 loss=3.883, nll_loss=2.198, ppl=4.59, wps=37941.3, ups=2.43, wpb=15606.3, bsz=607.4, num_updates=24700, lr=8.04844e-05, gnorm=0.722, clip=0, train_wall=39, wall=10724
2020-10-13 13:26:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 13:26:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28835.92578125Mb; avail=215691.1015625Mb
2020-10-13 13:26:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003110
2020-10-13 13:26:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28835.92578125Mb; avail=215691.1015625Mb
2020-10-13 13:26:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.303262
2020-10-13 13:26:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28836.453125Mb; avail=215690.90625Mb
2020-10-13 13:26:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.223375
2020-10-13 13:26:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.531457
2020-10-13 13:26:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28835.71875Mb; avail=215691.80859375Mb
2020-10-13 13:26:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28835.71875Mb; avail=215691.80859375Mb
2020-10-13 13:26:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002691
2020-10-13 13:26:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28835.71875Mb; avail=215691.80859375Mb
2020-10-13 13:26:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.274979
2020-10-13 13:26:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28849.76953125Mb; avail=215677.71484375Mb
2020-10-13 13:26:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.109915
2020-10-13 13:26:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.388981
2020-10-13 13:26:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28866.33984375Mb; avail=215660.41015625Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:26:11 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 4.45 | nll_loss 2.729 | ppl 6.63 | wps 73072.9 | wpb 5051.4 | bsz 192.5 | num_updates 24726 | best_loss 4.441
2020-10-13 13:26:11 | INFO | fairseq_cli.train | begin save checkpoint
2020-10-13 13:26:15 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/checkpoint_last.pt (epoch 39 @ 24726 updates, score 4.45) (writing took 4.064948183950037 seconds)
2020-10-13 13:26:15 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2020-10-13 13:26:15 | INFO | train | epoch 039 | loss 3.886 | nll_loss 2.201 | ppl 4.6 | wps 35159.2 | ups 2.23 | wpb 15785.1 | bsz 594.2 | num_updates 24726 | lr 8.0442e-05 | gnorm 0.712 | clip 0 | train_wall 246 | wall 10749
2020-10-13 13:26:15 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=40/shard_epoch=39
2020-10-13 13:26:15 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=40/shard_epoch=40
2020-10-13 13:26:15 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28654.3359375Mb; avail=215873.22265625Mb
2020-10-13 13:26:15 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.010830
2020-10-13 13:26:16 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.114040
2020-10-13 13:26:16 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28817.73046875Mb; avail=215710.7109375Mb
2020-10-13 13:26:16 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.004261
2020-10-13 13:26:16 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28821.36328125Mb; avail=215707.078125Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:26:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:03.119941
2020-10-13 13:26:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:03.239495
2020-10-13 13:26:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29444.64453125Mb; avail=215083.4296875Mb
2020-10-13 13:26:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=29443.35546875Mb; avail=215084.71875Mb
2020-10-13 13:26:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.091050
2020-10-13 13:26:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29446.98828125Mb; avail=215080.48046875Mb
2020-10-13 13:26:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.007649
2020-10-13 13:26:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29447.59375Mb; avail=215080.48046875Mb
2020-10-13 13:26:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.391209
2020-10-13 13:26:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.491487
2020-10-13 13:26:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28577.51171875Mb; avail=215950.15234375Mb
2020-10-13 13:26:21 | INFO | fairseq.trainer | begin training epoch 40
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:26:56 | INFO | train_inner | epoch 040:     74 / 634 loss=3.873, nll_loss=2.185, ppl=4.55, wps=24356.9, ups=1.55, wpb=15740.5, bsz=586.2, num_updates=24800, lr=8.03219e-05, gnorm=0.717, clip=0, train_wall=39, wall=10789
2020-10-13 13:27:37 | INFO | train_inner | epoch 040:    174 / 634 loss=3.873, nll_loss=2.185, ppl=4.55, wps=38945.5, ups=2.46, wpb=15807.1, bsz=586.1, num_updates=24900, lr=8.01605e-05, gnorm=0.725, clip=0, train_wall=38, wall=10830
2020-10-13 13:28:18 | INFO | train_inner | epoch 040:    274 / 634 loss=3.874, nll_loss=2.187, ppl=4.55, wps=38403.4, ups=2.44, wpb=15765.1, bsz=597.4, num_updates=25000, lr=8e-05, gnorm=0.705, clip=0, train_wall=39, wall=10871
2020-10-13 13:28:59 | INFO | train_inner | epoch 040:    374 / 634 loss=3.875, nll_loss=2.187, ppl=4.55, wps=38410.2, ups=2.42, wpb=15858.5, bsz=581.9, num_updates=25100, lr=7.98405e-05, gnorm=0.703, clip=0, train_wall=39, wall=10912
2020-10-13 13:29:40 | INFO | train_inner | epoch 040:    474 / 634 loss=3.842, nll_loss=2.151, ppl=4.44, wps=38384.4, ups=2.42, wpb=15882.3, bsz=646, num_updates=25200, lr=7.96819e-05, gnorm=0.697, clip=0, train_wall=39, wall=10953
2020-10-13 13:30:22 | INFO | train_inner | epoch 040:    574 / 634 loss=3.877, nll_loss=2.19, ppl=4.56, wps=37971.6, ups=2.41, wpb=15727.1, bsz=587.4, num_updates=25300, lr=7.95243e-05, gnorm=0.701, clip=0, train_wall=39, wall=10995
2020-10-13 13:30:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 13:30:46 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28842.046875Mb; avail=215685.03125Mb
2020-10-13 13:30:46 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002140
2020-10-13 13:30:46 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28842.046875Mb; avail=215685.03125Mb
2020-10-13 13:30:47 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.144395
2020-10-13 13:30:47 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28842.0390625Mb; avail=215685.0390625Mb
2020-10-13 13:30:47 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.109340
2020-10-13 13:30:47 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.257223
2020-10-13 13:30:47 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28842.0390625Mb; avail=215685.0390625Mb
2020-10-13 13:30:47 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28862.01953125Mb; avail=215665.05859375Mb
2020-10-13 13:30:47 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002601
2020-10-13 13:30:47 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28862.01953125Mb; avail=215665.05859375Mb
2020-10-13 13:30:47 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.142003
2020-10-13 13:30:47 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28874.203125Mb; avail=215653.3359375Mb
2020-10-13 13:30:47 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.110638
2020-10-13 13:30:47 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.257019
2020-10-13 13:30:47 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28879.62890625Mb; avail=215647.91015625Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:30:55 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 4.444 | nll_loss 2.726 | ppl 6.62 | wps 70043.1 | wpb 5051.4 | bsz 192.5 | num_updates 25360 | best_loss 4.441
2020-10-13 13:30:55 | INFO | fairseq_cli.train | begin save checkpoint
2020-10-13 13:30:59 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_azeazpturtup_sepspm8000/M2O/checkpoint_last.pt (epoch 40 @ 25360 updates, score 4.444) (writing took 3.709389752941206 seconds)
2020-10-13 13:30:59 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2020-10-13 13:30:59 | INFO | train | epoch 040 | loss 3.87 | nll_loss 2.182 | ppl 4.54 | wps 35244.2 | ups 2.23 | wpb 15785.1 | bsz 594.2 | num_updates 25360 | lr 7.94301e-05 | gnorm 0.709 | clip 0 | train_wall 246 | wall 11032
2020-10-13 13:30:59 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=41/shard_epoch=40
2020-10-13 13:30:59 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=41/shard_epoch=41
2020-10-13 13:30:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=25565.0625Mb; avail=218974.30859375Mb
2020-10-13 13:30:59 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.012776
2020-10-13 13:31:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.148744
2020-10-13 13:31:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=25570.7890625Mb; avail=218968.83984375Mb
2020-10-13 13:31:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.006799
2020-10-13 13:31:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=25570.7890625Mb; avail=218968.83984375Mb
2020-10-13 13:31:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.660318
2020-10-13 13:31:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.817552
2020-10-13 13:31:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=25570.140625Mb; avail=218969.82421875Mb
2020-10-13 13:31:02 | INFO | fairseq_cli.train | done training in 11033.6 seconds
/home/ubuntu/anaconda3/envs/torch16/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 160 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
