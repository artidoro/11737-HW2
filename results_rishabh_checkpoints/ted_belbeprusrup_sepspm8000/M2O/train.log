Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:27:40 | INFO | fairseq.distributed_utils | distributed init (rank 1): tcp://localhost:17160
2020-10-13 10:27:40 | INFO | fairseq.distributed_utils | distributed init (rank 0): tcp://localhost:17160
2020-10-13 10:27:41 | INFO | fairseq.distributed_utils | initialized host ip-172-31-31-6 as rank 1
2020-10-13 10:27:41 | INFO | fairseq.distributed_utils | initialized host ip-172-31-31-6 as rank 0
2020-10-13 10:27:45 | WARNING | fairseq.data.multilingual.multilingual_data_manager | External language dictionary is not provided; use lang-pairs to infer the set of supported languages. The language ordering is not stable which might cause misalignment in pretraining and finetuning.
2020-10-13 10:27:45 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_iwslt_de_en', attention_dropout=0.0, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', clip_norm=25.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='fairseq/data-bin/ted_belbeprusrup_sepspm8000/M2O/', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_langtok=False, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method='tcp://localhost:17160', distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, enable_lang_ids=False, enable_reservsed_directions_shared_datasets=False, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_langtok=None, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, extra_data=None, extra_lang_pairs=None, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', keep_best_checkpoints=-1, keep_inference_langtok=False, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, lang_dict=None, lang_pairs='bel-eng,rus-eng,bep-eng,rup-eng', lang_tok_replacing_bos_eos=False, lang_tok_style='multilingual', langs=None, langtoks=None, langtoks_specs=['main'], layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, local_rank=0, localsgd_frequency=3, log_format=None, log_interval=100, lr=[0.0002], lr_scheduler='inverse_sqrt', max_epoch=40, max_source_positions=1024, max_target_positions=1024, max_tokens=4500, max_tokens_valid=4500, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', sampling_method='concat', sampling_temperature=1.5, sampling_weights=None, sampling_weights_from_file=None, save_dir='fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/', save_interval=1, save_interval_updates=0, scoring='bleu', seed=2, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0, target_lang=None, task='translation_multi_simple_epoch', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[2], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, virtual_data_size=None, virtual_epoch_size=1000000, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0, zero_sharding='none')
2020-10-13 10:27:45 | WARNING | fairseq.data.multilingual.multilingual_data_manager | External language dictionary is not provided; use lang-pairs to infer the set of supported languages. The language ordering is not stable which might cause misalignment in pretraining and finetuning.
2020-10-13 10:27:45 | INFO | fairseq.data.multilingual.multilingual_data_manager | inferred language list: ['bel', 'bep', 'eng', 'rup', 'rus']
2020-10-13 10:27:46 | INFO | fairseq.data.multilingual.multilingual_data_manager | [bel] dictionary: 36181 types
2020-10-13 10:27:46 | INFO | fairseq.data.multilingual.multilingual_data_manager | [bep] dictionary: 36181 types
2020-10-13 10:27:46 | INFO | fairseq.data.multilingual.multilingual_data_manager | [eng] dictionary: 36181 types
2020-10-13 10:27:46 | INFO | fairseq.data.multilingual.multilingual_data_manager | [rup] dictionary: 36181 types
2020-10-13 10:27:46 | INFO | fairseq.data.multilingual.multilingual_data_manager | [rus] dictionary: 36181 types
2020-10-13 10:27:46 | INFO | fairseq.tasks.translation_multi_simple_epoch | loading data for valid epoch=1/None
2020-10-13 10:27:46 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=12267.0234375Mb; avail=232263.03125Mb
2020-10-13 10:27:46 | INFO | fairseq.data.multilingual.multilingual_data_manager | langtoks settings: {'main': (None, None)}
2020-10-13 10:27:46 | INFO | fairseq.data.multilingual.multilingual_data_manager | [valid] num of shards: {'main:bel-eng': 1, 'main:rus-eng': 1, 'main:bep-eng': 1, 'main:rup-eng': 1}
2020-10-13 10:27:46 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:bel-eng src_langtok: None; tgt_langtok: None
2020-10-13 10:27:46 | INFO | fairseq.data.data_utils | loaded 248 examples from: fairseq/data-bin/ted_belbeprusrup_sepspm8000/M2O/valid.bel-eng.bel
2020-10-13 10:27:46 | INFO | fairseq.data.data_utils | loaded 248 examples from: fairseq/data-bin/ted_belbeprusrup_sepspm8000/M2O/valid.bel-eng.eng
2020-10-13 10:27:46 | INFO | fairseq.data.multilingual.multilingual_data_manager | fairseq/data-bin/ted_belbeprusrup_sepspm8000/M2O/ valid bel-eng 248 examples
2020-10-13 10:27:46 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:rus-eng src_langtok: None; tgt_langtok: None
2020-10-13 10:27:46 | INFO | fairseq.data.data_utils | loaded 4814 examples from: fairseq/data-bin/ted_belbeprusrup_sepspm8000/M2O/valid.rus-eng.rus
2020-10-13 10:27:46 | INFO | fairseq.data.data_utils | loaded 4814 examples from: fairseq/data-bin/ted_belbeprusrup_sepspm8000/M2O/valid.rus-eng.eng
2020-10-13 10:27:46 | INFO | fairseq.data.multilingual.multilingual_data_manager | fairseq/data-bin/ted_belbeprusrup_sepspm8000/M2O/ valid rus-eng 4814 examples
2020-10-13 10:27:46 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:bep-eng src_langtok: None; tgt_langtok: None
2020-10-13 10:27:46 | INFO | fairseq.data.data_utils | loaded 248 examples from: fairseq/data-bin/ted_belbeprusrup_sepspm8000/M2O/valid.bep-eng.bep
2020-10-13 10:27:46 | INFO | fairseq.data.data_utils | loaded 248 examples from: fairseq/data-bin/ted_belbeprusrup_sepspm8000/M2O/valid.bep-eng.eng
2020-10-13 10:27:46 | INFO | fairseq.data.multilingual.multilingual_data_manager | fairseq/data-bin/ted_belbeprusrup_sepspm8000/M2O/ valid bep-eng 248 examples
2020-10-13 10:27:46 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:rup-eng src_langtok: None; tgt_langtok: None
2020-10-13 10:27:46 | INFO | fairseq.data.data_utils | loaded 4814 examples from: fairseq/data-bin/ted_belbeprusrup_sepspm8000/M2O/valid.rup-eng.rup
2020-10-13 10:27:46 | INFO | fairseq.data.data_utils | loaded 4814 examples from: fairseq/data-bin/ted_belbeprusrup_sepspm8000/M2O/valid.rup-eng.eng
2020-10-13 10:27:46 | INFO | fairseq.data.multilingual.multilingual_data_manager | fairseq/data-bin/ted_belbeprusrup_sepspm8000/M2O/ valid rup-eng 4814 examples
2020-10-13 10:27:47 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(36181, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(36181, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=36181, bias=False)
  )
)
2020-10-13 10:27:47 | INFO | fairseq_cli.train | task: translation_multi_simple_epoch (TranslationMultiSimpleEpochTask)
2020-10-13 10:27:47 | INFO | fairseq_cli.train | model: transformer_iwslt_de_en (TransformerModel)
2020-10-13 10:27:47 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2020-10-13 10:27:47 | INFO | fairseq_cli.train | num. model params: 50067968 (num. trained: 50067968)
2020-10-13 10:27:47 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2020-10-13 10:27:47 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2020-10-13 10:27:47 | INFO | fairseq.utils | ***********************CUDA enviroments for all 2 workers***********************
2020-10-13 10:27:47 | INFO | fairseq.utils | rank   0: capabilities =  7.0  ; total memory = 15.752 GB ; name = Tesla V100-SXM2-16GB                    
2020-10-13 10:27:47 | INFO | fairseq.utils | rank   1: capabilities =  7.0  ; total memory = 15.752 GB ; name = Tesla V100-SXM2-16GB                    
2020-10-13 10:27:47 | INFO | fairseq.utils | ***********************CUDA enviroments for all 2 workers***********************
2020-10-13 10:27:47 | INFO | fairseq_cli.train | training on 2 devices (GPUs/TPUs)
2020-10-13 10:27:47 | INFO | fairseq_cli.train | max tokens per GPU = 4500 and max sentences per GPU = None
2020-10-13 10:27:47 | INFO | fairseq.trainer | no existing checkpoint found fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/checkpoint_last.pt
2020-10-13 10:27:47 | INFO | fairseq.trainer | loading train data for epoch 1
2020-10-13 10:27:47 | INFO | fairseq.tasks.translation_multi_simple_epoch | loading data for train epoch=1/None
2020-10-13 10:27:47 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=12496.48046875Mb; avail=232033.27734375Mb
2020-10-13 10:27:47 | INFO | fairseq.data.multilingual.multilingual_data_manager | langtoks settings: {'main': (None, None)}
2020-10-13 10:27:47 | INFO | fairseq.data.multilingual.multilingual_data_manager | [train] num of shards: {'main:bel-eng': 1, 'main:rus-eng': 1, 'main:bep-eng': 1, 'main:rup-eng': 1}
2020-10-13 10:27:47 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:bel-eng src_langtok: None; tgt_langtok: None
2020-10-13 10:27:47 | INFO | fairseq.data.data_utils | loaded 4509 examples from: fairseq/data-bin/ted_belbeprusrup_sepspm8000/M2O/train.bel-eng.bel
2020-10-13 10:27:47 | INFO | fairseq.data.data_utils | loaded 4509 examples from: fairseq/data-bin/ted_belbeprusrup_sepspm8000/M2O/train.bel-eng.eng
2020-10-13 10:27:47 | INFO | fairseq.data.multilingual.multilingual_data_manager | fairseq/data-bin/ted_belbeprusrup_sepspm8000/M2O/ train bel-eng 4509 examples
2020-10-13 10:27:47 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:rus-eng src_langtok: None; tgt_langtok: None
2020-10-13 10:27:47 | INFO | fairseq.data.data_utils | loaded 208397 examples from: fairseq/data-bin/ted_belbeprusrup_sepspm8000/M2O/train.rus-eng.rus
2020-10-13 10:27:47 | INFO | fairseq.data.data_utils | loaded 208397 examples from: fairseq/data-bin/ted_belbeprusrup_sepspm8000/M2O/train.rus-eng.eng
2020-10-13 10:27:47 | INFO | fairseq.data.multilingual.multilingual_data_manager | fairseq/data-bin/ted_belbeprusrup_sepspm8000/M2O/ train rus-eng 208397 examples
2020-10-13 10:27:47 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:bep-eng src_langtok: None; tgt_langtok: None
2020-10-13 10:27:47 | INFO | fairseq.data.data_utils | loaded 4507 examples from: fairseq/data-bin/ted_belbeprusrup_sepspm8000/M2O/train.bep-eng.bep
2020-10-13 10:27:47 | INFO | fairseq.data.data_utils | loaded 4507 examples from: fairseq/data-bin/ted_belbeprusrup_sepspm8000/M2O/train.bep-eng.eng
2020-10-13 10:27:47 | INFO | fairseq.data.multilingual.multilingual_data_manager | fairseq/data-bin/ted_belbeprusrup_sepspm8000/M2O/ train bep-eng 4507 examples
2020-10-13 10:27:47 | INFO | fairseq.data.multilingual.multilingual_data_manager | main:rup-eng src_langtok: None; tgt_langtok: None
2020-10-13 10:27:47 | INFO | fairseq.data.data_utils | loaded 208378 examples from: fairseq/data-bin/ted_belbeprusrup_sepspm8000/M2O/train.rup-eng.rup
2020-10-13 10:27:47 | INFO | fairseq.data.data_utils | loaded 208378 examples from: fairseq/data-bin/ted_belbeprusrup_sepspm8000/M2O/train.rup-eng.eng
2020-10-13 10:27:47 | INFO | fairseq.data.multilingual.multilingual_data_manager | fairseq/data-bin/ted_belbeprusrup_sepspm8000/M2O/ train rup-eng 208378 examples
2020-10-13 10:27:47 | WARNING | fairseq.data.multilingual.sampled_multi_epoch_dataset | virtual epoch size 1000000 is greater than virtual dataset size 425791
2020-10-13 10:27:47 | INFO | fairseq.data.multilingual.multilingual_data_manager | estimated total data sizes of all shards used in sampling ratios: [('main:bel-eng', 4509), ('main:rus-eng', 208397), ('main:bep-eng', 4507), ('main:rup-eng', 208378)]. Note that if the data a shard has not been loaded yet, use the max known data size to approximate
2020-10-13 10:27:47 | INFO | fairseq.data.multilingual.sampling_method | selected sampler: concat
2020-10-13 10:27:47 | WARNING | fairseq.data.multilingual.sampled_multi_epoch_dataset | virtual epoch size 1000000 is greater than virtual dataset size 425791
2020-10-13 10:27:47 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | virtual epoch size 425791; virtual dataset size 425791
2020-10-13 10:27:47 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=1/shard_epoch=1
2020-10-13 10:27:47 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Raw sizes: {'main:bel-eng': 4509, 'main:rus-eng': 208397, 'main:bep-eng': 4507, 'main:rup-eng': 208378}; raw total size: 425791
2020-10-13 10:27:47 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] Resampled sizes: {'main:bel-eng': 4509, 'main:rus-eng': 208397, 'main:bep-eng': 4507, 'main:rup-eng': 208378}; resampled total size: 425791
2020-10-13 10:27:47 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] A concat dataset
2020-10-13 10:27:47 | INFO | fairseq.data.multilingual.sampled_multi_dataset | [train] virtual dataset established time: 0:00:00.052544
2020-10-13 10:27:47 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=12511.03125Mb; avail=232018.52734375Mb
2020-10-13 10:27:47 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.007984
2020-10-13 10:27:47 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.102035
2020-10-13 10:27:47 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=12547.71484375Mb; avail=231981.71484375Mb
2020-10-13 10:27:47 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.004344
2020-10-13 10:27:47 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=12547.69140625Mb; avail=231981.73828125Mb
2020-10-13 10:27:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.690635
2020-10-13 10:27:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.797915
2020-10-13 10:27:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=12550.52734375Mb; avail=231979.3359375Mb
2020-10-13 10:27:49 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16
2020-10-13 10:27:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=12541.78125Mb; avail=231988.08203125Mb
2020-10-13 10:27:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.077238
2020-10-13 10:27:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=12540.46875Mb; avail=231988.66015625Mb
2020-10-13 10:27:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.003350
2020-10-13 10:27:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=12540.46875Mb; avail=231988.66015625Mb
2020-10-13 10:27:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.686473
2020-10-13 10:27:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.767882
2020-10-13 10:27:51 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=12629.828125Mb; avail=231899.99609375Mb
2020-10-13 10:27:51 | INFO | fairseq.trainer | begin training epoch 1
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:28:30 | INFO | train_inner | epoch 001:    100 / 756 loss=14.741, nll_loss=14.615, ppl=25098.2, wps=43508.6, ups=2.82, wpb=15423.9, bsz=594.3, num_updates=100, lr=5.0975e-06, gnorm=4.461, clip=0, train_wall=35, wall=43
2020-10-13 10:29:05 | INFO | train_inner | epoch 001:    200 / 756 loss=13.007, nll_loss=12.683, ppl=6577.04, wps=42601.8, ups=2.87, wpb=14861, bsz=541.2, num_updates=200, lr=1.0095e-05, gnorm=1.924, clip=0, train_wall=33, wall=78
2020-10-13 10:29:40 | INFO | train_inner | epoch 001:    300 / 756 loss=12.02, nll_loss=11.581, ppl=3063.52, wps=43017.3, ups=2.85, wpb=15083.6, bsz=575.4, num_updates=300, lr=1.50925e-05, gnorm=1.586, clip=0, train_wall=34, wall=113
2020-10-13 10:30:15 | INFO | train_inner | epoch 001:    400 / 756 loss=10.728, nll_loss=10.11, ppl=1104.81, wps=43472.7, ups=2.84, wpb=15295.6, bsz=557.7, num_updates=400, lr=2.009e-05, gnorm=1.745, clip=0, train_wall=34, wall=148
2020-10-13 10:30:50 | INFO | train_inner | epoch 001:    500 / 756 loss=9.849, nll_loss=9.069, ppl=537.05, wps=42635.5, ups=2.84, wpb=14992.8, bsz=548.5, num_updates=500, lr=2.50875e-05, gnorm=1.154, clip=0, train_wall=34, wall=183
2020-10-13 10:31:26 | INFO | train_inner | epoch 001:    600 / 756 loss=9.381, nll_loss=8.489, ppl=359.39, wps=42802.5, ups=2.81, wpb=15211.5, bsz=562.3, num_updates=600, lr=3.0085e-05, gnorm=1.159, clip=0, train_wall=34, wall=219
2020-10-13 10:32:01 | INFO | train_inner | epoch 001:    700 / 756 loss=9.197, nll_loss=8.248, ppl=303.92, wps=43027.4, ups=2.82, wpb=15252.4, bsz=571.8, num_updates=700, lr=3.50825e-05, gnorm=1.235, clip=0, train_wall=34, wall=254
2020-10-13 10:32:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 10:32:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13381.8671875Mb; avail=231147.05859375Mb
2020-10-13 10:32:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001874
2020-10-13 10:32:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13381.8671875Mb; avail=231147.05859375Mb
2020-10-13 10:32:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.138597
2020-10-13 10:32:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13381.375Mb; avail=231147.55078125Mb
2020-10-13 10:32:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.103661
2020-10-13 10:32:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.244941
2020-10-13 10:32:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13381.375Mb; avail=231147.55078125Mb
2020-10-13 10:32:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13381.375Mb; avail=231147.55078125Mb
2020-10-13 10:32:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001761
2020-10-13 10:32:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13381.375Mb; avail=231147.55078125Mb
2020-10-13 10:32:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.140142
2020-10-13 10:32:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13381.38671875Mb; avail=231147.71875Mb
2020-10-13 10:32:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.098875
2020-10-13 10:32:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.241531
2020-10-13 10:32:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13381.984375Mb; avail=231147.85546875Mb
/home/ubuntu/courses/fairseq/fairseq/utils.py:340: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
/home/ubuntu/courses/fairseq/fairseq/utils.py:340: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:32:27 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 8.801 | nll_loss 7.736 | ppl 213.22 | wps 84216.6 | wpb 4934.1 | bsz 184.1 | num_updates 756
2020-10-13 10:32:27 | INFO | fairseq_cli.train | begin save checkpoint
2020-10-13 10:32:29 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/checkpoint_best.pt (epoch 1 @ 756 updates, score 8.801) (writing took 2.1375105981715024 seconds)
2020-10-13 10:32:30 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2020-10-13 10:32:30 | INFO | train | epoch 001 | loss 11.113 | nll_loss 10.495 | ppl 1443.56 | wps 41633 | ups 2.74 | wpb 15168.1 | bsz 563.1 | num_updates 756 | lr 3.78811e-05 | gnorm 1.841 | clip 0 | train_wall 256 | wall 283
2020-10-13 10:32:30 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=2/shard_epoch=1
2020-10-13 10:32:30 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=2/shard_epoch=2
2020-10-13 10:32:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=12937.69140625Mb; avail=231591.828125Mb
2020-10-13 10:32:30 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.008956
2020-10-13 10:32:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.091857
2020-10-13 10:32:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=12938.73828125Mb; avail=231590.78125Mb
2020-10-13 10:32:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.003274
2020-10-13 10:32:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=12938.73828125Mb; avail=231590.78125Mb
2020-10-13 10:32:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.561367
2020-10-13 10:32:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.657396
2020-10-13 10:32:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13015.91796875Mb; avail=231514.07421875Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:32:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13013.3046875Mb; avail=231516.6875Mb
2020-10-13 10:32:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.071234
2020-10-13 10:32:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13020.20703125Mb; avail=231509.78515625Mb
2020-10-13 10:32:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.003482
2020-10-13 10:32:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13020.8125Mb; avail=231509.1796875Mb
2020-10-13 10:32:33 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.551485
2020-10-13 10:32:33 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.627124
2020-10-13 10:32:33 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13135.3984375Mb; avail=231394.32421875Mb
2020-10-13 10:32:33 | INFO | fairseq.trainer | begin training epoch 2
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:32:52 | INFO | train_inner | epoch 002:     44 / 756 loss=9.067, nll_loss=8.09, ppl=272.45, wps=30182.1, ups=1.97, wpb=15356.1, bsz=543.8, num_updates=800, lr=4.008e-05, gnorm=1.208, clip=0, train_wall=34, wall=305
2020-10-13 10:33:28 | INFO | train_inner | epoch 002:    144 / 756 loss=8.806, nll_loss=7.792, ppl=221.64, wps=42363.7, ups=2.77, wpb=15266.3, bsz=571.3, num_updates=900, lr=4.50775e-05, gnorm=1.312, clip=0, train_wall=35, wall=341
2020-10-13 10:34:03 | INFO | train_inner | epoch 002:    244 / 756 loss=8.757, nll_loss=7.734, ppl=212.92, wps=42285.4, ups=2.84, wpb=14915.1, bsz=559.7, num_updates=1000, lr=5.0075e-05, gnorm=1.154, clip=0, train_wall=34, wall=376
2020-10-13 10:34:39 | INFO | train_inner | epoch 002:    344 / 756 loss=8.477, nll_loss=7.417, ppl=170.89, wps=42878.4, ups=2.83, wpb=15140, bsz=540.2, num_updates=1100, lr=5.50725e-05, gnorm=1.153, clip=0, train_wall=34, wall=412
2020-10-13 10:35:14 | INFO | train_inner | epoch 002:    444 / 756 loss=8.457, nll_loss=7.393, ppl=168.13, wps=42619.8, ups=2.8, wpb=15239.9, bsz=565.5, num_updates=1200, lr=6.007e-05, gnorm=1.252, clip=0, train_wall=34, wall=447
2020-10-13 10:35:50 | INFO | train_inner | epoch 002:    544 / 756 loss=8.272, nll_loss=7.184, ppl=145.42, wps=43168.2, ups=2.81, wpb=15373.2, bsz=575.4, num_updates=1300, lr=6.50675e-05, gnorm=1.103, clip=0, train_wall=34, wall=483
2020-10-13 10:36:26 | INFO | train_inner | epoch 002:    644 / 756 loss=8.234, nll_loss=7.139, ppl=140.99, wps=42348.6, ups=2.81, wpb=15078.9, bsz=573, num_updates=1400, lr=7.0065e-05, gnorm=1.24, clip=0, train_wall=34, wall=518
2020-10-13 10:37:01 | INFO | train_inner | epoch 002:    744 / 756 loss=8.129, nll_loss=7.02, ppl=129.79, wps=42625.4, ups=2.83, wpb=15066.3, bsz=564.9, num_updates=1500, lr=7.50625e-05, gnorm=1.327, clip=0, train_wall=34, wall=554
2020-10-13 10:37:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 10:37:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13480.97265625Mb; avail=231047.2890625Mb
2020-10-13 10:37:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002045
2020-10-13 10:37:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13480.97265625Mb; avail=231047.2890625Mb
2020-10-13 10:37:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.138110
2020-10-13 10:37:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13462.59765625Mb; avail=231066.0078125Mb
2020-10-13 10:37:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.100913
2020-10-13 10:37:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.241972
2020-10-13 10:37:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13462.19921875Mb; avail=231066.9609375Mb
2020-10-13 10:37:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13462.19921875Mb; avail=231066.9609375Mb
2020-10-13 10:37:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001805
2020-10-13 10:37:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13462.19921875Mb; avail=231066.9609375Mb
2020-10-13 10:37:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.137130
2020-10-13 10:37:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13461.88671875Mb; avail=231067.4609375Mb
2020-10-13 10:37:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.099684
2020-10-13 10:37:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.239408
2020-10-13 10:37:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13461.87890625Mb; avail=231067.4609375Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:37:12 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 7.789 | nll_loss 6.574 | ppl 95.25 | wps 83324.6 | wpb 4934.1 | bsz 184.1 | num_updates 1512 | best_loss 7.789
2020-10-13 10:37:12 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:37:18 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/checkpoint_best.pt (epoch 2 @ 1512 updates, score 7.789) (writing took 6.253495272016153 seconds)
2020-10-13 10:37:18 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2020-10-13 10:37:18 | INFO | train | epoch 002 | loss 8.477 | nll_loss 7.417 | ppl 170.89 | wps 39746.4 | ups 2.62 | wpb 15167.5 | bsz 562.8 | num_updates 1512 | lr 7.56622e-05 | gnorm 1.219 | clip 0 | train_wall 258 | wall 571
2020-10-13 10:37:18 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=3/shard_epoch=2
2020-10-13 10:37:18 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=3/shard_epoch=3
2020-10-13 10:37:18 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13221.0Mb; avail=231309.234375Mb
2020-10-13 10:37:18 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.008363
2020-10-13 10:37:18 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.090754
2020-10-13 10:37:18 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13236.08984375Mb; avail=231293.578125Mb
2020-10-13 10:37:18 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.003208
2020-10-13 10:37:18 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13236.08984375Mb; avail=231293.578125Mb
2020-10-13 10:37:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.554916
2020-10-13 10:37:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.649815
2020-10-13 10:37:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13249.39453125Mb; avail=231279.81640625Mb
2020-10-13 10:37:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13238.07421875Mb; avail=231291.13671875Mb
2020-10-13 10:37:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.070860
2020-10-13 10:37:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13243.38671875Mb; avail=231285.82421875Mb
2020-10-13 10:37:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.003342
2020-10-13 10:37:20 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13243.38671875Mb; avail=231285.82421875Mb
2020-10-13 10:37:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.562582
2020-10-13 10:37:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.637660
2020-10-13 10:37:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13245.390625Mb; avail=231284.765625Mb
2020-10-13 10:37:22 | INFO | fairseq.trainer | begin training epoch 3
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:37:56 | INFO | train_inner | epoch 003:     88 / 756 loss=8.012, nll_loss=6.887, ppl=118.39, wps=27469.3, ups=1.83, wpb=15038, bsz=565.5, num_updates=1600, lr=8.006e-05, gnorm=1.106, clip=0, train_wall=34, wall=609
2020-10-13 10:38:31 | INFO | train_inner | epoch 003:    188 / 756 loss=7.941, nll_loss=6.808, ppl=112.04, wps=42872.6, ups=2.81, wpb=15266.2, bsz=577.4, num_updates=1700, lr=8.50575e-05, gnorm=1.098, clip=0, train_wall=34, wall=644
2020-10-13 10:39:07 | INFO | train_inner | epoch 003:    288 / 756 loss=7.858, nll_loss=6.713, ppl=104.91, wps=42780.2, ups=2.81, wpb=15206.9, bsz=557.8, num_updates=1800, lr=9.0055e-05, gnorm=1.16, clip=0, train_wall=34, wall=680
2020-10-13 10:39:42 | INFO | train_inner | epoch 003:    388 / 756 loss=7.78, nll_loss=6.624, ppl=98.64, wps=42586.7, ups=2.82, wpb=15109.4, bsz=543.4, num_updates=1900, lr=9.50525e-05, gnorm=1.102, clip=0, train_wall=34, wall=715
2020-10-13 10:40:18 | INFO | train_inner | epoch 003:    488 / 756 loss=7.745, nll_loss=6.583, ppl=95.89, wps=42116.1, ups=2.78, wpb=15175, bsz=575, num_updates=2000, lr=0.00010005, gnorm=1.08, clip=0, train_wall=34, wall=751
2020-10-13 10:40:55 | INFO | train_inner | epoch 003:    588 / 756 loss=7.696, nll_loss=6.527, ppl=92.22, wps=41797.6, ups=2.76, wpb=15162.9, bsz=552.2, num_updates=2100, lr=0.000105048, gnorm=1.07, clip=0, train_wall=35, wall=788
2020-10-13 10:41:31 | INFO | train_inner | epoch 003:    688 / 756 loss=7.607, nll_loss=6.426, ppl=86, wps=42477.6, ups=2.78, wpb=15296.7, bsz=553.5, num_updates=2200, lr=0.000110045, gnorm=0.974, clip=0, train_wall=34, wall=824
2020-10-13 10:41:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 10:41:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13477.1875Mb; avail=231052.2421875Mb
2020-10-13 10:41:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001999
2020-10-13 10:41:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13477.1875Mb; avail=231052.2421875Mb
2020-10-13 10:41:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.137518
2020-10-13 10:41:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13477.05859375Mb; avail=231051.63671875Mb
2020-10-13 10:41:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.099730
2020-10-13 10:41:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.240058
2020-10-13 10:41:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13477.05859375Mb; avail=231051.63671875Mb
2020-10-13 10:41:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13477.05859375Mb; avail=231051.63671875Mb
2020-10-13 10:41:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001753
2020-10-13 10:41:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13477.05859375Mb; avail=231051.63671875Mb
2020-10-13 10:41:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.141339
2020-10-13 10:41:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13490.7734375Mb; avail=231037.921875Mb
2020-10-13 10:41:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.100458
2020-10-13 10:41:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.244423
2020-10-13 10:41:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13485.8671875Mb; avail=231043.37109375Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:42:01 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 7.286 | nll_loss 6.01 | ppl 64.43 | wps 87613 | wpb 4934.1 | bsz 184.1 | num_updates 2268 | best_loss 7.286
2020-10-13 10:42:01 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:42:08 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/checkpoint_best.pt (epoch 3 @ 2268 updates, score 7.286) (writing took 6.4184429831802845 seconds)
2020-10-13 10:42:08 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2020-10-13 10:42:08 | INFO | train | epoch 003 | loss 7.778 | nll_loss 6.621 | ppl 98.45 | wps 39586.4 | ups 2.61 | wpb 15168.6 | bsz 563.1 | num_updates 2268 | lr 0.000113443 | gnorm 1.084 | clip 0 | train_wall 259 | wall 861
2020-10-13 10:42:08 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=4/shard_epoch=3
2020-10-13 10:42:08 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=4/shard_epoch=4
2020-10-13 10:42:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13215.9453125Mb; avail=231313.3984375Mb
2020-10-13 10:42:08 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.014667
2020-10-13 10:42:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.116345
2020-10-13 10:42:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13221.98046875Mb; avail=231307.36328125Mb
2020-10-13 10:42:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.003390
2020-10-13 10:42:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13221.98046875Mb; avail=231307.36328125Mb
2020-10-13 10:42:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.562895
2020-10-13 10:42:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.683553
2020-10-13 10:42:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13234.30078125Mb; avail=231294.91796875Mb
2020-10-13 10:42:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13222.48828125Mb; avail=231306.73046875Mb
2020-10-13 10:42:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.070312
2020-10-13 10:42:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13222.48828125Mb; avail=231306.73046875Mb
2020-10-13 10:42:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.003136
2020-10-13 10:42:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13222.48828125Mb; avail=231306.73046875Mb
2020-10-13 10:42:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.544564
2020-10-13 10:42:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.618868
2020-10-13 10:42:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13250.265625Mb; avail=231278.94921875Mb
2020-10-13 10:42:11 | INFO | fairseq.trainer | begin training epoch 4
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:42:26 | INFO | train_inner | epoch 004:     32 / 756 loss=7.574, nll_loss=6.389, ppl=83.81, wps=27513.6, ups=1.82, wpb=15117.8, bsz=574, num_updates=2300, lr=0.000115043, gnorm=1.028, clip=0, train_wall=34, wall=878
2020-10-13 10:43:01 | INFO | train_inner | epoch 004:    132 / 756 loss=7.494, nll_loss=6.298, ppl=78.66, wps=42493.5, ups=2.8, wpb=15185.6, bsz=590.1, num_updates=2400, lr=0.00012004, gnorm=1.02, clip=0, train_wall=34, wall=914
2020-10-13 10:43:37 | INFO | train_inner | epoch 004:    232 / 756 loss=7.482, nll_loss=6.283, ppl=77.88, wps=42103.1, ups=2.79, wpb=15104.4, bsz=566.5, num_updates=2500, lr=0.000125037, gnorm=0.996, clip=0, train_wall=34, wall=950
2020-10-13 10:44:13 | INFO | train_inner | epoch 004:    332 / 756 loss=7.391, nll_loss=6.18, ppl=72.48, wps=42964, ups=2.8, wpb=15355.6, bsz=544.5, num_updates=2600, lr=0.000130035, gnorm=1.037, clip=0, train_wall=34, wall=986
2020-10-13 10:44:49 | INFO | train_inner | epoch 004:    432 / 756 loss=7.338, nll_loss=6.119, ppl=69.51, wps=42206.7, ups=2.78, wpb=15188.4, bsz=584.6, num_updates=2700, lr=0.000135032, gnorm=0.971, clip=0, train_wall=34, wall=1022
2020-10-13 10:45:25 | INFO | train_inner | epoch 004:    532 / 756 loss=7.256, nll_loss=6.027, ppl=65.23, wps=41930.5, ups=2.78, wpb=15092.8, bsz=563.8, num_updates=2800, lr=0.00014003, gnorm=0.941, clip=0, train_wall=34, wall=1058
2020-10-13 10:46:00 | INFO | train_inner | epoch 004:    632 / 756 loss=7.184, nll_loss=5.944, ppl=61.57, wps=42793.3, ups=2.81, wpb=15220.9, bsz=565.6, num_updates=2900, lr=0.000145028, gnorm=0.952, clip=0, train_wall=34, wall=1093
2020-10-13 10:46:36 | INFO | train_inner | epoch 004:    732 / 756 loss=7.177, nll_loss=5.936, ppl=61.22, wps=42217.3, ups=2.82, wpb=14993, bsz=549.8, num_updates=3000, lr=0.000150025, gnorm=0.945, clip=0, train_wall=34, wall=1129
2020-10-13 10:46:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 10:46:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13498.96875Mb; avail=231030.52734375Mb
2020-10-13 10:46:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002015
2020-10-13 10:46:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13498.96875Mb; avail=231030.52734375Mb
2020-10-13 10:46:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.181197
2020-10-13 10:46:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13513.35546875Mb; avail=231014.3828125Mb
2020-10-13 10:46:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.099226
2020-10-13 10:46:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.283389
2020-10-13 10:46:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13498.95703125Mb; avail=231029.078125Mb
2020-10-13 10:46:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13501.01953125Mb; avail=231027.515625Mb
2020-10-13 10:46:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001803
2020-10-13 10:46:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13500.28515625Mb; avail=231027.515625Mb
2020-10-13 10:46:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.150010
2020-10-13 10:46:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13501.26171875Mb; avail=231026.99609375Mb
2020-10-13 10:46:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.133444
2020-10-13 10:46:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.286401
2020-10-13 10:46:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13511.58984375Mb; avail=231016.24609375Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:46:51 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 6.842 | nll_loss 5.481 | ppl 44.65 | wps 83931.3 | wpb 4934.1 | bsz 184.1 | num_updates 3024 | best_loss 6.842
2020-10-13 10:46:51 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:46:57 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/checkpoint_best.pt (epoch 4 @ 3024 updates, score 6.842) (writing took 6.384635709924623 seconds)
2020-10-13 10:46:58 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2020-10-13 10:46:58 | INFO | train | epoch 004 | loss 7.332 | nll_loss 6.113 | ppl 69.22 | wps 39575.9 | ups 2.61 | wpb 15169 | bsz 563.2 | num_updates 3024 | lr 0.000151224 | gnorm 0.975 | clip 0 | train_wall 259 | wall 1151
2020-10-13 10:46:58 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=5/shard_epoch=4
2020-10-13 10:46:58 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=5/shard_epoch=5
2020-10-13 10:46:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13309.83203125Mb; avail=231218.84375Mb
2020-10-13 10:46:58 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.009064
2020-10-13 10:46:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.103580
2020-10-13 10:46:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13268.15234375Mb; avail=231260.0859375Mb
2020-10-13 10:46:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.004230
2020-10-13 10:46:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13268.7578125Mb; avail=231259.97265625Mb
2020-10-13 10:47:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.730474
2020-10-13 10:47:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.839343
2020-10-13 10:47:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13279.36328125Mb; avail=231248.7578125Mb
2020-10-13 10:47:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13274.1953125Mb; avail=231253.359375Mb
2020-10-13 10:47:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.080433
2020-10-13 10:47:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13279.95703125Mb; avail=231247.63671875Mb
2020-10-13 10:47:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.004272
2020-10-13 10:47:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13279.22265625Mb; avail=231248.12890625Mb
2020-10-13 10:47:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.724139
2020-10-13 10:47:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.809958
2020-10-13 10:47:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13267.6796875Mb; avail=231259.94140625Mb
2020-10-13 10:47:01 | INFO | fairseq.trainer | begin training epoch 5
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:47:36 | INFO | train_inner | epoch 005:     76 / 756 loss=7.09, nll_loss=5.838, ppl=57.22, wps=25037.3, ups=1.67, wpb=15021, bsz=509.9, num_updates=3100, lr=0.000155023, gnorm=0.946, clip=0, train_wall=34, wall=1189
2020-10-13 10:48:11 | INFO | train_inner | epoch 005:    176 / 756 loss=7.003, nll_loss=5.739, ppl=53.41, wps=43037.3, ups=2.81, wpb=15290.4, bsz=602.2, num_updates=3200, lr=0.00016002, gnorm=0.935, clip=0, train_wall=34, wall=1224
2020-10-13 10:48:47 | INFO | train_inner | epoch 005:    276 / 756 loss=6.94, nll_loss=5.666, ppl=50.77, wps=42710.9, ups=2.82, wpb=15151.4, bsz=560.6, num_updates=3300, lr=0.000165018, gnorm=0.989, clip=0, train_wall=34, wall=1260
2020-10-13 10:49:23 | INFO | train_inner | epoch 005:    376 / 756 loss=6.825, nll_loss=5.535, ppl=46.38, wps=43044.8, ups=2.81, wpb=15313.3, bsz=586.1, num_updates=3400, lr=0.000170015, gnorm=0.995, clip=0, train_wall=34, wall=1295
2020-10-13 10:49:58 | INFO | train_inner | epoch 005:    476 / 756 loss=6.795, nll_loss=5.5, ppl=45.26, wps=42556.7, ups=2.8, wpb=15203, bsz=547.8, num_updates=3500, lr=0.000175013, gnorm=1.049, clip=0, train_wall=34, wall=1331
2020-10-13 10:50:34 | INFO | train_inner | epoch 005:    576 / 756 loss=6.754, nll_loss=5.454, ppl=43.84, wps=42966.8, ups=2.82, wpb=15232.8, bsz=562.4, num_updates=3600, lr=0.00018001, gnorm=0.969, clip=0, train_wall=34, wall=1367
2020-10-13 10:51:09 | INFO | train_inner | epoch 005:    676 / 756 loss=6.669, nll_loss=5.357, ppl=40.98, wps=42036.9, ups=2.81, wpb=14962, bsz=549, num_updates=3700, lr=0.000185008, gnorm=0.957, clip=0, train_wall=34, wall=1402
2020-10-13 10:51:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 10:51:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13513.875Mb; avail=231015.2421875Mb
2020-10-13 10:51:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002107
2020-10-13 10:51:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13513.875Mb; avail=231015.2421875Mb
2020-10-13 10:51:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.136375
2020-10-13 10:51:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13504.515625Mb; avail=231024.6015625Mb
2020-10-13 10:51:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.099684
2020-10-13 10:51:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.238961
2020-10-13 10:51:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13504.515625Mb; avail=231024.6015625Mb
2020-10-13 10:51:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13504.515625Mb; avail=231024.6015625Mb
2020-10-13 10:51:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001806
2020-10-13 10:51:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13504.515625Mb; avail=231024.6015625Mb
2020-10-13 10:51:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.139573
2020-10-13 10:51:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13513.734375Mb; avail=231015.3828125Mb
2020-10-13 10:51:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.098940
2020-10-13 10:51:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.241125
2020-10-13 10:51:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13503.515625Mb; avail=231025.6015625Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:51:44 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 6.313 | nll_loss 4.868 | ppl 29.2 | wps 87385.8 | wpb 4934.1 | bsz 184.1 | num_updates 3780 | best_loss 6.313
2020-10-13 10:51:44 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:51:53 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/checkpoint_best.pt (epoch 5 @ 3780 updates, score 6.313) (writing took 9.124112036079168 seconds)
2020-10-13 10:51:54 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2020-10-13 10:51:54 | INFO | train | epoch 005 | loss 6.835 | nll_loss 5.547 | ppl 46.75 | wps 38760.8 | ups 2.56 | wpb 15168.6 | bsz 563 | num_updates 3780 | lr 0.000189006 | gnorm 0.982 | clip 0 | train_wall 258 | wall 1446
2020-10-13 10:51:54 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=6/shard_epoch=5
2020-10-13 10:51:54 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=6/shard_epoch=6
2020-10-13 10:51:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13590.20703125Mb; avail=230938.78125Mb
2020-10-13 10:51:54 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.009665
2020-10-13 10:51:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.100326
2020-10-13 10:51:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13597.44921875Mb; avail=230931.5390625Mb
2020-10-13 10:51:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.003469
2020-10-13 10:51:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13597.44921875Mb; avail=230931.5390625Mb
2020-10-13 10:51:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.724653
2020-10-13 10:51:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.829582
2020-10-13 10:51:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13598.4453125Mb; avail=230930.8046875Mb
2020-10-13 10:51:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13602.1015625Mb; avail=230927.1484375Mb
2020-10-13 10:51:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.078683
2020-10-13 10:51:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13608.60546875Mb; avail=230920.64453125Mb
2020-10-13 10:51:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.003842
2020-10-13 10:51:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13608.60546875Mb; avail=230920.64453125Mb
2020-10-13 10:51:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.566781
2020-10-13 10:51:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.650462
2020-10-13 10:51:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13016.97265625Mb; avail=231512.53125Mb
2020-10-13 10:51:57 | INFO | fairseq.trainer | begin training epoch 6
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:52:07 | INFO | train_inner | epoch 006:     20 / 756 loss=6.568, nll_loss=5.243, ppl=37.87, wps=26149.2, ups=1.73, wpb=15073.7, bsz=559.7, num_updates=3800, lr=0.000190005, gnorm=0.961, clip=0, train_wall=34, wall=1460
2020-10-13 10:52:42 | INFO | train_inner | epoch 006:    120 / 756 loss=6.528, nll_loss=5.196, ppl=36.66, wps=42690.2, ups=2.82, wpb=15114.8, bsz=574.6, num_updates=3900, lr=0.000195003, gnorm=0.969, clip=0, train_wall=34, wall=1495
2020-10-13 10:53:18 | INFO | train_inner | epoch 006:    220 / 756 loss=6.455, nll_loss=5.113, ppl=34.6, wps=42934.6, ups=2.81, wpb=15275.4, bsz=549.5, num_updates=4000, lr=0.0002, gnorm=1.016, clip=0, train_wall=34, wall=1531
2020-10-13 10:53:53 | INFO | train_inner | epoch 006:    320 / 756 loss=6.385, nll_loss=5.033, ppl=32.74, wps=42832.2, ups=2.83, wpb=15131.1, bsz=573.4, num_updates=4100, lr=0.000197546, gnorm=0.978, clip=0, train_wall=34, wall=1566
2020-10-13 10:54:29 | INFO | train_inner | epoch 006:    420 / 756 loss=6.272, nll_loss=4.904, ppl=29.93, wps=42977.3, ups=2.79, wpb=15409.3, bsz=595.7, num_updates=4200, lr=0.00019518, gnorm=0.969, clip=0, train_wall=34, wall=1602
2020-10-13 10:55:05 | INFO | train_inner | epoch 006:    520 / 756 loss=6.305, nll_loss=4.941, ppl=30.71, wps=42102.4, ups=2.79, wpb=15116, bsz=533.9, num_updates=4300, lr=0.000192897, gnorm=0.982, clip=0, train_wall=34, wall=1638
2020-10-13 10:55:41 | INFO | train_inner | epoch 006:    620 / 756 loss=6.187, nll_loss=4.807, ppl=27.99, wps=41822, ups=2.8, wpb=14926.6, bsz=592.1, num_updates=4400, lr=0.000190693, gnorm=1.018, clip=0, train_wall=34, wall=1674
2020-10-13 10:56:16 | INFO | train_inner | epoch 006:    720 / 756 loss=6.197, nll_loss=4.817, ppl=28.18, wps=43071.2, ups=2.83, wpb=15241.7, bsz=534.3, num_updates=4500, lr=0.000188562, gnorm=0.952, clip=0, train_wall=34, wall=1709
2020-10-13 10:56:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 10:56:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13508.859375Mb; avail=231019.85546875Mb
2020-10-13 10:56:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002036
2020-10-13 10:56:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13508.859375Mb; avail=231019.85546875Mb
2020-10-13 10:56:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.136966
2020-10-13 10:56:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13508.3671875Mb; avail=231020.34765625Mb
2020-10-13 10:56:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.098400
2020-10-13 10:56:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.238174
2020-10-13 10:56:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13508.4453125Mb; avail=231020.26953125Mb
2020-10-13 10:56:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13508.4453125Mb; avail=231020.26953125Mb
2020-10-13 10:56:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001713
2020-10-13 10:56:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13508.4453125Mb; avail=231020.26953125Mb
2020-10-13 10:56:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.134493
2020-10-13 10:56:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13508.25390625Mb; avail=231020.05078125Mb
2020-10-13 10:56:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.098965
2020-10-13 10:56:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.235928
2020-10-13 10:56:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13509.078125Mb; avail=231020.25390625Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:56:35 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 5.869 | nll_loss 4.347 | ppl 20.36 | wps 87982.6 | wpb 4934.1 | bsz 184.1 | num_updates 4536 | best_loss 5.869
2020-10-13 10:56:35 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:56:42 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/checkpoint_best.pt (epoch 6 @ 4536 updates, score 5.869) (writing took 6.250391243956983 seconds)
2020-10-13 10:56:42 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2020-10-13 10:56:42 | INFO | train | epoch 006 | loss 6.326 | nll_loss 4.965 | ppl 31.23 | wps 39767 | ups 2.62 | wpb 15168.1 | bsz 563.1 | num_updates 4536 | lr 0.000187812 | gnorm 0.978 | clip 0 | train_wall 258 | wall 1735
2020-10-13 10:56:42 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=7/shard_epoch=6
2020-10-13 10:56:42 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=7/shard_epoch=7
2020-10-13 10:56:42 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13312.6015625Mb; avail=231218.0703125Mb
2020-10-13 10:56:42 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.007046
2020-10-13 10:56:42 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.093774
2020-10-13 10:56:42 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13276.9609375Mb; avail=231252.234375Mb
2020-10-13 10:56:42 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.003256
2020-10-13 10:56:42 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13276.9609375Mb; avail=231252.234375Mb
2020-10-13 10:56:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.523477
2020-10-13 10:56:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.621447
2020-10-13 10:56:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13283.55859375Mb; avail=231245.4765625Mb
2020-10-13 10:56:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13283.109375Mb; avail=231245.92578125Mb
2020-10-13 10:56:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.070726
2020-10-13 10:56:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13288.46875Mb; avail=231240.56640625Mb
2020-10-13 10:56:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.003150
2020-10-13 10:56:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13288.46875Mb; avail=231240.56640625Mb
2020-10-13 10:56:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.533546
2020-10-13 10:56:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.608341
2020-10-13 10:56:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13277.58203125Mb; avail=231251.8671875Mb
2020-10-13 10:56:45 | INFO | fairseq.trainer | begin training epoch 7
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 10:57:11 | INFO | train_inner | epoch 007:     64 / 756 loss=6.061, nll_loss=4.663, ppl=25.34, wps=27894.9, ups=1.82, wpb=15302.6, bsz=568.4, num_updates=4600, lr=0.000186501, gnorm=0.929, clip=0, train_wall=34, wall=1764
2020-10-13 10:57:46 | INFO | train_inner | epoch 007:    164 / 756 loss=6.02, nll_loss=4.617, ppl=24.53, wps=42766.7, ups=2.83, wpb=15091.8, bsz=558.5, num_updates=4700, lr=0.000184506, gnorm=0.974, clip=0, train_wall=34, wall=1799
2020-10-13 10:58:22 | INFO | train_inner | epoch 007:    264 / 756 loss=5.942, nll_loss=4.527, ppl=23.05, wps=43128.3, ups=2.82, wpb=15271.1, bsz=559.1, num_updates=4800, lr=0.000182574, gnorm=0.854, clip=0, train_wall=34, wall=1835
2020-10-13 10:59:00 | INFO | train_inner | epoch 007:    364 / 756 loss=5.895, nll_loss=4.473, ppl=22.21, wps=40201.7, ups=2.64, wpb=15217.7, bsz=596.2, num_updates=4900, lr=0.000180702, gnorm=0.821, clip=0, train_wall=36, wall=1872
2020-10-13 10:59:35 | INFO | train_inner | epoch 007:    464 / 756 loss=5.877, nll_loss=4.452, ppl=21.89, wps=42478.5, ups=2.82, wpb=15073.8, bsz=547, num_updates=5000, lr=0.000178885, gnorm=0.854, clip=0, train_wall=34, wall=1908
2020-10-13 11:00:10 | INFO | train_inner | epoch 007:    564 / 756 loss=5.86, nll_loss=4.432, ppl=21.59, wps=42247.2, ups=2.83, wpb=14949.9, bsz=534, num_updates=5100, lr=0.000177123, gnorm=0.841, clip=0, train_wall=34, wall=1943
2020-10-13 11:00:46 | INFO | train_inner | epoch 007:    664 / 756 loss=5.751, nll_loss=4.308, ppl=19.81, wps=43347.8, ups=2.82, wpb=15374.7, bsz=577.7, num_updates=5200, lr=0.000175412, gnorm=0.823, clip=0, train_wall=34, wall=1979
2020-10-13 11:01:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 11:01:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13512.19140625Mb; avail=231016.44921875Mb
2020-10-13 11:01:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002018
2020-10-13 11:01:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13512.19140625Mb; avail=231016.44921875Mb
2020-10-13 11:01:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.137141
2020-10-13 11:01:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13522.27734375Mb; avail=231006.36328125Mb
2020-10-13 11:01:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.100878
2020-10-13 11:01:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.240862
2020-10-13 11:01:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13512.93359375Mb; avail=231015.70703125Mb
2020-10-13 11:01:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13512.93359375Mb; avail=231015.70703125Mb
2020-10-13 11:01:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001794
2020-10-13 11:01:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13512.93359375Mb; avail=231015.70703125Mb
2020-10-13 11:01:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.140897
2020-10-13 11:01:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13512.92578125Mb; avail=231015.71484375Mb
2020-10-13 11:01:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.099962
2020-10-13 11:01:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.243434
2020-10-13 11:01:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13517.9140625Mb; avail=231010.4921875Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:01:25 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 5.558 | nll_loss 3.984 | ppl 15.82 | wps 87338.7 | wpb 4934.1 | bsz 184.1 | num_updates 5292 | best_loss 5.558
2020-10-13 11:01:25 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:01:31 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/checkpoint_best.pt (epoch 7 @ 5292 updates, score 5.558) (writing took 6.241941935149953 seconds)
2020-10-13 11:01:32 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2020-10-13 11:01:32 | INFO | train | epoch 007 | loss 5.891 | nll_loss 4.469 | ppl 22.14 | wps 39562.8 | ups 2.61 | wpb 15168.8 | bsz 562.8 | num_updates 5292 | lr 0.00017388 | gnorm 0.876 | clip 0 | train_wall 259 | wall 2025
2020-10-13 11:01:32 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=8/shard_epoch=7
2020-10-13 11:01:32 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=8/shard_epoch=8
2020-10-13 11:01:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13327.40625Mb; avail=231201.75390625Mb
2020-10-13 11:01:32 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.008011
2020-10-13 11:01:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.090446
2020-10-13 11:01:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13334.125Mb; avail=231195.03515625Mb
2020-10-13 11:01:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.003160
2020-10-13 11:01:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13334.125Mb; avail=231195.03515625Mb
2020-10-13 11:01:33 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.560216
2020-10-13 11:01:33 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.654746
2020-10-13 11:01:33 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13352.86328125Mb; avail=231176.140625Mb
2020-10-13 11:01:33 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=13347.73828125Mb; avail=231181.265625Mb
2020-10-13 11:01:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.072264
2020-10-13 11:01:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13338.9296875Mb; avail=231190.07421875Mb
2020-10-13 11:01:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.003186
2020-10-13 11:01:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13338.9296875Mb; avail=231190.07421875Mb
2020-10-13 11:01:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.556713
2020-10-13 11:01:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.633121
2020-10-13 11:01:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=13345.6796875Mb; avail=231183.33984375Mb
2020-10-13 11:01:35 | INFO | fairseq.trainer | begin training epoch 8
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:01:41 | INFO | train_inner | epoch 008:      8 / 756 loss=5.779, nll_loss=4.34, ppl=20.25, wps=27531.3, ups=1.81, wpb=15170.4, bsz=553.8, num_updates=5300, lr=0.000173749, gnorm=0.924, clip=0, train_wall=34, wall=2034
2020-10-13 11:02:16 | INFO | train_inner | epoch 008:    108 / 756 loss=5.669, nll_loss=4.215, ppl=18.57, wps=42707.3, ups=2.83, wpb=15117, bsz=549.2, num_updates=5400, lr=0.000172133, gnorm=0.792, clip=0, train_wall=34, wall=2069
2020-10-13 11:02:55 | INFO | train_inner | epoch 008:    208 / 756 loss=5.612, nll_loss=4.151, ppl=17.76, wps=38909.4, ups=2.56, wpb=15185.8, bsz=607.1, num_updates=5500, lr=0.000170561, gnorm=0.831, clip=0, train_wall=37, wall=2108
2020-10-13 11:03:36 | INFO | train_inner | epoch 008:    308 / 756 loss=5.598, nll_loss=4.134, ppl=17.56, wps=37367.9, ups=2.46, wpb=15190.2, bsz=596.9, num_updates=5600, lr=0.000169031, gnorm=0.79, clip=0, train_wall=38, wall=2149
2020-10-13 11:04:16 | INFO | train_inner | epoch 008:    408 / 756 loss=5.563, nll_loss=4.095, ppl=17.09, wps=37849.8, ups=2.48, wpb=15237.5, bsz=541.4, num_updates=5700, lr=0.000167542, gnorm=0.789, clip=0, train_wall=38, wall=2189
2020-10-13 11:04:57 | INFO | train_inner | epoch 008:    508 / 756 loss=5.572, nll_loss=4.103, ppl=17.19, wps=36957, ups=2.45, wpb=15101.7, bsz=542.2, num_updates=5800, lr=0.000166091, gnorm=0.792, clip=0, train_wall=39, wall=2230
2020-10-13 11:05:38 | INFO | train_inner | epoch 008:    608 / 756 loss=5.524, nll_loss=4.049, ppl=16.56, wps=37461.1, ups=2.46, wpb=15243.2, bsz=551.1, num_updates=5900, lr=0.000164677, gnorm=0.766, clip=0, train_wall=38, wall=2271
2020-10-13 11:06:18 | INFO | train_inner | epoch 008:    708 / 756 loss=5.511, nll_loss=4.035, ppl=16.39, wps=37753.8, ups=2.48, wpb=15234.1, bsz=576.2, num_updates=6000, lr=0.000163299, gnorm=0.784, clip=0, train_wall=38, wall=2311
2020-10-13 11:06:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 11:06:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=23433.171875Mb; avail=221094.63671875Mb
2020-10-13 11:06:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003039
2020-10-13 11:06:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23433.171875Mb; avail=221094.63671875Mb
2020-10-13 11:06:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.320866
2020-10-13 11:06:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23541.6640625Mb; avail=220986.85546875Mb
2020-10-13 11:06:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.219790
2020-10-13 11:06:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.545738
2020-10-13 11:06:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23541.6640625Mb; avail=220986.85546875Mb
2020-10-13 11:06:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=23541.6640625Mb; avail=220986.85546875Mb
2020-10-13 11:06:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003009
2020-10-13 11:06:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23541.6640625Mb; avail=220986.85546875Mb
2020-10-13 11:06:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.235817
2020-10-13 11:06:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23541.78515625Mb; avail=220986.734375Mb
2020-10-13 11:06:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.223475
2020-10-13 11:06:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.463997
2020-10-13 11:06:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23544.3359375Mb; avail=220983.85546875Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:06:47 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 5.349 | nll_loss 3.738 | ppl 13.34 | wps 74606.3 | wpb 4934.1 | bsz 184.1 | num_updates 6048 | best_loss 5.349
2020-10-13 11:06:47 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:06:53 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/checkpoint_best.pt (epoch 8 @ 6048 updates, score 5.349) (writing took 6.672144409967586 seconds)
2020-10-13 11:06:54 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2020-10-13 11:06:54 | INFO | train | epoch 008 | loss 5.575 | nll_loss 4.108 | ppl 17.24 | wps 35594.9 | ups 2.35 | wpb 15167.9 | bsz 562.9 | num_updates 6048 | lr 0.00016265 | gnorm 0.79 | clip 0 | train_wall 283 | wall 2347
2020-10-13 11:06:54 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=9/shard_epoch=8
2020-10-13 11:06:54 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=9/shard_epoch=9
2020-10-13 11:06:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=22772.37109375Mb; avail=221756.29296875Mb
2020-10-13 11:06:54 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.015218
2020-10-13 11:06:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.162571
2020-10-13 11:06:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22830.9375Mb; avail=221697.625Mb
2020-10-13 11:06:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.009185
2020-10-13 11:06:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22830.9375Mb; avail=221697.3828125Mb
2020-10-13 11:06:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.561199
2020-10-13 11:06:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.734781
2020-10-13 11:06:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23224.3671875Mb; avail=221304.1015625Mb
2020-10-13 11:06:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=23213.046875Mb; avail=221315.421875Mb
2020-10-13 11:06:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.077737
2020-10-13 11:06:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23213.58984375Mb; avail=221314.87890625Mb
2020-10-13 11:06:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.007046
2020-10-13 11:06:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23213.58984375Mb; avail=221314.87890625Mb
2020-10-13 11:06:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.975959
2020-10-13 11:06:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.061986
2020-10-13 11:06:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21131.86328125Mb; avail=223396.65234375Mb
2020-10-13 11:06:59 | INFO | fairseq.trainer | begin training epoch 9
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:07:24 | INFO | train_inner | epoch 009:     52 / 756 loss=5.475, nll_loss=3.994, ppl=15.93, wps=22777.7, ups=1.53, wpb=14881.6, bsz=530.6, num_updates=6100, lr=0.000161955, gnorm=0.802, clip=0, train_wall=38, wall=2376
2020-10-13 11:08:04 | INFO | train_inner | epoch 009:    152 / 756 loss=5.399, nll_loss=3.907, ppl=15, wps=37684.4, ups=2.49, wpb=15104.4, bsz=555.7, num_updates=6200, lr=0.000160644, gnorm=0.751, clip=0, train_wall=38, wall=2417
2020-10-13 11:08:44 | INFO | train_inner | epoch 009:    252 / 756 loss=5.412, nll_loss=3.922, ppl=15.15, wps=37411.1, ups=2.45, wpb=15254.3, bsz=560.8, num_updates=6300, lr=0.000159364, gnorm=0.776, clip=0, train_wall=39, wall=2457
2020-10-13 11:09:25 | INFO | train_inner | epoch 009:    352 / 756 loss=5.351, nll_loss=3.852, ppl=14.44, wps=37548, ups=2.46, wpb=15283.4, bsz=593.8, num_updates=6400, lr=0.000158114, gnorm=0.721, clip=0, train_wall=38, wall=2498
2020-10-13 11:10:06 | INFO | train_inner | epoch 009:    452 / 756 loss=5.337, nll_loss=3.836, ppl=14.28, wps=37573.7, ups=2.47, wpb=15234.6, bsz=561.8, num_updates=6500, lr=0.000156893, gnorm=0.756, clip=0, train_wall=38, wall=2539
2020-10-13 11:10:46 | INFO | train_inner | epoch 009:    552 / 756 loss=5.321, nll_loss=3.818, ppl=14.11, wps=37708, ups=2.47, wpb=15287.2, bsz=555, num_updates=6600, lr=0.0001557, gnorm=0.758, clip=0, train_wall=38, wall=2579
2020-10-13 11:11:27 | INFO | train_inner | epoch 009:    652 / 756 loss=5.302, nll_loss=3.797, ppl=13.9, wps=37484.8, ups=2.46, wpb=15219.4, bsz=561.2, num_updates=6700, lr=0.000154533, gnorm=0.723, clip=0, train_wall=38, wall=2620
2020-10-13 11:12:07 | INFO | train_inner | epoch 009:    752 / 756 loss=5.306, nll_loss=3.801, ppl=13.94, wps=37408.1, ups=2.5, wpb=14985.8, bsz=570.2, num_updates=6800, lr=0.000153393, gnorm=0.762, clip=0, train_wall=38, wall=2660
2020-10-13 11:12:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 11:12:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=23500.55078125Mb; avail=221027.16015625Mb
2020-10-13 11:12:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002957
2020-10-13 11:12:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23501.9296875Mb; avail=221026.3984375Mb
2020-10-13 11:12:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.169906
2020-10-13 11:12:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23491.65625Mb; avail=221036.671875Mb
2020-10-13 11:12:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.100980
2020-10-13 11:12:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.275167
2020-10-13 11:12:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23518.2265625Mb; avail=221010.1015625Mb
2020-10-13 11:12:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=23518.2265625Mb; avail=221010.1015625Mb
2020-10-13 11:12:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002234
2020-10-13 11:12:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23518.2265625Mb; avail=221010.1015625Mb
2020-10-13 11:12:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.262364
2020-10-13 11:12:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23518.34765625Mb; avail=221009.98046875Mb
2020-10-13 11:12:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.218967
2020-10-13 11:12:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.485431
2020-10-13 11:12:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23527.84375Mb; avail=221000.6640625Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:12:17 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 5.187 | nll_loss 3.562 | ppl 11.81 | wps 70393.2 | wpb 4934.1 | bsz 184.1 | num_updates 6804 | best_loss 5.187
2020-10-13 11:12:17 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:12:24 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/checkpoint_best.pt (epoch 9 @ 6804 updates, score 5.187) (writing took 7.220215557841584 seconds)
2020-10-13 11:12:25 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2020-10-13 11:12:25 | INFO | train | epoch 009 | loss 5.353 | nll_loss 3.855 | ppl 14.47 | wps 34672.6 | ups 2.29 | wpb 15168.6 | bsz 563 | num_updates 6804 | lr 0.000153348 | gnorm 0.756 | clip 0 | train_wall 289 | wall 2678
2020-10-13 11:12:25 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=10/shard_epoch=9
2020-10-13 11:12:25 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=10/shard_epoch=10
2020-10-13 11:12:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=22648.5Mb; avail=221880.12890625Mb
2020-10-13 11:12:25 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.009533
2020-10-13 11:12:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.125302
2020-10-13 11:12:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22674.5859375Mb; avail=221854.04296875Mb
2020-10-13 11:12:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.005740
2020-10-13 11:12:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22674.5859375Mb; avail=221854.04296875Mb
2020-10-13 11:12:27 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.396458
2020-10-13 11:12:27 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.528776
2020-10-13 11:12:27 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21155.4609375Mb; avail=223373.06640625Mb
2020-10-13 11:12:27 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=21165.9375Mb; avail=223361.71875Mb
2020-10-13 11:12:27 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.077667
2020-10-13 11:12:27 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21170.85546875Mb; avail=223357.1484375Mb
2020-10-13 11:12:27 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.005322
2020-10-13 11:12:27 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21170.85546875Mb; avail=223357.1484375Mb
2020-10-13 11:12:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.594917
2020-10-13 11:12:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.679087
2020-10-13 11:12:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21214.1015625Mb; avail=223313.64453125Mb
2020-10-13 11:12:29 | INFO | fairseq.trainer | begin training epoch 10
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:13:12 | INFO | train_inner | epoch 010:     96 / 756 loss=5.256, nll_loss=3.745, ppl=13.41, wps=22835.4, ups=1.54, wpb=14815.1, bsz=536.4, num_updates=6900, lr=0.000152277, gnorm=0.744, clip=0, train_wall=38, wall=2725
2020-10-13 11:13:52 | INFO | train_inner | epoch 010:    196 / 756 loss=5.238, nll_loss=3.723, ppl=13.21, wps=37803.3, ups=2.49, wpb=15187.3, bsz=564.9, num_updates=7000, lr=0.000151186, gnorm=0.703, clip=0, train_wall=38, wall=2765
2020-10-13 11:14:33 | INFO | train_inner | epoch 010:    296 / 756 loss=5.195, nll_loss=3.676, ppl=12.78, wps=37232, ups=2.44, wpb=15259.2, bsz=541, num_updates=7100, lr=0.000150117, gnorm=0.715, clip=0, train_wall=39, wall=2806
2020-10-13 11:15:14 | INFO | train_inner | epoch 010:    396 / 756 loss=5.154, nll_loss=3.628, ppl=12.37, wps=37466.7, ups=2.45, wpb=15317.9, bsz=600.8, num_updates=7200, lr=0.000149071, gnorm=0.7, clip=0, train_wall=39, wall=2847
2020-10-13 11:15:55 | INFO | train_inner | epoch 010:    496 / 756 loss=5.174, nll_loss=3.651, ppl=12.56, wps=37314.5, ups=2.45, wpb=15260.5, bsz=572, num_updates=7300, lr=0.000148047, gnorm=0.73, clip=0, train_wall=39, wall=2888
2020-10-13 11:16:35 | INFO | train_inner | epoch 010:    596 / 756 loss=5.151, nll_loss=3.626, ppl=12.34, wps=37417.4, ups=2.47, wpb=15165.1, bsz=548.9, num_updates=7400, lr=0.000147043, gnorm=0.724, clip=0, train_wall=38, wall=2928
2020-10-13 11:17:16 | INFO | train_inner | epoch 010:    696 / 756 loss=5.154, nll_loss=3.628, ppl=12.37, wps=37387.3, ups=2.47, wpb=15123.3, bsz=569.5, num_updates=7500, lr=0.000146059, gnorm=0.753, clip=0, train_wall=38, wall=2969
2020-10-13 11:17:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 11:17:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=22175.546875Mb; avail=222352.921875Mb
2020-10-13 11:17:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002173
2020-10-13 11:17:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22175.546875Mb; avail=222352.921875Mb
2020-10-13 11:17:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.303518
2020-10-13 11:17:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22183.0078125Mb; avail=222345.4609375Mb
2020-10-13 11:17:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.213983
2020-10-13 11:17:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.521086
2020-10-13 11:17:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21706.0234375Mb; avail=222825.34765625Mb
2020-10-13 11:17:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=21393.55859375Mb; avail=223135.11328125Mb
2020-10-13 11:17:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001910
2020-10-13 11:17:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21393.55859375Mb; avail=223135.11328125Mb
2020-10-13 11:17:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.292357
2020-10-13 11:17:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21394.0625Mb; avail=223134.98046875Mb
2020-10-13 11:17:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.233793
2020-10-13 11:17:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.529525
2020-10-13 11:17:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21392.65625Mb; avail=223135.80859375Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:17:48 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 5.086 | nll_loss 3.444 | ppl 10.88 | wps 75467.9 | wpb 4934.1 | bsz 184.1 | num_updates 7560 | best_loss 5.086
2020-10-13 11:17:48 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:17:55 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/checkpoint_best.pt (epoch 10 @ 7560 updates, score 5.086) (writing took 6.974188179941848 seconds)
2020-10-13 11:17:56 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2020-10-13 11:17:56 | INFO | train | epoch 010 | loss 5.184 | nll_loss 3.663 | ppl 12.66 | wps 34621.9 | ups 2.28 | wpb 15167.8 | bsz 563.1 | num_updates 7560 | lr 0.000145479 | gnorm 0.721 | clip 0 | train_wall 289 | wall 3009
2020-10-13 11:17:56 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=11/shard_epoch=10
2020-10-13 11:17:56 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=11/shard_epoch=11
2020-10-13 11:17:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=22639.37890625Mb; avail=221889.06640625Mb
2020-10-13 11:17:56 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.013999
2020-10-13 11:17:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.173488
2020-10-13 11:17:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22648.09375Mb; avail=221880.3515625Mb
2020-10-13 11:17:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.008394
2020-10-13 11:17:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22650.36328125Mb; avail=221878.08203125Mb
2020-10-13 11:17:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.868551
2020-10-13 11:17:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.052779
2020-10-13 11:17:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22237.03515625Mb; avail=222291.10546875Mb
2020-10-13 11:17:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=22223.91015625Mb; avail=222304.23046875Mb
2020-10-13 11:17:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.095780
2020-10-13 11:17:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22224.9921875Mb; avail=222303.2734375Mb
2020-10-13 11:17:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.004655
2020-10-13 11:17:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22224.9921875Mb; avail=222303.2734375Mb
2020-10-13 11:18:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:03.265302
2020-10-13 11:18:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:03.366840
2020-10-13 11:18:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22989.6328125Mb; avail=221535.0859375Mb
2020-10-13 11:18:01 | INFO | fairseq.trainer | begin training epoch 11
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:18:22 | INFO | train_inner | epoch 011:     40 / 756 loss=5.092, nll_loss=3.558, ppl=11.78, wps=22933.2, ups=1.5, wpb=15321.8, bsz=579.4, num_updates=7600, lr=0.000145095, gnorm=0.687, clip=0, train_wall=38, wall=3035
2020-10-13 11:19:03 | INFO | train_inner | epoch 011:    140 / 756 loss=5.087, nll_loss=3.553, ppl=11.74, wps=37344.4, ups=2.46, wpb=15169.2, bsz=553.6, num_updates=7700, lr=0.00014415, gnorm=0.709, clip=0, train_wall=38, wall=3076
2020-10-13 11:19:44 | INFO | train_inner | epoch 011:    240 / 756 loss=5.06, nll_loss=3.522, ppl=11.48, wps=38021.1, ups=2.47, wpb=15383, bsz=591.4, num_updates=7800, lr=0.000143223, gnorm=0.73, clip=0, train_wall=38, wall=3116
2020-10-13 11:20:24 | INFO | train_inner | epoch 011:    340 / 756 loss=5.062, nll_loss=3.524, ppl=11.51, wps=37389.9, ups=2.5, wpb=14981.8, bsz=573.5, num_updates=7900, lr=0.000142314, gnorm=0.716, clip=0, train_wall=38, wall=3157
2020-10-13 11:21:02 | INFO | train_inner | epoch 011:    440 / 756 loss=5.077, nll_loss=3.541, ppl=11.64, wps=38915.7, ups=2.59, wpb=15026.4, bsz=534.2, num_updates=8000, lr=0.000141421, gnorm=0.719, clip=0, train_wall=37, wall=3195
2020-10-13 11:21:42 | INFO | train_inner | epoch 011:    540 / 756 loss=5.04, nll_loss=3.5, ppl=11.31, wps=38307.5, ups=2.52, wpb=15192.1, bsz=552.8, num_updates=8100, lr=0.000140546, gnorm=0.717, clip=0, train_wall=37, wall=3235
2020-10-13 11:22:23 | INFO | train_inner | epoch 011:    640 / 756 loss=5.02, nll_loss=3.477, ppl=11.14, wps=37222.7, ups=2.46, wpb=15119.9, bsz=558.4, num_updates=8200, lr=0.000139686, gnorm=0.687, clip=0, train_wall=38, wall=3275
2020-10-13 11:23:03 | INFO | train_inner | epoch 011:    740 / 756 loss=5.041, nll_loss=3.5, ppl=11.31, wps=37704.8, ups=2.47, wpb=15236.6, bsz=556.2, num_updates=8300, lr=0.000138842, gnorm=0.704, clip=0, train_wall=38, wall=3316
2020-10-13 11:23:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 11:23:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28374.71484375Mb; avail=216152.94921875Mb
2020-10-13 11:23:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003192
2020-10-13 11:23:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28374.71484375Mb; avail=216152.94921875Mb
2020-10-13 11:23:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.312431
2020-10-13 11:23:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28437.3671875Mb; avail=216090.70703125Mb
2020-10-13 11:23:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.160418
2020-10-13 11:23:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.477627
2020-10-13 11:23:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28439.54296875Mb; avail=216089.15234375Mb
2020-10-13 11:23:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28439.54296875Mb; avail=216089.15234375Mb
2020-10-13 11:23:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002089
2020-10-13 11:23:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28439.54296875Mb; avail=216089.15234375Mb
2020-10-13 11:23:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.137107
2020-10-13 11:23:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28439.54296875Mb; avail=216089.15234375Mb
2020-10-13 11:23:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.100564
2020-10-13 11:23:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.240980
2020-10-13 11:23:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28439.54296875Mb; avail=216089.15234375Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:23:18 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 5.012 | nll_loss 3.364 | ppl 10.29 | wps 70967.8 | wpb 4934.1 | bsz 184.1 | num_updates 8316 | best_loss 5.012
2020-10-13 11:23:18 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:23:25 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/checkpoint_best.pt (epoch 11 @ 8316 updates, score 5.012) (writing took 7.081135320942849 seconds)
2020-10-13 11:23:25 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2020-10-13 11:23:25 | INFO | train | epoch 011 | loss 5.053 | nll_loss 3.514 | ppl 11.43 | wps 34800.3 | ups 2.29 | wpb 15169 | bsz 563.1 | num_updates 8316 | lr 0.000138708 | gnorm 0.712 | clip 0 | train_wall 287 | wall 3338
2020-10-13 11:23:25 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=12/shard_epoch=11
2020-10-13 11:23:25 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=12/shard_epoch=12
2020-10-13 11:23:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28924.69140625Mb; avail=215604.1640625Mb
2020-10-13 11:23:25 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.007258
2020-10-13 11:23:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.107128
2020-10-13 11:23:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28923.91015625Mb; avail=215604.04296875Mb
2020-10-13 11:23:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.005071
2020-10-13 11:23:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28924.515625Mb; avail=215604.04296875Mb
2020-10-13 11:23:28 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.275533
2020-10-13 11:23:28 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.389118
2020-10-13 11:23:28 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29024.39453125Mb; avail=215504.1328125Mb
2020-10-13 11:23:28 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28919.046875Mb; avail=215610.95703125Mb
2020-10-13 11:23:28 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.080303
2020-10-13 11:23:28 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28938.53125Mb; avail=215590.6015625Mb
2020-10-13 11:23:28 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.006608
2020-10-13 11:23:28 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28944.5859375Mb; avail=215583.94140625Mb
2020-10-13 11:23:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.687657
2020-10-13 11:23:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.775964
2020-10-13 11:23:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27313.0703125Mb; avail=217215.2421875Mb
2020-10-13 11:23:30 | INFO | fairseq.trainer | begin training epoch 12
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:24:07 | INFO | train_inner | epoch 012:     84 / 756 loss=4.957, nll_loss=3.406, ppl=10.6, wps=23320.9, ups=1.55, wpb=15016.3, bsz=579, num_updates=8400, lr=0.000138013, gnorm=0.689, clip=0, train_wall=38, wall=3380
2020-10-13 11:24:48 | INFO | train_inner | epoch 012:    184 / 756 loss=4.978, nll_loss=3.429, ppl=10.77, wps=36882.3, ups=2.47, wpb=14921.9, bsz=590.4, num_updates=8500, lr=0.000137199, gnorm=0.723, clip=0, train_wall=38, wall=3421
2020-10-13 11:25:28 | INFO | train_inner | epoch 012:    284 / 756 loss=4.972, nll_loss=3.421, ppl=10.71, wps=37289.3, ups=2.47, wpb=15093, bsz=545.1, num_updates=8600, lr=0.000136399, gnorm=0.703, clip=0, train_wall=38, wall=3461
2020-10-13 11:26:09 | INFO | train_inner | epoch 012:    384 / 756 loss=4.957, nll_loss=3.405, ppl=10.59, wps=37570.7, ups=2.48, wpb=15170.6, bsz=539.4, num_updates=8700, lr=0.000135613, gnorm=0.665, clip=0, train_wall=38, wall=3502
2020-10-13 11:26:49 | INFO | train_inner | epoch 012:    484 / 756 loss=4.927, nll_loss=3.371, ppl=10.35, wps=37496.7, ups=2.45, wpb=15287.1, bsz=569.6, num_updates=8800, lr=0.00013484, gnorm=0.681, clip=0, train_wall=39, wall=3542
2020-10-13 11:27:30 | INFO | train_inner | epoch 012:    584 / 756 loss=4.927, nll_loss=3.372, ppl=10.35, wps=37387.7, ups=2.47, wpb=15114, bsz=589.3, num_updates=8900, lr=0.00013408, gnorm=0.701, clip=0, train_wall=38, wall=3583
2020-10-13 11:28:10 | INFO | train_inner | epoch 012:    684 / 756 loss=4.916, nll_loss=3.359, ppl=10.26, wps=37693.2, ups=2.47, wpb=15276.5, bsz=540.3, num_updates=9000, lr=0.000133333, gnorm=0.685, clip=0, train_wall=38, wall=3623
2020-10-13 11:28:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 11:28:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=30094.44921875Mb; avail=214433.56640625Mb
2020-10-13 11:28:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002140
2020-10-13 11:28:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=30094.44921875Mb; avail=214433.56640625Mb
2020-10-13 11:28:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.146600
2020-10-13 11:28:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=30094.83203125Mb; avail=214433.18359375Mb
2020-10-13 11:28:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.125896
2020-10-13 11:28:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.275729
2020-10-13 11:28:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=30098.87109375Mb; avail=214429.78515625Mb
2020-10-13 11:28:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=30100.44921875Mb; avail=214428.08984375Mb
2020-10-13 11:28:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001997
2020-10-13 11:28:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=30100.44921875Mb; avail=214428.08984375Mb
2020-10-13 11:28:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.229128
2020-10-13 11:28:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=30098.4765625Mb; avail=214429.90234375Mb
2020-10-13 11:28:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.220156
2020-10-13 11:28:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.452725
2020-10-13 11:28:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=30117.5Mb; avail=214410.875Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:28:49 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 4.934 | nll_loss 3.274 | ppl 9.67 | wps 69720 | wpb 4934.1 | bsz 184.1 | num_updates 9072 | best_loss 4.934
2020-10-13 11:28:49 | INFO | fairseq_cli.train | begin save checkpoint
2020-10-13 11:28:56 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/checkpoint_best.pt (epoch 12 @ 9072 updates, score 4.934) (writing took 6.60864520794712 seconds)
2020-10-13 11:28:56 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2020-10-13 11:28:56 | INFO | train | epoch 012 | loss 4.945 | nll_loss 3.392 | ppl 10.5 | wps 34681.8 | ups 2.29 | wpb 15171.9 | bsz 563.2 | num_updates 9072 | lr 0.000132803 | gnorm 0.691 | clip 0 | train_wall 289 | wall 3669
2020-10-13 11:28:56 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=13/shard_epoch=12
2020-10-13 11:28:56 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=13/shard_epoch=13
2020-10-13 11:28:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28274.36328125Mb; avail=216254.28125Mb
2020-10-13 11:28:56 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.013262
2020-10-13 11:28:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.173410
2020-10-13 11:28:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28368.96484375Mb; avail=216158.32421875Mb
2020-10-13 11:28:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.010720
2020-10-13 11:28:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28359.328125Mb; avail=216168.17578125Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:28:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.397479
2020-10-13 11:28:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.583297
2020-10-13 11:28:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28702.7421875Mb; avail=215826.04296875Mb
2020-10-13 11:28:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28686.0546875Mb; avail=215843.22265625Mb
2020-10-13 11:28:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.076723
2020-10-13 11:28:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28689.1953125Mb; avail=215839.58984375Mb
2020-10-13 11:28:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.004438
2020-10-13 11:28:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28689.1953125Mb; avail=215839.58984375Mb
2020-10-13 11:29:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.993358
2020-10-13 11:29:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:03.075643
2020-10-13 11:29:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27465.19140625Mb; avail=217063.1875Mb
2020-10-13 11:29:02 | INFO | fairseq.trainer | begin training epoch 13
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:29:17 | INFO | train_inner | epoch 013:     28 / 756 loss=4.922, nll_loss=3.366, ppl=10.31, wps=22751.3, ups=1.5, wpb=15211.6, bsz=561.8, num_updates=9100, lr=0.000132599, gnorm=0.688, clip=0, train_wall=38, wall=3690
2020-10-13 11:29:58 | INFO | train_inner | epoch 013:    128 / 756 loss=4.846, nll_loss=3.28, ppl=9.71, wps=37261.9, ups=2.48, wpb=15025.7, bsz=565.2, num_updates=9200, lr=0.000131876, gnorm=0.665, clip=0, train_wall=38, wall=3730
2020-10-13 11:30:38 | INFO | train_inner | epoch 013:    228 / 756 loss=4.864, nll_loss=3.3, ppl=9.85, wps=37642.5, ups=2.47, wpb=15218.1, bsz=576.6, num_updates=9300, lr=0.000131165, gnorm=0.684, clip=0, train_wall=38, wall=3771
2020-10-13 11:31:18 | INFO | train_inner | epoch 013:    328 / 756 loss=4.869, nll_loss=3.305, ppl=9.88, wps=37771.3, ups=2.47, wpb=15274.2, bsz=559.3, num_updates=9400, lr=0.000130466, gnorm=0.674, clip=0, train_wall=38, wall=3811
2020-10-13 11:31:59 | INFO | train_inner | epoch 013:    428 / 756 loss=4.874, nll_loss=3.312, ppl=9.93, wps=37732.1, ups=2.47, wpb=15252.9, bsz=567.4, num_updates=9500, lr=0.000129777, gnorm=0.693, clip=0, train_wall=38, wall=3852
2020-10-13 11:32:39 | INFO | train_inner | epoch 013:    528 / 756 loss=4.835, nll_loss=3.268, ppl=9.63, wps=37320.7, ups=2.46, wpb=15141.5, bsz=561.9, num_updates=9600, lr=0.000129099, gnorm=0.672, clip=0, train_wall=38, wall=3892
2020-10-13 11:33:20 | INFO | train_inner | epoch 013:    628 / 756 loss=4.841, nll_loss=3.275, ppl=9.68, wps=36792.4, ups=2.44, wpb=15101.8, bsz=558.7, num_updates=9700, lr=0.000128432, gnorm=0.664, clip=0, train_wall=39, wall=3933
2020-10-13 11:34:01 | INFO | train_inner | epoch 013:    728 / 756 loss=4.846, nll_loss=3.28, ppl=9.72, wps=37983.1, ups=2.47, wpb=15369.2, bsz=542.2, num_updates=9800, lr=0.000127775, gnorm=0.682, clip=0, train_wall=38, wall=3974
2020-10-13 11:34:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 11:34:12 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28007.796875Mb; avail=216519.71875Mb
2020-10-13 11:34:12 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003180
2020-10-13 11:34:12 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28008.12109375Mb; avail=216519.59765625Mb
2020-10-13 11:34:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.313321
2020-10-13 11:34:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28091.91796875Mb; avail=216436.43359375Mb
2020-10-13 11:34:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.216169
2020-10-13 11:34:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.534081
2020-10-13 11:34:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28217.61328125Mb; avail=216310.73828125Mb
2020-10-13 11:34:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28238.74609375Mb; avail=216289.60546875Mb
2020-10-13 11:34:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003011
2020-10-13 11:34:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28239.3515625Mb; avail=216289.0Mb
2020-10-13 11:34:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.307516
2020-10-13 11:34:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28346.48046875Mb; avail=216181.4375Mb
2020-10-13 11:34:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.212983
2020-10-13 11:34:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.525004
2020-10-13 11:34:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28440.8671875Mb; avail=216087.46484375Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:34:21 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 4.886 | nll_loss 3.22 | ppl 9.31 | wps 76129.2 | wpb 4934.1 | bsz 184.1 | num_updates 9828 | best_loss 4.886
2020-10-13 11:34:21 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:34:28 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/checkpoint_best.pt (epoch 13 @ 9828 updates, score 4.886) (writing took 7.013207139912993 seconds)
2020-10-13 11:34:29 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2020-10-13 11:34:29 | INFO | train | epoch 013 | loss 4.853 | nll_loss 3.288 | ppl 9.76 | wps 34469.6 | ups 2.27 | wpb 15167.8 | bsz 563.1 | num_updates 9828 | lr 0.000127593 | gnorm 0.678 | clip 0 | train_wall 289 | wall 4002
2020-10-13 11:34:29 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=14/shard_epoch=13
2020-10-13 11:34:29 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=14/shard_epoch=14
2020-10-13 11:34:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27732.640625Mb; avail=216795.84375Mb
2020-10-13 11:34:29 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.015137
2020-10-13 11:34:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.165530
2020-10-13 11:34:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27826.87109375Mb; avail=216701.0078125Mb
2020-10-13 11:34:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.007540
2020-10-13 11:34:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27830.50390625Mb; avail=216697.98046875Mb
2020-10-13 11:34:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.623478
2020-10-13 11:34:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.798192
2020-10-13 11:34:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28360.546875Mb; avail=216167.29296875Mb
2020-10-13 11:34:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28360.0546875Mb; avail=216167.78515625Mb
2020-10-13 11:34:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.076101
2020-10-13 11:34:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28360.0546875Mb; avail=216167.78515625Mb
2020-10-13 11:34:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.004979
2020-10-13 11:34:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28360.0546875Mb; avail=216167.78515625Mb
2020-10-13 11:34:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.083071
2020-10-13 11:34:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.165242
2020-10-13 11:34:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26903.04296875Mb; avail=217625.24609375Mb
2020-10-13 11:34:34 | INFO | fairseq.trainer | begin training epoch 14
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:35:07 | INFO | train_inner | epoch 014:     72 / 756 loss=4.776, nll_loss=3.201, ppl=9.2, wps=22843.9, ups=1.51, wpb=15092.1, bsz=589.8, num_updates=9900, lr=0.000127128, gnorm=0.681, clip=0, train_wall=38, wall=4040
2020-10-13 11:35:48 | INFO | train_inner | epoch 014:    172 / 756 loss=4.768, nll_loss=3.192, ppl=9.14, wps=36614.4, ups=2.47, wpb=14834.1, bsz=577.6, num_updates=10000, lr=0.000126491, gnorm=0.676, clip=0, train_wall=38, wall=4080
2020-10-13 11:36:28 | INFO | train_inner | epoch 014:    272 / 756 loss=4.779, nll_loss=3.204, ppl=9.21, wps=37903.5, ups=2.49, wpb=15246.4, bsz=547.8, num_updates=10100, lr=0.000125863, gnorm=0.665, clip=0, train_wall=38, wall=4121
2020-10-13 11:37:08 | INFO | train_inner | epoch 014:    372 / 756 loss=4.788, nll_loss=3.214, ppl=9.28, wps=36918.6, ups=2.46, wpb=14995.3, bsz=536.6, num_updates=10200, lr=0.000125245, gnorm=0.673, clip=0, train_wall=39, wall=4161
2020-10-13 11:37:48 | INFO | train_inner | epoch 014:    472 / 756 loss=4.776, nll_loss=3.201, ppl=9.2, wps=37712.3, ups=2.49, wpb=15131.6, bsz=548.6, num_updates=10300, lr=0.000124635, gnorm=0.694, clip=0, train_wall=38, wall=4201
2020-10-13 11:38:28 | INFO | train_inner | epoch 014:    572 / 756 loss=4.79, nll_loss=3.216, ppl=9.29, wps=38281, ups=2.5, wpb=15322.9, bsz=554.6, num_updates=10400, lr=0.000124035, gnorm=0.657, clip=0, train_wall=38, wall=4241
2020-10-13 11:39:08 | INFO | train_inner | epoch 014:    672 / 756 loss=4.771, nll_loss=3.194, ppl=9.15, wps=39105.8, ups=2.52, wpb=15509, bsz=582.6, num_updates=10500, lr=0.000123443, gnorm=0.669, clip=0, train_wall=38, wall=4281
2020-10-13 11:39:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 11:39:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=21205.73828125Mb; avail=223322.6328125Mb
2020-10-13 11:39:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002054
2020-10-13 11:39:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21205.73828125Mb; avail=223322.6328125Mb
2020-10-13 11:39:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.139920
2020-10-13 11:39:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21215.765625Mb; avail=223312.60546875Mb
2020-10-13 11:39:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.102454
2020-10-13 11:39:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.245353
2020-10-13 11:39:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21206.0546875Mb; avail=223322.31640625Mb
2020-10-13 11:39:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=21206.0546875Mb; avail=223322.31640625Mb
2020-10-13 11:39:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001818
2020-10-13 11:39:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21206.0546875Mb; avail=223322.31640625Mb
2020-10-13 11:39:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.139671
2020-10-13 11:39:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21206.359375Mb; avail=223322.9296875Mb
2020-10-13 11:39:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.102612
2020-10-13 11:39:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.244950
2020-10-13 11:39:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21205.23828125Mb; avail=223323.62109375Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:39:45 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 4.84 | nll_loss 3.168 | ppl 8.99 | wps 79475.6 | wpb 4934.1 | bsz 184.1 | num_updates 10584 | best_loss 4.84
2020-10-13 11:39:45 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:39:52 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/checkpoint_best.pt (epoch 14 @ 10584 updates, score 4.84) (writing took 6.600656633032486 seconds)
2020-10-13 11:39:52 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2020-10-13 11:39:52 | INFO | train | epoch 014 | loss 4.774 | nll_loss 3.198 | ppl 9.18 | wps 35479.4 | ups 2.34 | wpb 15168.9 | bsz 563.1 | num_updates 10584 | lr 0.000122952 | gnorm 0.669 | clip 0 | train_wall 284 | wall 4325
2020-10-13 11:39:52 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=15/shard_epoch=14
2020-10-13 11:39:52 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=15/shard_epoch=15
2020-10-13 11:39:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=22222.91796875Mb; avail=222304.80078125Mb
2020-10-13 11:39:52 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.015212
2020-10-13 11:39:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.139634
2020-10-13 11:39:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22242.50390625Mb; avail=222285.21484375Mb
2020-10-13 11:39:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.006394
2020-10-13 11:39:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22243.59375Mb; avail=222284.125Mb
2020-10-13 11:39:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.575267
2020-10-13 11:39:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.722611
2020-10-13 11:39:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22708.2578125Mb; avail=221820.2421875Mb
2020-10-13 11:39:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=22669.41015625Mb; avail=221859.08984375Mb
2020-10-13 11:39:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.072795
2020-10-13 11:39:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22667.41015625Mb; avail=221861.08984375Mb
2020-10-13 11:39:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.003671
2020-10-13 11:39:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22667.41015625Mb; avail=221861.08984375Mb
2020-10-13 11:39:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.388569
2020-10-13 11:39:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.466072
2020-10-13 11:39:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22939.62109375Mb; avail=221588.21875Mb
2020-10-13 11:39:57 | INFO | fairseq.trainer | begin training epoch 15
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:40:07 | INFO | train_inner | epoch 015:     16 / 756 loss=4.738, nll_loss=3.158, ppl=8.93, wps=25639.3, ups=1.69, wpb=15194.2, bsz=579, num_updates=10600, lr=0.000122859, gnorm=0.656, clip=0, train_wall=34, wall=4340
2020-10-13 11:40:47 | INFO | train_inner | epoch 015:    116 / 756 loss=4.715, nll_loss=3.132, ppl=8.77, wps=38501.9, ups=2.55, wpb=15121.7, bsz=565, num_updates=10700, lr=0.000122284, gnorm=0.677, clip=0, train_wall=37, wall=4380
2020-10-13 11:41:27 | INFO | train_inner | epoch 015:    216 / 756 loss=4.708, nll_loss=3.124, ppl=8.72, wps=37430.7, ups=2.47, wpb=15149, bsz=541.6, num_updates=10800, lr=0.000121716, gnorm=0.666, clip=0, train_wall=38, wall=4420
2020-10-13 11:42:08 | INFO | train_inner | epoch 015:    316 / 756 loss=4.696, nll_loss=3.11, ppl=8.64, wps=37523.5, ups=2.47, wpb=15206.8, bsz=574.4, num_updates=10900, lr=0.000121157, gnorm=0.668, clip=0, train_wall=38, wall=4461
2020-10-13 11:42:48 | INFO | train_inner | epoch 015:    416 / 756 loss=4.739, nll_loss=3.158, ppl=8.92, wps=37003.3, ups=2.46, wpb=15055.3, bsz=550.6, num_updates=11000, lr=0.000120605, gnorm=0.667, clip=0, train_wall=38, wall=4501
2020-10-13 11:43:29 | INFO | train_inner | epoch 015:    516 / 756 loss=4.685, nll_loss=3.098, ppl=8.56, wps=37525.6, ups=2.48, wpb=15156.8, bsz=578.3, num_updates=11100, lr=0.00012006, gnorm=0.67, clip=0, train_wall=38, wall=4542
2020-10-13 11:44:09 | INFO | train_inner | epoch 015:    616 / 756 loss=4.693, nll_loss=3.107, ppl=8.62, wps=37570.8, ups=2.48, wpb=15157.4, bsz=569.8, num_updates=11200, lr=0.000119523, gnorm=0.666, clip=0, train_wall=38, wall=4582
2020-10-13 11:44:50 | INFO | train_inner | epoch 015:    716 / 756 loss=4.712, nll_loss=3.128, ppl=8.74, wps=37625.3, ups=2.46, wpb=15303.1, bsz=554.9, num_updates=11300, lr=0.000118993, gnorm=0.672, clip=0, train_wall=38, wall=4623
2020-10-13 11:45:06 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 11:45:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27483.58203125Mb; avail=217044.3984375Mb
2020-10-13 11:45:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002168
2020-10-13 11:45:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27483.58203125Mb; avail=217044.3984375Mb
2020-10-13 11:45:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.139483
2020-10-13 11:45:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27482.84765625Mb; avail=217044.3984375Mb
2020-10-13 11:45:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.102424
2020-10-13 11:45:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.245115
2020-10-13 11:45:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27483.0390625Mb; avail=217044.640625Mb
2020-10-13 11:45:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27483.0390625Mb; avail=217044.640625Mb
2020-10-13 11:45:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001993
2020-10-13 11:45:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27483.0390625Mb; avail=217044.640625Mb
2020-10-13 11:45:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.179793
2020-10-13 11:45:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27556.96484375Mb; avail=216971.05078125Mb
2020-10-13 11:45:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.123744
2020-10-13 11:45:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.306858
2020-10-13 11:45:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27626.984375Mb; avail=216901.25390625Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:45:15 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 4.794 | nll_loss 3.117 | ppl 8.67 | wps 65071.9 | wpb 4934.1 | bsz 184.1 | num_updates 11340 | best_loss 4.794
2020-10-13 11:45:15 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:45:22 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/checkpoint_best.pt (epoch 15 @ 11340 updates, score 4.794) (writing took 7.105092706158757 seconds)
2020-10-13 11:45:22 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2020-10-13 11:45:22 | INFO | train | epoch 015 | loss 4.706 | nll_loss 3.122 | ppl 8.7 | wps 34712.5 | ups 2.29 | wpb 15170.1 | bsz 563.1 | num_updates 11340 | lr 0.000118783 | gnorm 0.671 | clip 0 | train_wall 288 | wall 4655
2020-10-13 11:45:22 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=16/shard_epoch=15
2020-10-13 11:45:22 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=16/shard_epoch=16
2020-10-13 11:45:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28076.6953125Mb; avail=216451.890625Mb
2020-10-13 11:45:22 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.016104
2020-10-13 11:45:23 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.171002
2020-10-13 11:45:23 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28088.83984375Mb; avail=216439.71875Mb
2020-10-13 11:45:23 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.008067
2020-10-13 11:45:23 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28089.4453125Mb; avail=216439.11328125Mb
2020-10-13 11:45:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.999575
2020-10-13 11:45:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.180325
2020-10-13 11:45:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28365.171875Mb; avail=216163.58984375Mb
2020-10-13 11:45:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28518.44140625Mb; avail=216009.109375Mb
2020-10-13 11:45:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.102123
2020-10-13 11:45:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28711.7890625Mb; avail=215816.97265625Mb
2020-10-13 11:45:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.005135
2020-10-13 11:45:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28707.1875Mb; avail=215823.05078125Mb
2020-10-13 11:45:27 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.990780
2020-10-13 11:45:27 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.099192
2020-10-13 11:45:27 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28831.05859375Mb; avail=215697.19921875Mb
2020-10-13 11:45:27 | INFO | fairseq.trainer | begin training epoch 16
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:45:56 | INFO | train_inner | epoch 016:     60 / 756 loss=4.665, nll_loss=3.075, ppl=8.43, wps=23211, ups=1.52, wpb=15299.7, bsz=559.2, num_updates=11400, lr=0.00011847, gnorm=0.681, clip=0, train_wall=38, wall=4689
2020-10-13 11:46:36 | INFO | train_inner | epoch 016:    160 / 756 loss=4.657, nll_loss=3.066, ppl=8.37, wps=37271.6, ups=2.48, wpb=15045.6, bsz=542.9, num_updates=11500, lr=0.000117954, gnorm=0.663, clip=0, train_wall=38, wall=4729
2020-10-13 11:47:17 | INFO | train_inner | epoch 016:    260 / 756 loss=4.625, nll_loss=3.029, ppl=8.16, wps=37442.5, ups=2.43, wpb=15385.1, bsz=599.8, num_updates=11600, lr=0.000117444, gnorm=0.667, clip=0, train_wall=38, wall=4770
2020-10-13 11:47:58 | INFO | train_inner | epoch 016:    360 / 756 loss=4.641, nll_loss=3.047, ppl=8.27, wps=37411.2, ups=2.46, wpb=15224.7, bsz=575.9, num_updates=11700, lr=0.000116941, gnorm=0.67, clip=0, train_wall=38, wall=4811
2020-10-13 11:48:39 | INFO | train_inner | epoch 016:    460 / 756 loss=4.639, nll_loss=3.046, ppl=8.26, wps=37549.2, ups=2.45, wpb=15308.1, bsz=571.4, num_updates=11800, lr=0.000116445, gnorm=0.67, clip=0, train_wall=39, wall=4852
2020-10-13 11:49:19 | INFO | train_inner | epoch 016:    560 / 756 loss=4.652, nll_loss=3.059, ppl=8.34, wps=37089, ups=2.46, wpb=15050.1, bsz=559, num_updates=11900, lr=0.000115954, gnorm=0.666, clip=0, train_wall=38, wall=4892
2020-10-13 11:49:59 | INFO | train_inner | epoch 016:    660 / 756 loss=4.65, nll_loss=3.058, ppl=8.33, wps=37045.3, ups=2.49, wpb=14881.3, bsz=549.3, num_updates=12000, lr=0.00011547, gnorm=0.664, clip=0, train_wall=38, wall=4932
2020-10-13 11:50:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 11:50:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28569.6328125Mb; avail=215958.6328125Mb
2020-10-13 11:50:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003117
2020-10-13 11:50:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28570.23828125Mb; avail=215958.02734375Mb
2020-10-13 11:50:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.231152
2020-10-13 11:50:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28996.046875Mb; avail=215532.21875Mb
2020-10-13 11:50:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.103427
2020-10-13 11:50:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.338915
2020-10-13 11:50:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29220.609375Mb; avail=215307.65625Mb
2020-10-13 11:50:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=29241.1953125Mb; avail=215287.0703125Mb
2020-10-13 11:50:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002048
2020-10-13 11:50:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29241.1953125Mb; avail=215287.0703125Mb
2020-10-13 11:50:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.137013
2020-10-13 11:50:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29512.6640625Mb; avail=215015.6015625Mb
2020-10-13 11:50:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.101461
2020-10-13 11:50:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.241624
2020-10-13 11:50:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29711.1875Mb; avail=214817.1796875Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:50:47 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 4.757 | nll_loss 3.073 | ppl 8.42 | wps 64738.8 | wpb 4934.1 | bsz 184.1 | num_updates 12096 | best_loss 4.757
2020-10-13 11:50:47 | INFO | fairseq_cli.train | begin save checkpoint
2020-10-13 11:50:54 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/checkpoint_best.pt (epoch 16 @ 12096 updates, score 4.757) (writing took 6.497020029928535 seconds)
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:50:54 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2020-10-13 11:50:54 | INFO | train | epoch 016 | loss 4.646 | nll_loss 3.053 | ppl 8.3 | wps 34543.9 | ups 2.28 | wpb 15167.9 | bsz 563.1 | num_updates 12096 | lr 0.000115011 | gnorm 0.667 | clip 0 | train_wall 289 | wall 4987
2020-10-13 11:50:54 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=17/shard_epoch=16
2020-10-13 11:50:54 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=17/shard_epoch=17
2020-10-13 11:50:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28281.921875Mb; avail=216246.9375Mb
2020-10-13 11:50:54 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.016801
2020-10-13 11:50:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.170541
2020-10-13 11:50:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28324.15625Mb; avail=216204.484375Mb
2020-10-13 11:50:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.008520
2020-10-13 11:50:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28324.6484375Mb; avail=216203.38671875Mb
2020-10-13 11:50:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.566792
2020-10-13 11:50:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.747427
2020-10-13 11:50:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27230.3671875Mb; avail=217298.25Mb
2020-10-13 11:50:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27228.83984375Mb; avail=217300.375Mb
2020-10-13 11:50:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.076525
2020-10-13 11:50:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27235.55859375Mb; avail=217293.1640625Mb
2020-10-13 11:50:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.004581
2020-10-13 11:50:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27236.1640625Mb; avail=217292.55859375Mb
2020-10-13 11:51:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.261829
2020-10-13 11:51:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.344209
2020-10-13 11:51:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27950.23046875Mb; avail=216577.92578125Mb
2020-10-13 11:51:00 | INFO | fairseq.trainer | begin training epoch 17
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:51:06 | INFO | train_inner | epoch 017:      4 / 756 loss=4.652, nll_loss=3.06, ppl=8.34, wps=22884.1, ups=1.51, wpb=15163.3, bsz=556.2, num_updates=12100, lr=0.000114992, gnorm=0.659, clip=0, train_wall=39, wall=4999
2020-10-13 11:51:46 | INFO | train_inner | epoch 017:    104 / 756 loss=4.589, nll_loss=2.988, ppl=7.94, wps=37643.7, ups=2.47, wpb=15249.5, bsz=555, num_updates=12200, lr=0.00011452, gnorm=0.652, clip=0, train_wall=38, wall=5039
2020-10-13 11:52:27 | INFO | train_inner | epoch 017:    204 / 756 loss=4.615, nll_loss=3.018, ppl=8.1, wps=36980.9, ups=2.45, wpb=15112, bsz=548.1, num_updates=12300, lr=0.000114053, gnorm=0.658, clip=0, train_wall=38, wall=5080
2020-10-13 11:53:08 | INFO | train_inner | epoch 017:    304 / 756 loss=4.554, nll_loss=2.95, ppl=7.73, wps=37018.4, ups=2.44, wpb=15165.9, bsz=598.6, num_updates=12400, lr=0.000113592, gnorm=0.668, clip=0, train_wall=39, wall=5121
2020-10-13 11:53:48 | INFO | train_inner | epoch 017:    404 / 756 loss=4.612, nll_loss=3.014, ppl=8.08, wps=37866.6, ups=2.47, wpb=15305.5, bsz=542.2, num_updates=12500, lr=0.000113137, gnorm=0.659, clip=0, train_wall=38, wall=5161
2020-10-13 11:54:29 | INFO | train_inner | epoch 017:    504 / 756 loss=4.592, nll_loss=2.992, ppl=7.95, wps=37764.4, ups=2.49, wpb=15174.5, bsz=581.6, num_updates=12600, lr=0.000112687, gnorm=0.687, clip=0, train_wall=38, wall=5202
2020-10-13 11:55:09 | INFO | train_inner | epoch 017:    604 / 756 loss=4.602, nll_loss=3.003, ppl=8.02, wps=37363, ups=2.48, wpb=15046.9, bsz=533.4, num_updates=12700, lr=0.000112243, gnorm=0.667, clip=0, train_wall=38, wall=5242
2020-10-13 11:55:49 | INFO | train_inner | epoch 017:    704 / 756 loss=4.581, nll_loss=2.979, ppl=7.89, wps=37581.9, ups=2.48, wpb=15180.3, bsz=572.1, num_updates=12800, lr=0.000111803, gnorm=0.643, clip=0, train_wall=38, wall=5282
2020-10-13 11:56:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 11:56:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27484.83203125Mb; avail=217042.6328125Mb
2020-10-13 11:56:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002110
2020-10-13 11:56:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27484.83203125Mb; avail=217042.6328125Mb
2020-10-13 11:56:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.157121
2020-10-13 11:56:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27494.12890625Mb; avail=217033.51171875Mb
2020-10-13 11:56:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.128722
2020-10-13 11:56:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.289003
2020-10-13 11:56:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27495.55078125Mb; avail=217032.49609375Mb
2020-10-13 11:56:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27496.0703125Mb; avail=217031.9765625Mb
2020-10-13 11:56:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001987
2020-10-13 11:56:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27496.0703125Mb; avail=217031.9765625Mb
2020-10-13 11:56:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.218383
2020-10-13 11:56:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27485.734375Mb; avail=217042.3125Mb
2020-10-13 11:56:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.101626
2020-10-13 11:56:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.323289
2020-10-13 11:56:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27485.734375Mb; avail=217042.3125Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:56:19 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 4.729 | nll_loss 3.04 | ppl 8.23 | wps 73604.4 | wpb 4934.1 | bsz 184.1 | num_updates 12852 | best_loss 4.729
2020-10-13 11:56:19 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:56:26 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/checkpoint_best.pt (epoch 17 @ 12852 updates, score 4.729) (writing took 6.604714043904096 seconds)
2020-10-13 11:56:26 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2020-10-13 11:56:26 | INFO | train | epoch 017 | loss 4.591 | nll_loss 2.991 | ppl 7.95 | wps 34561.6 | ups 2.28 | wpb 15168 | bsz 563.2 | num_updates 12852 | lr 0.000111577 | gnorm 0.662 | clip 0 | train_wall 289 | wall 5319
2020-10-13 11:56:26 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=18/shard_epoch=17
2020-10-13 11:56:26 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=18/shard_epoch=18
2020-10-13 11:56:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27235.3359375Mb; avail=217292.66796875Mb
2020-10-13 11:56:26 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.015187
2020-10-13 11:56:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.183383
2020-10-13 11:56:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27248.8125Mb; avail=217279.58984375Mb
2020-10-13 11:56:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.007890
2020-10-13 11:56:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27248.8125Mb; avail=217279.58984375Mb
2020-10-13 11:56:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:03.159480
2020-10-13 11:56:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:03.352546
2020-10-13 11:56:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28373.81640625Mb; avail=216154.61328125Mb
2020-10-13 11:56:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28444.66796875Mb; avail=216083.76171875Mb
2020-10-13 11:56:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.123950
2020-10-13 11:56:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28444.66796875Mb; avail=216083.76171875Mb
2020-10-13 11:56:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.007941
2020-10-13 11:56:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28444.66796875Mb; avail=216083.76171875Mb
2020-10-13 11:56:33 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.780037
2020-10-13 11:56:33 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.913930
2020-10-13 11:56:33 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28694.48828125Mb; avail=215834.05859375Mb
2020-10-13 11:56:33 | INFO | fairseq.trainer | begin training epoch 18
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 11:56:56 | INFO | train_inner | epoch 018:     48 / 756 loss=4.541, nll_loss=2.935, ppl=7.65, wps=22521.9, ups=1.49, wpb=15129.2, bsz=598.1, num_updates=12900, lr=0.000111369, gnorm=0.648, clip=0, train_wall=38, wall=5349
2020-10-13 11:57:36 | INFO | train_inner | epoch 018:    148 / 756 loss=4.544, nll_loss=2.938, ppl=7.66, wps=38021.6, ups=2.5, wpb=15191, bsz=543.9, num_updates=13000, lr=0.00011094, gnorm=0.679, clip=0, train_wall=38, wall=5389
2020-10-13 11:58:16 | INFO | train_inner | epoch 018:    248 / 756 loss=4.556, nll_loss=2.951, ppl=7.73, wps=38341.7, ups=2.53, wpb=15154.2, bsz=541.8, num_updates=13100, lr=0.000110516, gnorm=0.665, clip=0, train_wall=37, wall=5429
2020-10-13 11:58:52 | INFO | train_inner | epoch 018:    348 / 756 loss=4.541, nll_loss=2.934, ppl=7.64, wps=41893.3, ups=2.76, wpb=15152.5, bsz=576.7, num_updates=13200, lr=0.000110096, gnorm=0.667, clip=0, train_wall=34, wall=5465
2020-10-13 11:59:31 | INFO | train_inner | epoch 018:    448 / 756 loss=4.534, nll_loss=2.926, ppl=7.6, wps=39174.3, ups=2.56, wpb=15286.6, bsz=564.7, num_updates=13300, lr=0.000109682, gnorm=0.647, clip=0, train_wall=37, wall=5504
2020-10-13 12:00:11 | INFO | train_inner | epoch 018:    548 / 756 loss=4.535, nll_loss=2.928, ppl=7.61, wps=37544.8, ups=2.5, wpb=15007.1, bsz=569.2, num_updates=13400, lr=0.000109272, gnorm=0.686, clip=0, train_wall=38, wall=5544
2020-10-13 12:00:52 | INFO | train_inner | epoch 018:    648 / 756 loss=4.554, nll_loss=2.949, ppl=7.72, wps=37481.7, ups=2.45, wpb=15283, bsz=554.8, num_updates=13500, lr=0.000108866, gnorm=0.655, clip=0, train_wall=39, wall=5585
2020-10-13 12:01:33 | INFO | train_inner | epoch 018:    748 / 756 loss=4.545, nll_loss=2.938, ppl=7.67, wps=36896.7, ups=2.43, wpb=15165.1, bsz=573.1, num_updates=13600, lr=0.000108465, gnorm=0.666, clip=0, train_wall=39, wall=5626
2020-10-13 12:01:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 12:01:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28317.65625Mb; avail=216210.24609375Mb
2020-10-13 12:01:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002040
2020-10-13 12:01:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28317.65625Mb; avail=216210.24609375Mb
2020-10-13 12:01:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.162668
2020-10-13 12:01:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28327.890625Mb; avail=216199.7890625Mb
2020-10-13 12:01:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.219694
2020-10-13 12:01:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.385707
2020-10-13 12:01:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28318.18359375Mb; avail=216209.7890625Mb
2020-10-13 12:01:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28321.16015625Mb; avail=216206.8125Mb
2020-10-13 12:01:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002933
2020-10-13 12:01:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28321.765625Mb; avail=216206.20703125Mb
2020-10-13 12:01:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.311050
2020-10-13 12:01:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27656.5625Mb; avail=216871.6328125Mb
2020-10-13 12:01:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.275897
2020-10-13 12:01:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.591963
2020-10-13 12:01:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27662.91015625Mb; avail=216865.703125Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:01:45 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 4.699 | nll_loss 3.009 | ppl 8.05 | wps 73477.9 | wpb 4934.1 | bsz 184.1 | num_updates 13608 | best_loss 4.699
2020-10-13 12:01:45 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:01:52 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/checkpoint_best.pt (epoch 18 @ 13608 updates, score 4.699) (writing took 7.10337409703061 seconds)
2020-10-13 12:01:52 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2020-10-13 12:01:52 | INFO | train | epoch 018 | loss 4.543 | nll_loss 2.936 | ppl 7.65 | wps 35134.8 | ups 2.32 | wpb 15167.5 | bsz 562.9 | num_updates 13608 | lr 0.000108433 | gnorm 0.665 | clip 0 | train_wall 283 | wall 5645
2020-10-13 12:01:52 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=19/shard_epoch=18
2020-10-13 12:01:52 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=19/shard_epoch=19
2020-10-13 12:01:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28081.7578125Mb; avail=216446.515625Mb
2020-10-13 12:01:53 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.014532
2020-10-13 12:01:53 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.162694
2020-10-13 12:01:53 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28099.85546875Mb; avail=216428.41796875Mb
2020-10-13 12:01:53 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.008796
2020-10-13 12:01:53 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28100.34765625Mb; avail=216427.3203125Mb
2020-10-13 12:01:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.760067
2020-10-13 12:01:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.933275
2020-10-13 12:01:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27083.296875Mb; avail=217444.97265625Mb
2020-10-13 12:01:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27065.234375Mb; avail=217462.91796875Mb
2020-10-13 12:01:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.079346
2020-10-13 12:01:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27073.62890625Mb; avail=217454.5234375Mb
2020-10-13 12:01:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.005220
2020-10-13 12:01:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27076.65625Mb; avail=217451.49609375Mb
2020-10-13 12:01:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.810316
2020-10-13 12:01:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.896049
2020-10-13 12:01:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27346.90234375Mb; avail=217181.140625Mb
2020-10-13 12:01:58 | INFO | fairseq.trainer | begin training epoch 19
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:02:40 | INFO | train_inner | epoch 019:     92 / 756 loss=4.503, nll_loss=2.892, ppl=7.42, wps=22625.6, ups=1.5, wpb=15065, bsz=540.7, num_updates=13700, lr=0.000108069, gnorm=0.674, clip=0, train_wall=38, wall=5692
2020-10-13 12:03:20 | INFO | train_inner | epoch 019:    192 / 756 loss=4.504, nll_loss=2.893, ppl=7.43, wps=37719.3, ups=2.48, wpb=15225.5, bsz=574.4, num_updates=13800, lr=0.000107676, gnorm=0.668, clip=0, train_wall=38, wall=5733
2020-10-13 12:04:00 | INFO | train_inner | epoch 019:    292 / 756 loss=4.485, nll_loss=2.871, ppl=7.32, wps=37478.6, ups=2.48, wpb=15104.8, bsz=545.2, num_updates=13900, lr=0.000107288, gnorm=0.65, clip=0, train_wall=38, wall=5773
2020-10-13 12:04:41 | INFO | train_inner | epoch 019:    392 / 756 loss=4.508, nll_loss=2.896, ppl=7.44, wps=37476.3, ups=2.44, wpb=15340.9, bsz=561.7, num_updates=14000, lr=0.000106904, gnorm=0.641, clip=0, train_wall=39, wall=5814
2020-10-13 12:05:22 | INFO | train_inner | epoch 019:    492 / 756 loss=4.479, nll_loss=2.865, ppl=7.28, wps=37477.1, ups=2.45, wpb=15275.7, bsz=591, num_updates=14100, lr=0.000106525, gnorm=0.655, clip=0, train_wall=39, wall=5855
2020-10-13 12:06:03 | INFO | train_inner | epoch 019:    592 / 756 loss=4.514, nll_loss=2.904, ppl=7.48, wps=37230.7, ups=2.44, wpb=15249, bsz=548.1, num_updates=14200, lr=0.000106149, gnorm=0.646, clip=0, train_wall=39, wall=5896
2020-10-13 12:06:44 | INFO | train_inner | epoch 019:    692 / 756 loss=4.503, nll_loss=2.891, ppl=7.42, wps=36814.2, ups=2.45, wpb=15011.5, bsz=580.1, num_updates=14300, lr=0.000105777, gnorm=0.665, clip=0, train_wall=38, wall=5937
2020-10-13 12:07:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 12:07:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27146.96875Mb; avail=217381.20703125Mb
2020-10-13 12:07:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003253
2020-10-13 12:07:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27146.96875Mb; avail=217381.20703125Mb
2020-10-13 12:07:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.311120
2020-10-13 12:07:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27264.828125Mb; avail=217263.34765625Mb
2020-10-13 12:07:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.104550
2020-10-13 12:07:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.420447
2020-10-13 12:07:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27333.90234375Mb; avail=217194.2734375Mb
2020-10-13 12:07:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27363.91796875Mb; avail=217164.4609375Mb
2020-10-13 12:07:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002816
2020-10-13 12:07:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27368.76171875Mb; avail=217159.6171875Mb
2020-10-13 12:07:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.162447
2020-10-13 12:07:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27464.8203125Mb; avail=217063.04296875Mb
2020-10-13 12:07:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.101506
2020-10-13 12:07:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.268054
2020-10-13 12:07:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27520.26953125Mb; avail=217007.65625Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:07:19 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 4.678 | nll_loss 2.985 | ppl 7.92 | wps 67855.6 | wpb 4934.1 | bsz 184.1 | num_updates 14364 | best_loss 4.678
2020-10-13 12:07:19 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:07:25 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/checkpoint_best.pt (epoch 19 @ 14364 updates, score 4.678) (writing took 6.610185537021607 seconds)
2020-10-13 12:07:26 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2020-10-13 12:07:26 | INFO | train | epoch 019 | loss 4.498 | nll_loss 2.886 | ppl 7.39 | wps 34419.2 | ups 2.27 | wpb 15167.9 | bsz 563 | num_updates 14364 | lr 0.000105541 | gnorm 0.658 | clip 0 | train_wall 291 | wall 5979
2020-10-13 12:07:26 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=20/shard_epoch=19
2020-10-13 12:07:26 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=20/shard_epoch=20
2020-10-13 12:07:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27306.8125Mb; avail=217221.4765625Mb
2020-10-13 12:07:26 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.014762
2020-10-13 12:07:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.162098
2020-10-13 12:07:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27314.80859375Mb; avail=217213.48046875Mb
2020-10-13 12:07:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.007824
2020-10-13 12:07:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27314.80859375Mb; avail=217213.48046875Mb
2020-10-13 12:07:28 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.650004
2020-10-13 12:07:28 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.821479
2020-10-13 12:07:28 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26977.61328125Mb; avail=217550.86328125Mb
2020-10-13 12:07:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=26932.578125Mb; avail=217595.8984375Mb
2020-10-13 12:07:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.103870
2020-10-13 12:07:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26937.6640625Mb; avail=217590.8125Mb
2020-10-13 12:07:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.005031
2020-10-13 12:07:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=26937.6640625Mb; avail=217590.8125Mb
2020-10-13 12:07:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.280689
2020-10-13 12:07:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.390802
2020-10-13 12:07:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27608.890625Mb; avail=216919.23828125Mb
2020-10-13 12:07:31 | INFO | fairseq.trainer | begin training epoch 20
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:07:50 | INFO | train_inner | epoch 020:     36 / 756 loss=4.474, nll_loss=2.859, ppl=7.26, wps=22683.4, ups=1.51, wpb=15022.3, bsz=575.1, num_updates=14400, lr=0.000105409, gnorm=0.675, clip=0, train_wall=38, wall=6003
2020-10-13 12:08:30 | INFO | train_inner | epoch 020:    136 / 756 loss=4.452, nll_loss=2.833, ppl=7.12, wps=37309.6, ups=2.47, wpb=15123.2, bsz=543, num_updates=14500, lr=0.000105045, gnorm=0.651, clip=0, train_wall=38, wall=6043
2020-10-13 12:09:11 | INFO | train_inner | epoch 020:    236 / 756 loss=4.442, nll_loss=2.823, ppl=7.08, wps=37389, ups=2.45, wpb=15253, bsz=605.5, num_updates=14600, lr=0.000104685, gnorm=0.681, clip=0, train_wall=38, wall=6084
2020-10-13 12:09:51 | INFO | train_inner | epoch 020:    336 / 756 loss=4.448, nll_loss=2.829, ppl=7.11, wps=37491.6, ups=2.49, wpb=15068.8, bsz=587, num_updates=14700, lr=0.000104328, gnorm=0.672, clip=0, train_wall=38, wall=6124
2020-10-13 12:10:32 | INFO | train_inner | epoch 020:    436 / 756 loss=4.467, nll_loss=2.85, ppl=7.21, wps=37285.4, ups=2.47, wpb=15105.4, bsz=548.2, num_updates=14800, lr=0.000103975, gnorm=0.662, clip=0, train_wall=38, wall=6165
2020-10-13 12:11:13 | INFO | train_inner | epoch 020:    536 / 756 loss=4.452, nll_loss=2.833, ppl=7.13, wps=37500.1, ups=2.45, wpb=15308.8, bsz=544.2, num_updates=14900, lr=0.000103626, gnorm=0.65, clip=0, train_wall=39, wall=6206
2020-10-13 12:11:54 | INFO | train_inner | epoch 020:    636 / 756 loss=4.469, nll_loss=2.853, ppl=7.22, wps=37223.5, ups=2.45, wpb=15200, bsz=535.7, num_updates=15000, lr=0.00010328, gnorm=0.663, clip=0, train_wall=38, wall=6247
2020-10-13 12:12:34 | INFO | train_inner | epoch 020:    736 / 756 loss=4.466, nll_loss=2.849, ppl=7.21, wps=37158.2, ups=2.45, wpb=15141.4, bsz=573.2, num_updates=15100, lr=0.000102937, gnorm=0.659, clip=0, train_wall=38, wall=6287
2020-10-13 12:12:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 12:12:42 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28501.67578125Mb; avail=216025.45703125Mb
2020-10-13 12:12:42 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003288
2020-10-13 12:12:42 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28502.28125Mb; avail=216024.8515625Mb
2020-10-13 12:12:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.320921
2020-10-13 12:12:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28506.62890625Mb; avail=216021.5Mb
2020-10-13 12:12:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.126629
2020-10-13 12:12:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.452407
2020-10-13 12:12:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28503.21875Mb; avail=216024.91015625Mb
2020-10-13 12:12:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28503.21875Mb; avail=216024.91015625Mb
2020-10-13 12:12:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002024
2020-10-13 12:12:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28503.71875Mb; avail=216024.41015625Mb
2020-10-13 12:12:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.141822
2020-10-13 12:12:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28513.59375Mb; avail=216014.53515625Mb
2020-10-13 12:12:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.217841
2020-10-13 12:12:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.362751
2020-10-13 12:12:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28512.3203125Mb; avail=216015.69921875Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:12:51 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 4.663 | nll_loss 2.968 | ppl 7.82 | wps 73774.9 | wpb 4934.1 | bsz 184.1 | num_updates 15120 | best_loss 4.663
2020-10-13 12:12:51 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:12:58 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/checkpoint_best.pt (epoch 20 @ 15120 updates, score 4.663) (writing took 7.004032771103084 seconds)
2020-10-13 12:12:58 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2020-10-13 12:12:58 | INFO | train | epoch 020 | loss 4.457 | nll_loss 2.839 | ppl 7.16 | wps 34459.8 | ups 2.27 | wpb 15167.8 | bsz 563.1 | num_updates 15120 | lr 0.000102869 | gnorm 0.663 | clip 0 | train_wall 289 | wall 6311
2020-10-13 12:12:58 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=21/shard_epoch=20
2020-10-13 12:12:58 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=21/shard_epoch=21
2020-10-13 12:12:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27660.75Mb; avail=216867.69921875Mb
2020-10-13 12:12:58 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.016529
2020-10-13 12:12:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.164322
2020-10-13 12:12:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27765.2421875Mb; avail=216763.29296875Mb
2020-10-13 12:12:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.007926
2020-10-13 12:12:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27765.2421875Mb; avail=216763.29296875Mb
2020-10-13 12:13:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.643137
2020-10-13 12:13:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.817132
2020-10-13 12:13:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28518.796875Mb; avail=216009.47265625Mb
2020-10-13 12:13:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28529.26953125Mb; avail=215998.890625Mb
2020-10-13 12:13:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.078405
2020-10-13 12:13:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28528.34375Mb; avail=216000.03125Mb
2020-10-13 12:13:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.004980
2020-10-13 12:13:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28528.34375Mb; avail=216000.03125Mb
2020-10-13 12:13:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.049802
2020-10-13 12:13:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.134518
2020-10-13 12:13:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27862.5546875Mb; avail=216665.54296875Mb
2020-10-13 12:13:03 | INFO | fairseq.trainer | begin training epoch 21
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:13:40 | INFO | train_inner | epoch 021:     80 / 756 loss=4.416, nll_loss=2.794, ppl=6.93, wps=22927.1, ups=1.52, wpb=15051.2, bsz=514.1, num_updates=15200, lr=0.000102598, gnorm=0.672, clip=0, train_wall=38, wall=6353
2020-10-13 12:14:21 | INFO | train_inner | epoch 021:    180 / 756 loss=4.413, nll_loss=2.789, ppl=6.91, wps=37678.6, ups=2.46, wpb=15314.5, bsz=592.3, num_updates=15300, lr=0.000102262, gnorm=0.659, clip=0, train_wall=38, wall=6394
2020-10-13 12:15:01 | INFO | train_inner | epoch 021:    280 / 756 loss=4.44, nll_loss=2.82, ppl=7.06, wps=37306.4, ups=2.45, wpb=15197.7, bsz=552.1, num_updates=15400, lr=0.000101929, gnorm=0.672, clip=0, train_wall=38, wall=6434
2020-10-13 12:15:42 | INFO | train_inner | epoch 021:    380 / 756 loss=4.423, nll_loss=2.799, ppl=6.96, wps=37497.5, ups=2.46, wpb=15254.6, bsz=595.2, num_updates=15500, lr=0.0001016, gnorm=0.655, clip=0, train_wall=38, wall=6475
2020-10-13 12:16:23 | INFO | train_inner | epoch 021:    480 / 756 loss=4.418, nll_loss=2.796, ppl=6.94, wps=37536.6, ups=2.47, wpb=15190.4, bsz=573.4, num_updates=15600, lr=0.000101274, gnorm=0.656, clip=0, train_wall=38, wall=6515
2020-10-13 12:17:03 | INFO | train_inner | epoch 021:    580 / 756 loss=4.444, nll_loss=2.823, ppl=7.08, wps=38093.4, ups=2.5, wpb=15248.6, bsz=538.5, num_updates=15700, lr=0.000100951, gnorm=0.65, clip=0, train_wall=38, wall=6555
2020-10-13 12:17:40 | INFO | train_inner | epoch 021:    680 / 756 loss=4.415, nll_loss=2.792, ppl=6.92, wps=40243.2, ups=2.69, wpb=14954.5, bsz=547.7, num_updates=15800, lr=0.000100631, gnorm=0.688, clip=0, train_wall=35, wall=6593
2020-10-13 12:18:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 12:18:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=21693.97265625Mb; avail=222834.17578125Mb
2020-10-13 12:18:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002137
2020-10-13 12:18:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21693.97265625Mb; avail=222834.17578125Mb
2020-10-13 12:18:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.229985
2020-10-13 12:18:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21715.75390625Mb; avail=222812.39453125Mb
2020-10-13 12:18:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.174990
2020-10-13 12:18:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.408325
2020-10-13 12:18:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21729.6796875Mb; avail=222798.46875Mb
2020-10-13 12:18:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=21736.453125Mb; avail=222791.6953125Mb
2020-10-13 12:18:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002522
2020-10-13 12:18:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21736.453125Mb; avail=222791.6953125Mb
2020-10-13 12:18:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.215699
2020-10-13 12:18:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21763.9921875Mb; avail=222763.93359375Mb
2020-10-13 12:18:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.131808
2020-10-13 12:18:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.351162
2020-10-13 12:18:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21765.5078125Mb; avail=222762.18359375Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:18:16 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 4.637 | nll_loss 2.939 | ppl 7.67 | wps 72849.9 | wpb 4934.1 | bsz 184.1 | num_updates 15876 | best_loss 4.637
2020-10-13 12:18:16 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:18:22 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/checkpoint_best.pt (epoch 21 @ 15876 updates, score 4.637) (writing took 6.509688953869045 seconds)
2020-10-13 12:18:23 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2020-10-13 12:18:23 | INFO | train | epoch 021 | loss 4.42 | nll_loss 2.797 | ppl 6.95 | wps 35360.2 | ups 2.33 | wpb 15167.9 | bsz 563.1 | num_updates 15876 | lr 0.00010039 | gnorm 0.662 | clip 0 | train_wall 283 | wall 6636
2020-10-13 12:18:23 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=22/shard_epoch=21
2020-10-13 12:18:23 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=22/shard_epoch=22
2020-10-13 12:18:23 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=23974.82421875Mb; avail=220553.34765625Mb
2020-10-13 12:18:23 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.017241
2020-10-13 12:18:23 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.169823
2020-10-13 12:18:23 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23968.609375Mb; avail=220559.5625Mb
2020-10-13 12:18:23 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.008807
2020-10-13 12:18:23 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23969.8203125Mb; avail=220558.3515625Mb
2020-10-13 12:18:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.339859
2020-10-13 12:18:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.520194
2020-10-13 12:18:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23524.01171875Mb; avail=221004.5625Mb
2020-10-13 12:18:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=23545.45703125Mb; avail=220983.27734375Mb
2020-10-13 12:18:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.074699
2020-10-13 12:18:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23512.7578125Mb; avail=221015.4765625Mb
2020-10-13 12:18:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.003624
2020-10-13 12:18:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23514.57421875Mb; avail=221013.66015625Mb
2020-10-13 12:18:27 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.851440
2020-10-13 12:18:27 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.930885
2020-10-13 12:18:27 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23907.6796875Mb; avail=220620.05078125Mb
2020-10-13 12:18:27 | INFO | fairseq.trainer | begin training epoch 22
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:18:40 | INFO | train_inner | epoch 022:     24 / 756 loss=4.403, nll_loss=2.779, ppl=6.86, wps=24724.2, ups=1.66, wpb=14930.6, bsz=559.4, num_updates=15900, lr=0.000100314, gnorm=0.662, clip=0, train_wall=35, wall=6653
2020-10-13 12:19:20 | INFO | train_inner | epoch 022:    124 / 756 loss=4.38, nll_loss=2.751, ppl=6.73, wps=37380.2, ups=2.49, wpb=15006, bsz=569.8, num_updates=16000, lr=0.0001, gnorm=0.659, clip=0, train_wall=38, wall=6693
2020-10-13 12:20:01 | INFO | train_inner | epoch 022:    224 / 756 loss=4.392, nll_loss=2.766, ppl=6.8, wps=37611.7, ups=2.46, wpb=15282.7, bsz=551.2, num_updates=16100, lr=9.9689e-05, gnorm=0.655, clip=0, train_wall=38, wall=6734
2020-10-13 12:20:42 | INFO | train_inner | epoch 022:    324 / 756 loss=4.375, nll_loss=2.746, ppl=6.71, wps=37245.1, ups=2.45, wpb=15184.3, bsz=567.3, num_updates=16200, lr=9.93808e-05, gnorm=0.656, clip=0, train_wall=39, wall=6775
2020-10-13 12:21:22 | INFO | train_inner | epoch 022:    424 / 756 loss=4.4, nll_loss=2.774, ppl=6.84, wps=37711.1, ups=2.47, wpb=15246.3, bsz=540.7, num_updates=16300, lr=9.90755e-05, gnorm=0.647, clip=0, train_wall=38, wall=6815
2020-10-13 12:22:02 | INFO | train_inner | epoch 022:    524 / 756 loss=4.385, nll_loss=2.757, ppl=6.76, wps=37790.2, ups=2.48, wpb=15237, bsz=555, num_updates=16400, lr=9.8773e-05, gnorm=0.651, clip=0, train_wall=38, wall=6855
2020-10-13 12:22:43 | INFO | train_inner | epoch 022:    624 / 756 loss=4.38, nll_loss=2.752, ppl=6.73, wps=37552, ups=2.47, wpb=15226.6, bsz=580.3, num_updates=16500, lr=9.84732e-05, gnorm=0.653, clip=0, train_wall=38, wall=6896
2020-10-13 12:23:23 | INFO | train_inner | epoch 022:    724 / 756 loss=4.392, nll_loss=2.765, ppl=6.8, wps=37668.9, ups=2.48, wpb=15181.6, bsz=586.8, num_updates=16600, lr=9.81761e-05, gnorm=0.687, clip=0, train_wall=38, wall=6936
2020-10-13 12:23:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 12:23:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27944.55078125Mb; avail=216583.1328125Mb
2020-10-13 12:23:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003238
2020-10-13 12:23:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27944.55078125Mb; avail=216583.1328125Mb
2020-10-13 12:23:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.317400
2020-10-13 12:23:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27949.74609375Mb; avail=216578.0859375Mb
2020-10-13 12:23:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.221002
2020-10-13 12:23:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.543672
2020-10-13 12:23:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27945.14453125Mb; avail=216582.6875Mb
2020-10-13 12:23:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27945.14453125Mb; avail=216582.6875Mb
2020-10-13 12:23:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002191
2020-10-13 12:23:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27945.14453125Mb; avail=216582.6875Mb
2020-10-13 12:23:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.139082
2020-10-13 12:23:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27944.6328125Mb; avail=216583.6328125Mb
2020-10-13 12:23:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.177805
2020-10-13 12:23:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.320245
2020-10-13 12:23:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27944.6328125Mb; avail=216583.6328125Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:23:45 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 4.627 | nll_loss 2.931 | ppl 7.63 | wps 69076.1 | wpb 4934.1 | bsz 184.1 | num_updates 16632 | best_loss 4.627
2020-10-13 12:23:45 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:23:52 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/checkpoint_best.pt (epoch 22 @ 16632 updates, score 4.627) (writing took 6.758432358969003 seconds)
2020-10-13 12:23:52 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2020-10-13 12:23:52 | INFO | train | epoch 022 | loss 4.385 | nll_loss 2.757 | ppl 6.76 | wps 34775.4 | ups 2.29 | wpb 15167.7 | bsz 563 | num_updates 16632 | lr 9.80816e-05 | gnorm 0.661 | clip 0 | train_wall 288 | wall 6965
2020-10-13 12:23:52 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=23/shard_epoch=22
2020-10-13 12:23:52 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=23/shard_epoch=23
2020-10-13 12:23:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27653.09375Mb; avail=216875.18359375Mb
2020-10-13 12:23:52 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.009056
2020-10-13 12:23:53 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.102526
2020-10-13 12:23:53 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27662.1015625Mb; avail=216866.125Mb
2020-10-13 12:23:53 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.005729
2020-10-13 12:23:53 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27662.70703125Mb; avail=216865.51953125Mb
2020-10-13 12:23:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.675397
2020-10-13 12:23:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.785236
2020-10-13 12:23:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28021.19921875Mb; avail=216506.94140625Mb
2020-10-13 12:23:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28025.078125Mb; avail=216503.078125Mb
2020-10-13 12:23:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.084438
2020-10-13 12:23:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28014.92578125Mb; avail=216512.5625Mb
2020-10-13 12:23:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.004852
2020-10-13 12:23:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28014.92578125Mb; avail=216512.5625Mb
2020-10-13 12:23:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.313780
2020-10-13 12:23:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.404260
2020-10-13 12:23:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27724.97265625Mb; avail=216803.34765625Mb
2020-10-13 12:23:58 | INFO | fairseq.trainer | begin training epoch 23
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:24:29 | INFO | train_inner | epoch 023:     68 / 756 loss=4.35, nll_loss=2.718, ppl=6.58, wps=22840.9, ups=1.51, wpb=15125.6, bsz=563.3, num_updates=16700, lr=9.78818e-05, gnorm=0.669, clip=0, train_wall=38, wall=7002
2020-10-13 12:25:10 | INFO | train_inner | epoch 023:    168 / 756 loss=4.327, nll_loss=2.692, ppl=6.46, wps=37409.9, ups=2.45, wpb=15261.6, bsz=581.1, num_updates=16800, lr=9.759e-05, gnorm=0.641, clip=0, train_wall=39, wall=7043
2020-10-13 12:25:51 | INFO | train_inner | epoch 023:    268 / 756 loss=4.343, nll_loss=2.71, ppl=6.54, wps=37703.4, ups=2.46, wpb=15303.5, bsz=568.1, num_updates=16900, lr=9.73009e-05, gnorm=0.667, clip=0, train_wall=38, wall=7084
2020-10-13 12:26:31 | INFO | train_inner | epoch 023:    368 / 756 loss=4.354, nll_loss=2.722, ppl=6.6, wps=37449.1, ups=2.47, wpb=15153.2, bsz=541.8, num_updates=17000, lr=9.70143e-05, gnorm=0.667, clip=0, train_wall=38, wall=7124
2020-10-13 12:27:12 | INFO | train_inner | epoch 023:    468 / 756 loss=4.379, nll_loss=2.75, ppl=6.73, wps=36978.4, ups=2.46, wpb=15045, bsz=552.2, num_updates=17100, lr=9.67302e-05, gnorm=0.661, clip=0, train_wall=38, wall=7165
2020-10-13 12:27:52 | INFO | train_inner | epoch 023:    568 / 756 loss=4.376, nll_loss=2.746, ppl=6.71, wps=37331.3, ups=2.49, wpb=14996.8, bsz=518.4, num_updates=17200, lr=9.64486e-05, gnorm=0.675, clip=0, train_wall=38, wall=7205
2020-10-13 12:28:33 | INFO | train_inner | epoch 023:    668 / 756 loss=4.365, nll_loss=2.734, ppl=6.65, wps=37506.1, ups=2.46, wpb=15216.1, bsz=560.9, num_updates=17300, lr=9.61694e-05, gnorm=0.666, clip=0, train_wall=38, wall=7246
2020-10-13 12:29:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 12:29:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28222.30078125Mb; avail=216305.33203125Mb
2020-10-13 12:29:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002303
2020-10-13 12:29:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28222.30078125Mb; avail=216305.33203125Mb
2020-10-13 12:29:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.287877
2020-10-13 12:29:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28355.8203125Mb; avail=216171.40625Mb
2020-10-13 12:29:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.213965
2020-10-13 12:29:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.505466
2020-10-13 12:29:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28438.93359375Mb; avail=216089.04296875Mb
2020-10-13 12:29:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28438.93359375Mb; avail=216089.04296875Mb
2020-10-13 12:29:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001995
2020-10-13 12:29:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28438.93359375Mb; avail=216089.04296875Mb
2020-10-13 12:29:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.140753
2020-10-13 12:29:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28491.1015625Mb; avail=216036.875Mb
2020-10-13 12:29:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.100823
2020-10-13 12:29:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.244570
2020-10-13 12:29:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28533.6796875Mb; avail=215994.296875Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:29:18 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 4.616 | nll_loss 2.912 | ppl 7.52 | wps 72285.7 | wpb 4934.1 | bsz 184.1 | num_updates 17388 | best_loss 4.616
2020-10-13 12:29:18 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:29:25 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/checkpoint_best.pt (epoch 23 @ 17388 updates, score 4.616) (writing took 6.887146887136623 seconds)
2020-10-13 12:29:25 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2020-10-13 12:29:25 | INFO | train | epoch 023 | loss 4.353 | nll_loss 2.722 | ppl 6.6 | wps 34440.4 | ups 2.27 | wpb 15167.8 | bsz 562.9 | num_updates 17388 | lr 9.59257e-05 | gnorm 0.664 | clip 0 | train_wall 289 | wall 7298
2020-10-13 12:29:25 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=24/shard_epoch=23
2020-10-13 12:29:25 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=24/shard_epoch=24
2020-10-13 12:29:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=27608.5625Mb; avail=216919.24609375Mb
2020-10-13 12:29:25 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.015866
2020-10-13 12:29:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.157528
2020-10-13 12:29:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27615.68359375Mb; avail=216912.125Mb
2020-10-13 12:29:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.007711
2020-10-13 12:29:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=27615.68359375Mb; avail=216912.125Mb
2020-10-13 12:29:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:03.248714
2020-10-13 12:29:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:03.415775
2020-10-13 12:29:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28181.734375Mb; avail=216346.25Mb
2020-10-13 12:29:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28161.0625Mb; avail=216366.921875Mb
2020-10-13 12:29:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.123473
2020-10-13 12:29:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28160.56640625Mb; avail=216367.41796875Mb
2020-10-13 12:29:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.009341
2020-10-13 12:29:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28160.80078125Mb; avail=216367.17578125Mb
2020-10-13 12:29:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.464867
2020-10-13 12:29:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.599578
2020-10-13 12:29:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28174.203125Mb; avail=216354.109375Mb
2020-10-13 12:29:32 | INFO | fairseq.trainer | begin training epoch 24
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:29:41 | INFO | train_inner | epoch 024:     12 / 756 loss=4.326, nll_loss=2.692, ppl=6.46, wps=22352.1, ups=1.47, wpb=15251.1, bsz=627, num_updates=17400, lr=9.58927e-05, gnorm=0.671, clip=0, train_wall=39, wall=7314
2020-10-13 12:30:22 | INFO | train_inner | epoch 024:    112 / 756 loss=4.31, nll_loss=2.672, ppl=6.37, wps=37477.7, ups=2.46, wpb=15257.5, bsz=586.3, num_updates=17500, lr=9.56183e-05, gnorm=0.666, clip=0, train_wall=38, wall=7355
2020-10-13 12:31:02 | INFO | train_inner | epoch 024:    212 / 756 loss=4.321, nll_loss=2.684, ppl=6.43, wps=37321.2, ups=2.46, wpb=15174.7, bsz=539, num_updates=17600, lr=9.53463e-05, gnorm=0.653, clip=0, train_wall=38, wall=7395
2020-10-13 12:31:43 | INFO | train_inner | epoch 024:    312 / 756 loss=4.319, nll_loss=2.683, ppl=6.42, wps=37473.4, ups=2.48, wpb=15134.1, bsz=559.4, num_updates=17700, lr=9.50765e-05, gnorm=0.655, clip=0, train_wall=38, wall=7436
2020-10-13 12:32:23 | INFO | train_inner | epoch 024:    412 / 756 loss=4.337, nll_loss=2.703, ppl=6.51, wps=37749.7, ups=2.48, wpb=15241.3, bsz=543.8, num_updates=17800, lr=9.48091e-05, gnorm=0.67, clip=0, train_wall=38, wall=7476
2020-10-13 12:33:04 | INFO | train_inner | epoch 024:    512 / 756 loss=4.332, nll_loss=2.697, ppl=6.48, wps=37006.9, ups=2.46, wpb=15040, bsz=570, num_updates=17900, lr=9.45439e-05, gnorm=0.678, clip=0, train_wall=39, wall=7517
2020-10-13 12:33:44 | INFO | train_inner | epoch 024:    612 / 756 loss=4.348, nll_loss=2.715, ppl=6.56, wps=37499.2, ups=2.47, wpb=15209.1, bsz=560, num_updates=18000, lr=9.42809e-05, gnorm=0.663, clip=0, train_wall=38, wall=7557
2020-10-13 12:34:25 | INFO | train_inner | epoch 024:    712 / 756 loss=4.293, nll_loss=2.654, ppl=6.29, wps=37007.9, ups=2.43, wpb=15207.9, bsz=609.7, num_updates=18100, lr=9.40201e-05, gnorm=0.647, clip=0, train_wall=38, wall=7598
2020-10-13 12:34:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 12:34:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=21212.671875Mb; avail=223315.17578125Mb
2020-10-13 12:34:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002981
2020-10-13 12:34:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21212.671875Mb; avail=223315.17578125Mb
2020-10-13 12:34:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.319794
2020-10-13 12:34:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21214.92578125Mb; avail=223313.24609375Mb
2020-10-13 12:34:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.218707
2020-10-13 12:34:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.543180
2020-10-13 12:34:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21214.92578125Mb; avail=223313.24609375Mb
2020-10-13 12:34:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=21214.92578125Mb; avail=223313.24609375Mb
2020-10-13 12:34:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003048
2020-10-13 12:34:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21214.92578125Mb; avail=223313.24609375Mb
2020-10-13 12:34:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.317777
2020-10-13 12:34:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21214.92578125Mb; avail=223313.24609375Mb
2020-10-13 12:34:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.201425
2020-10-13 12:34:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.523770
2020-10-13 12:34:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21238.67578125Mb; avail=223289.5703125Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:34:52 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 4.604 | nll_loss 2.903 | ppl 7.48 | wps 70888.1 | wpb 4934.1 | bsz 184.1 | num_updates 18144 | best_loss 4.604
2020-10-13 12:34:52 | INFO | fairseq_cli.train | begin save checkpoint
2020-10-13 12:34:59 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/checkpoint_best.pt (epoch 24 @ 18144 updates, score 4.604) (writing took 6.485935140168294 seconds)
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:34:59 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2020-10-13 12:34:59 | INFO | train | epoch 024 | loss 4.323 | nll_loss 2.687 | ppl 6.44 | wps 34354.4 | ups 2.26 | wpb 15167.9 | bsz 563 | num_updates 18144 | lr 9.3906e-05 | gnorm 0.662 | clip 0 | train_wall 290 | wall 7632
2020-10-13 12:34:59 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=25/shard_epoch=24
2020-10-13 12:34:59 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=25/shard_epoch=25
2020-10-13 12:34:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=20866.42578125Mb; avail=223661.7890625Mb
2020-10-13 12:34:59 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.009491
2020-10-13 12:34:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.106892
2020-10-13 12:34:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=20872.8125Mb; avail=223655.20703125Mb
2020-10-13 12:34:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.005277
2020-10-13 12:34:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=20873.41796875Mb; avail=223654.6015625Mb
2020-10-13 12:35:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.448782
2020-10-13 12:35:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.562258
2020-10-13 12:35:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21069.8515625Mb; avail=223458.796875Mb
2020-10-13 12:35:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=21117.5703125Mb; avail=223411.078125Mb
2020-10-13 12:35:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.102294
2020-10-13 12:35:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21162.97265625Mb; avail=223365.67578125Mb
2020-10-13 12:35:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.006128
2020-10-13 12:35:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21162.97265625Mb; avail=223365.67578125Mb
2020-10-13 12:35:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.994493
2020-10-13 12:35:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.104179
2020-10-13 12:35:04 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21504.4140625Mb; avail=223023.80859375Mb
2020-10-13 12:35:04 | INFO | fairseq.trainer | begin training epoch 25
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:35:30 | INFO | train_inner | epoch 025:     56 / 756 loss=4.306, nll_loss=2.668, ppl=6.36, wps=23058, ups=1.54, wpb=14987, bsz=520.1, num_updates=18200, lr=9.37614e-05, gnorm=0.672, clip=0, train_wall=38, wall=7663
2020-10-13 12:36:10 | INFO | train_inner | epoch 025:    156 / 756 loss=4.282, nll_loss=2.641, ppl=6.24, wps=38014.8, ups=2.51, wpb=15158.3, bsz=562.4, num_updates=18300, lr=9.35049e-05, gnorm=0.649, clip=0, train_wall=38, wall=7703
2020-10-13 12:36:47 | INFO | train_inner | epoch 025:    256 / 756 loss=4.281, nll_loss=2.64, ppl=6.23, wps=42008.8, ups=2.74, wpb=15316.9, bsz=585.6, num_updates=18400, lr=9.32505e-05, gnorm=0.656, clip=0, train_wall=35, wall=7740
2020-10-13 12:37:25 | INFO | train_inner | epoch 025:    356 / 756 loss=4.297, nll_loss=2.657, ppl=6.31, wps=39202.4, ups=2.58, wpb=15181.6, bsz=586.9, num_updates=18500, lr=9.29981e-05, gnorm=0.664, clip=0, train_wall=37, wall=7778
2020-10-13 12:38:05 | INFO | train_inner | epoch 025:    456 / 756 loss=4.321, nll_loss=2.683, ppl=6.42, wps=38191.5, ups=2.52, wpb=15126.2, bsz=535.1, num_updates=18600, lr=9.27478e-05, gnorm=0.667, clip=0, train_wall=37, wall=7818
2020-10-13 12:38:46 | INFO | train_inner | epoch 025:    556 / 756 loss=4.29, nll_loss=2.65, ppl=6.28, wps=37468.7, ups=2.46, wpb=15201.9, bsz=571.2, num_updates=18700, lr=9.24995e-05, gnorm=0.66, clip=0, train_wall=38, wall=7859
2020-10-13 12:39:27 | INFO | train_inner | epoch 025:    656 / 756 loss=4.305, nll_loss=2.666, ppl=6.35, wps=36372.2, ups=2.42, wpb=15048.7, bsz=541.2, num_updates=18800, lr=9.22531e-05, gnorm=0.678, clip=0, train_wall=39, wall=7900
2020-10-13 12:40:08 | INFO | train_inner | epoch 025:    756 / 756 loss=4.295, nll_loss=2.655, ppl=6.3, wps=37413.5, ups=2.47, wpb=15167.4, bsz=569.3, num_updates=18900, lr=9.20087e-05, gnorm=0.689, clip=0, train_wall=38, wall=7941
2020-10-13 12:40:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 12:40:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28733.50390625Mb; avail=215794.58203125Mb
2020-10-13 12:40:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003292
2020-10-13 12:40:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28733.50390625Mb; avail=215794.58203125Mb
2020-10-13 12:40:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.146207
2020-10-13 12:40:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28732.0234375Mb; avail=215795.9765625Mb
2020-10-13 12:40:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.100926
2020-10-13 12:40:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.251792
2020-10-13 12:40:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28732.0234375Mb; avail=215795.9765625Mb
2020-10-13 12:40:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28732.0234375Mb; avail=215795.9765625Mb
2020-10-13 12:40:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002088
2020-10-13 12:40:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28732.0234375Mb; avail=215795.9765625Mb
2020-10-13 12:40:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.213869
2020-10-13 12:40:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28741.65234375Mb; avail=215786.34765625Mb
2020-10-13 12:40:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.220562
2020-10-13 12:40:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.437926
2020-10-13 12:40:08 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28733.9296875Mb; avail=215794.0703125Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:40:17 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 4.595 | nll_loss 2.889 | ppl 7.41 | wps 72218.5 | wpb 4934.1 | bsz 184.1 | num_updates 18900 | best_loss 4.595
2020-10-13 12:40:17 | INFO | fairseq_cli.train | begin save checkpoint
2020-10-13 12:40:23 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/checkpoint_best.pt (epoch 25 @ 18900 updates, score 4.595) (writing took 6.767847237875685 seconds)
2020-10-13 12:40:24 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2020-10-13 12:40:24 | INFO | train | epoch 025 | loss 4.295 | nll_loss 2.655 | ppl 6.3 | wps 35321.9 | ups 2.33 | wpb 15168.2 | bsz 563.2 | num_updates 18900 | lr 9.20087e-05 | gnorm 0.666 | clip 0 | train_wall 283 | wall 7957
2020-10-13 12:40:24 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=26/shard_epoch=25
2020-10-13 12:40:24 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=26/shard_epoch=26
2020-10-13 12:40:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28296.36328125Mb; avail=216231.7109375Mb
2020-10-13 12:40:24 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.016509
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:40:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.167954
2020-10-13 12:40:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28318.984375Mb; avail=216208.35546875Mb
2020-10-13 12:40:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.008015
2020-10-13 12:40:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28319.58984375Mb; avail=216207.75Mb
2020-10-13 12:40:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.150819
2020-10-13 12:40:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.328344
2020-10-13 12:40:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28644.72265625Mb; avail=215883.59765625Mb
2020-10-13 12:40:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28767.41015625Mb; avail=215757.8828125Mb
2020-10-13 12:40:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.078122
2020-10-13 12:40:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28887.71875Mb; avail=215640.28125Mb
2020-10-13 12:40:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.004859
2020-10-13 12:40:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28902.85546875Mb; avail=215625.14453125Mb
2020-10-13 12:40:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:03.263338
2020-10-13 12:40:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:03.347666
2020-10-13 12:40:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28445.9921875Mb; avail=216081.9921875Mb
2020-10-13 12:40:30 | INFO | fairseq.trainer | begin training epoch 26
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:41:14 | INFO | train_inner | epoch 026:    100 / 756 loss=4.246, nll_loss=2.6, ppl=6.06, wps=22742, ups=1.5, wpb=15195.6, bsz=558, num_updates=19000, lr=9.17663e-05, gnorm=0.648, clip=0, train_wall=38, wall=8007
2020-10-13 12:41:55 | INFO | train_inner | epoch 026:    200 / 756 loss=4.265, nll_loss=2.621, ppl=6.15, wps=38389.7, ups=2.49, wpb=15401.1, bsz=576.7, num_updates=19100, lr=9.15258e-05, gnorm=0.663, clip=0, train_wall=38, wall=8047
2020-10-13 12:42:35 | INFO | train_inner | epoch 026:    300 / 756 loss=4.283, nll_loss=2.641, ppl=6.24, wps=37341.9, ups=2.46, wpb=15166.9, bsz=540.2, num_updates=19200, lr=9.12871e-05, gnorm=0.711, clip=0, train_wall=38, wall=8088
2020-10-13 12:43:16 | INFO | train_inner | epoch 026:    400 / 756 loss=4.242, nll_loss=2.595, ppl=6.04, wps=37263.9, ups=2.46, wpb=15166.1, bsz=622.6, num_updates=19300, lr=9.10503e-05, gnorm=0.667, clip=0, train_wall=38, wall=8129
2020-10-13 12:43:57 | INFO | train_inner | epoch 026:    500 / 756 loss=4.262, nll_loss=2.618, ppl=6.14, wps=37258.6, ups=2.46, wpb=15165.7, bsz=566.8, num_updates=19400, lr=9.08153e-05, gnorm=0.663, clip=0, train_wall=38, wall=8169
2020-10-13 12:44:37 | INFO | train_inner | epoch 026:    600 / 756 loss=4.291, nll_loss=2.65, ppl=6.28, wps=36863.8, ups=2.47, wpb=14933.3, bsz=538.8, num_updates=19500, lr=9.05822e-05, gnorm=0.683, clip=0, train_wall=38, wall=8210
2020-10-13 12:45:18 | INFO | train_inner | epoch 026:    700 / 756 loss=4.279, nll_loss=2.637, ppl=6.22, wps=37734, ups=2.47, wpb=15279.5, bsz=543.9, num_updates=19600, lr=9.03508e-05, gnorm=0.666, clip=0, train_wall=38, wall=8250
2020-10-13 12:45:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 12:45:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28693.1328125Mb; avail=215834.57421875Mb
2020-10-13 12:45:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002922
2020-10-13 12:45:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28693.1328125Mb; avail=215834.57421875Mb
2020-10-13 12:45:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.338320
2020-10-13 12:45:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28703.69140625Mb; avail=215824.015625Mb
2020-10-13 12:45:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.236901
2020-10-13 12:45:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.579738
2020-10-13 12:45:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28693.33984375Mb; avail=215834.3671875Mb
2020-10-13 12:45:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28693.33984375Mb; avail=215834.3671875Mb
2020-10-13 12:45:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003573
2020-10-13 12:45:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28693.33984375Mb; avail=215834.3671875Mb
2020-10-13 12:45:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.321793
2020-10-13 12:45:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28703.3359375Mb; avail=215823.83203125Mb
2020-10-13 12:45:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.225008
2020-10-13 12:45:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.552155
2020-10-13 12:45:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28712.30078125Mb; avail=215815.3828125Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:45:50 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 4.58 | nll_loss 2.876 | ppl 7.34 | wps 71285.9 | wpb 4934.1 | bsz 184.1 | num_updates 19656 | best_loss 4.58
2020-10-13 12:45:50 | INFO | fairseq_cli.train | begin save checkpoint
2020-10-13 12:45:57 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/checkpoint_best.pt (epoch 26 @ 19656 updates, score 4.58) (writing took 7.055376659147441 seconds)
2020-10-13 12:45:57 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2020-10-13 12:45:57 | INFO | train | epoch 026 | loss 4.269 | nll_loss 2.625 | ppl 6.17 | wps 34394.7 | ups 2.27 | wpb 15168.4 | bsz 563.1 | num_updates 19656 | lr 9.0222e-05 | gnorm 0.672 | clip 0 | train_wall 289 | wall 8290
2020-10-13 12:45:57 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=27/shard_epoch=26
2020-10-13 12:45:57 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=27/shard_epoch=27
2020-10-13 12:45:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28306.59375Mb; avail=216221.11328125Mb
2020-10-13 12:45:57 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.016310
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:45:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.174985
2020-10-13 12:45:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28320.69921875Mb; avail=216206.95703125Mb
2020-10-13 12:45:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.010623
2020-10-13 12:45:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28321.3046875Mb; avail=216206.3515625Mb
2020-10-13 12:46:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.763319
2020-10-13 12:46:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.950644
2020-10-13 12:46:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28440.44921875Mb; avail=216087.8125Mb
2020-10-13 12:46:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28453.05859375Mb; avail=216074.78515625Mb
2020-10-13 12:46:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.120030
2020-10-13 12:46:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28460.65234375Mb; avail=216067.19140625Mb
2020-10-13 12:46:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.008915
2020-10-13 12:46:00 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28460.16796875Mb; avail=216067.67578125Mb
2020-10-13 12:46:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.185692
2020-10-13 12:46:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.316257
2020-10-13 12:46:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28964.28125Mb; avail=215563.5625Mb
2020-10-13 12:46:03 | INFO | fairseq.trainer | begin training epoch 27
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:46:25 | INFO | train_inner | epoch 027:     44 / 756 loss=4.244, nll_loss=2.597, ppl=6.05, wps=22317.8, ups=1.49, wpb=14966.7, bsz=575.9, num_updates=19700, lr=9.01212e-05, gnorm=0.672, clip=0, train_wall=38, wall=8318
2020-10-13 12:47:05 | INFO | train_inner | epoch 027:    144 / 756 loss=4.244, nll_loss=2.597, ppl=6.05, wps=37707.7, ups=2.49, wpb=15168.1, bsz=556.2, num_updates=19800, lr=8.98933e-05, gnorm=0.656, clip=0, train_wall=38, wall=8358
2020-10-13 12:47:46 | INFO | train_inner | epoch 027:    244 / 756 loss=4.246, nll_loss=2.599, ppl=6.06, wps=37960.4, ups=2.46, wpb=15456.7, bsz=584.2, num_updates=19900, lr=8.96672e-05, gnorm=0.698, clip=0, train_wall=38, wall=8399
2020-10-13 12:48:26 | INFO | train_inner | epoch 027:    344 / 756 loss=4.235, nll_loss=2.588, ppl=6.01, wps=37612.7, ups=2.48, wpb=15188.5, bsz=572.1, num_updates=20000, lr=8.94427e-05, gnorm=0.657, clip=0, train_wall=38, wall=8439
2020-10-13 12:49:06 | INFO | train_inner | epoch 027:    444 / 756 loss=4.258, nll_loss=2.613, ppl=6.12, wps=37747.7, ups=2.48, wpb=15236.9, bsz=544.7, num_updates=20100, lr=8.92199e-05, gnorm=0.669, clip=0, train_wall=38, wall=8479
2020-10-13 12:49:47 | INFO | train_inner | epoch 027:    544 / 756 loss=4.232, nll_loss=2.584, ppl=6, wps=36788.4, ups=2.47, wpb=14919.6, bsz=582.9, num_updates=20200, lr=8.89988e-05, gnorm=0.68, clip=0, train_wall=38, wall=8520
2020-10-13 12:50:27 | INFO | train_inner | epoch 027:    644 / 756 loss=4.264, nll_loss=2.62, ppl=6.15, wps=37402.7, ups=2.47, wpb=15118.7, bsz=523.1, num_updates=20300, lr=8.87794e-05, gnorm=0.665, clip=0, train_wall=38, wall=8560
2020-10-13 12:51:08 | INFO | train_inner | epoch 027:    744 / 756 loss=4.253, nll_loss=2.608, ppl=6.1, wps=37601.8, ups=2.47, wpb=15224.1, bsz=558.5, num_updates=20400, lr=8.85615e-05, gnorm=0.678, clip=0, train_wall=38, wall=8601
2020-10-13 12:51:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 12:51:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28682.2578125Mb; avail=215845.984375Mb
2020-10-13 12:51:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003113
2020-10-13 12:51:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28682.86328125Mb; avail=215845.37890625Mb
2020-10-13 12:51:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.318526
2020-10-13 12:51:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28681.9921875Mb; avail=215846.25Mb
2020-10-13 12:51:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.219915
2020-10-13 12:51:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.542988
2020-10-13 12:51:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28707.15625Mb; avail=215820.859375Mb
2020-10-13 12:51:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28707.15625Mb; avail=215820.859375Mb
2020-10-13 12:51:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002982
2020-10-13 12:51:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28707.15625Mb; avail=215820.859375Mb
2020-10-13 12:51:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.308821
2020-10-13 12:51:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28825.01171875Mb; avail=215702.91015625Mb
2020-10-13 12:51:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.146757
2020-10-13 12:51:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.460154
2020-10-13 12:51:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28862.64453125Mb; avail=215665.27734375Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:51:22 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 4.572 | nll_loss 2.869 | ppl 7.31 | wps 72748.6 | wpb 4934.1 | bsz 184.1 | num_updates 20412 | best_loss 4.572
2020-10-13 12:51:22 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:51:29 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/checkpoint_best.pt (epoch 27 @ 20412 updates, score 4.572) (writing took 6.577502276049927 seconds)
2020-10-13 12:51:29 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2020-10-13 12:51:29 | INFO | train | epoch 027 | loss 4.244 | nll_loss 2.597 | ppl 6.05 | wps 34558.7 | ups 2.28 | wpb 15168.3 | bsz 563.1 | num_updates 20412 | lr 8.85355e-05 | gnorm 0.673 | clip 0 | train_wall 289 | wall 8622
2020-10-13 12:51:29 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=28/shard_epoch=27
2020-10-13 12:51:29 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=28/shard_epoch=28
2020-10-13 12:51:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28423.37109375Mb; avail=216104.62890625Mb
2020-10-13 12:51:29 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.007937
2020-10-13 12:51:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.103297
2020-10-13 12:51:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28437.6953125Mb; avail=216090.08203125Mb
2020-10-13 12:51:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.004654
2020-10-13 12:51:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28438.30078125Mb; avail=216089.4765625Mb
2020-10-13 12:51:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.822273
2020-10-13 12:51:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.931466
2020-10-13 12:51:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28580.27734375Mb; avail=215948.0078125Mb
2020-10-13 12:51:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28583.81640625Mb; avail=215944.46875Mb
2020-10-13 12:51:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.129751
2020-10-13 12:51:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28587.4453125Mb; avail=215940.83984375Mb
2020-10-13 12:51:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.009285
2020-10-13 12:51:31 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28587.38671875Mb; avail=215941.015625Mb
2020-10-13 12:51:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.310236
2020-10-13 12:51:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.450915
2020-10-13 12:51:34 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28468.1953125Mb; avail=216059.07421875Mb
2020-10-13 12:51:34 | INFO | fairseq.trainer | begin training epoch 28
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:52:13 | INFO | train_inner | epoch 028:     88 / 756 loss=4.222, nll_loss=2.571, ppl=5.94, wps=23175.8, ups=1.52, wpb=15212.8, bsz=547, num_updates=20500, lr=8.83452e-05, gnorm=0.671, clip=0, train_wall=38, wall=8666
2020-10-13 12:52:54 | INFO | train_inner | epoch 028:    188 / 756 loss=4.225, nll_loss=2.576, ppl=5.96, wps=37873, ups=2.47, wpb=15319, bsz=546.6, num_updates=20600, lr=8.81305e-05, gnorm=0.668, clip=0, train_wall=38, wall=8707
2020-10-13 12:53:35 | INFO | train_inner | epoch 028:    288 / 756 loss=4.218, nll_loss=2.567, ppl=5.93, wps=37308.6, ups=2.46, wpb=15183.8, bsz=571.7, num_updates=20700, lr=8.79174e-05, gnorm=0.668, clip=0, train_wall=38, wall=8748
2020-10-13 12:54:15 | INFO | train_inner | epoch 028:    388 / 756 loss=4.239, nll_loss=2.591, ppl=6.02, wps=37431.9, ups=2.49, wpb=15054.4, bsz=565.7, num_updates=20800, lr=8.77058e-05, gnorm=0.694, clip=0, train_wall=38, wall=8788
2020-10-13 12:54:55 | INFO | train_inner | epoch 028:    488 / 756 loss=4.214, nll_loss=2.563, ppl=5.91, wps=37685.8, ups=2.49, wpb=15139.1, bsz=573.5, num_updates=20900, lr=8.74957e-05, gnorm=0.663, clip=0, train_wall=38, wall=8828
2020-10-13 12:55:32 | INFO | train_inner | epoch 028:    588 / 756 loss=4.216, nll_loss=2.566, ppl=5.92, wps=41185.5, ups=2.72, wpb=15159.9, bsz=528.8, num_updates=21000, lr=8.72872e-05, gnorm=0.679, clip=0, train_wall=35, wall=8865
2020-10-13 12:56:10 | INFO | train_inner | epoch 028:    688 / 756 loss=4.218, nll_loss=2.567, ppl=5.93, wps=39915.4, ups=2.65, wpb=15067.8, bsz=588.2, num_updates=21100, lr=8.70801e-05, gnorm=0.682, clip=0, train_wall=36, wall=8902
2020-10-13 12:56:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 12:56:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28345.03125Mb; avail=216182.25Mb
2020-10-13 12:56:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002627
2020-10-13 12:56:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28345.03125Mb; avail=216182.25Mb
2020-10-13 12:56:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.275661
2020-10-13 12:56:36 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28423.99609375Mb; avail=216103.37890625Mb
2020-10-13 12:56:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.189078
2020-10-13 12:56:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.468759
2020-10-13 12:56:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28464.45703125Mb; avail=216063.4453125Mb
2020-10-13 12:56:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28469.30078125Mb; avail=216058.6015625Mb
2020-10-13 12:56:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002672
2020-10-13 12:56:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28469.30078125Mb; avail=216058.6015625Mb
2020-10-13 12:56:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.268427
2020-10-13 12:56:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28514.39453125Mb; avail=216013.5078125Mb
2020-10-13 12:56:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.181663
2020-10-13 12:56:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.454140
2020-10-13 12:56:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28539.01171875Mb; avail=215988.80078125Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:56:44 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 4.573 | nll_loss 2.867 | ppl 7.3 | wps 75841.6 | wpb 4934.1 | bsz 184.1 | num_updates 21168 | best_loss 4.572
2020-10-13 12:56:44 | INFO | fairseq_cli.train | begin save checkpoint
2020-10-13 12:56:49 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/checkpoint_last.pt (epoch 28 @ 21168 updates, score 4.573) (writing took 4.164013024885207 seconds)
2020-10-13 12:56:49 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2020-10-13 12:56:49 | INFO | train | epoch 028 | loss 4.221 | nll_loss 2.571 | ppl 5.94 | wps 35831.7 | ups 2.36 | wpb 15167.5 | bsz 562.9 | num_updates 21168 | lr 8.69401e-05 | gnorm 0.674 | clip 0 | train_wall 282 | wall 8942
2020-10-13 12:56:49 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=29/shard_epoch=28
2020-10-13 12:56:49 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=29/shard_epoch=29
2020-10-13 12:56:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28569.890625Mb; avail=215957.4140625Mb
2020-10-13 12:56:49 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.015674
2020-10-13 12:56:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.161682
2020-10-13 12:56:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28569.49609375Mb; avail=215958.23828125Mb
2020-10-13 12:56:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.007673
2020-10-13 12:56:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28570.1015625Mb; avail=215957.6328125Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:56:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.923340
2020-10-13 12:56:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:03.094366
2020-10-13 12:56:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29627.875Mb; avail=214899.9375Mb
2020-10-13 12:56:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=29802.48046875Mb; avail=214726.05078125Mb
2020-10-13 12:56:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.079570
2020-10-13 12:56:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29733.515625Mb; avail=214794.83203125Mb
2020-10-13 12:56:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.006100
2020-10-13 12:56:52 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29734.12109375Mb; avail=214794.2265625Mb
2020-10-13 12:56:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.143975
2020-10-13 12:56:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.230951
2020-10-13 12:56:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29827.22265625Mb; avail=214700.8125Mb
2020-10-13 12:56:54 | INFO | fairseq.trainer | begin training epoch 29
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 12:57:12 | INFO | train_inner | epoch 029:     32 / 756 loss=4.21, nll_loss=2.559, ppl=5.89, wps=24286.7, ups=1.61, wpb=15079.1, bsz=567.9, num_updates=21200, lr=8.68744e-05, gnorm=0.679, clip=0, train_wall=37, wall=8965
2020-10-13 12:57:52 | INFO | train_inner | epoch 029:    132 / 756 loss=4.192, nll_loss=2.538, ppl=5.81, wps=37193.4, ups=2.47, wpb=15035, bsz=545.9, num_updates=21300, lr=8.66703e-05, gnorm=0.67, clip=0, train_wall=38, wall=9005
2020-10-13 12:58:33 | INFO | train_inner | epoch 029:    232 / 756 loss=4.206, nll_loss=2.554, ppl=5.87, wps=37044.3, ups=2.45, wpb=15133.2, bsz=572.7, num_updates=21400, lr=8.64675e-05, gnorm=0.691, clip=0, train_wall=39, wall=9046
2020-10-13 12:59:13 | INFO | train_inner | epoch 029:    332 / 756 loss=4.192, nll_loss=2.538, ppl=5.81, wps=37263.6, ups=2.47, wpb=15114, bsz=561.2, num_updates=21500, lr=8.62662e-05, gnorm=0.666, clip=0, train_wall=38, wall=9086
2020-10-13 12:59:54 | INFO | train_inner | epoch 029:    432 / 756 loss=4.201, nll_loss=2.548, ppl=5.85, wps=37293.5, ups=2.47, wpb=15114.7, bsz=579, num_updates=21600, lr=8.60663e-05, gnorm=0.663, clip=0, train_wall=38, wall=9127
2020-10-13 13:00:35 | INFO | train_inner | epoch 029:    532 / 756 loss=4.2, nll_loss=2.547, ppl=5.85, wps=37653.7, ups=2.46, wpb=15324.5, bsz=550.5, num_updates=21700, lr=8.58678e-05, gnorm=0.669, clip=0, train_wall=38, wall=9168
2020-10-13 13:01:15 | INFO | train_inner | epoch 029:    632 / 756 loss=4.186, nll_loss=2.531, ppl=5.78, wps=37705.2, ups=2.46, wpb=15305.9, bsz=586.6, num_updates=21800, lr=8.56706e-05, gnorm=0.658, clip=0, train_wall=38, wall=9208
2020-10-13 13:01:56 | INFO | train_inner | epoch 029:    732 / 756 loss=4.212, nll_loss=2.56, ppl=5.9, wps=37647, ups=2.47, wpb=15216.9, bsz=569.3, num_updates=21900, lr=8.54748e-05, gnorm=0.672, clip=0, train_wall=38, wall=9249
2020-10-13 13:02:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 13:02:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=29643.68359375Mb; avail=214884.5390625Mb
2020-10-13 13:02:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003171
2020-10-13 13:02:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29643.68359375Mb; avail=214884.5390625Mb
2020-10-13 13:02:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.196943
2020-10-13 13:02:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29715.765625Mb; avail=214812.0390625Mb
2020-10-13 13:02:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.100431
2020-10-13 13:02:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.301769
2020-10-13 13:02:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29752.89453125Mb; avail=214774.91015625Mb
2020-10-13 13:02:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=29758.79296875Mb; avail=214769.01171875Mb
2020-10-13 13:02:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002032
2020-10-13 13:02:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29758.79296875Mb; avail=214769.01171875Mb
2020-10-13 13:02:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.145406
2020-10-13 13:02:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29804.80859375Mb; avail=214722.99609375Mb
2020-10-13 13:02:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.103533
2020-10-13 13:02:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.252211
2020-10-13 13:02:06 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29836.80078125Mb; avail=214691.00390625Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:02:15 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 4.566 | nll_loss 2.859 | ppl 7.26 | wps 59470.1 | wpb 4934.1 | bsz 184.1 | num_updates 21924 | best_loss 4.566
2020-10-13 13:02:15 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:02:22 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/checkpoint_best.pt (epoch 29 @ 21924 updates, score 4.566) (writing took 6.995300196809694 seconds)
2020-10-13 13:02:22 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2020-10-13 13:02:22 | INFO | train | epoch 029 | loss 4.199 | nll_loss 2.545 | ppl 5.84 | wps 34421.8 | ups 2.27 | wpb 15168.1 | bsz 563.1 | num_updates 21924 | lr 8.5428e-05 | gnorm 0.671 | clip 0 | train_wall 289 | wall 9275
2020-10-13 13:02:22 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=30/shard_epoch=29
2020-10-13 13:02:22 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=30/shard_epoch=30
2020-10-13 13:02:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28730.55078125Mb; avail=215797.59375Mb
2020-10-13 13:02:22 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.008306
2020-10-13 13:02:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.097604
2020-10-13 13:02:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28736.51171875Mb; avail=215791.6328125Mb
2020-10-13 13:02:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.004386
2020-10-13 13:02:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28736.51171875Mb; avail=215791.6328125Mb
2020-10-13 13:02:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.870930
2020-10-13 13:02:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.974070
2020-10-13 13:02:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28798.56640625Mb; avail=215729.6171875Mb
2020-10-13 13:02:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28809.2890625Mb; avail=215719.08984375Mb
2020-10-13 13:02:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.085315
2020-10-13 13:02:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28841.62109375Mb; avail=215686.15234375Mb
2020-10-13 13:02:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.007635
2020-10-13 13:02:24 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28841.984375Mb; avail=215685.7890625Mb
2020-10-13 13:02:27 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.868067
2020-10-13 13:02:27 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.962665
2020-10-13 13:02:27 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29170.734375Mb; avail=215356.4296875Mb
2020-10-13 13:02:27 | INFO | fairseq.trainer | begin training epoch 30
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:03:02 | INFO | train_inner | epoch 030:     76 / 756 loss=4.184, nll_loss=2.528, ppl=5.77, wps=22589.4, ups=1.5, wpb=15067.6, bsz=560.5, num_updates=22000, lr=8.52803e-05, gnorm=0.684, clip=0, train_wall=38, wall=9315
2020-10-13 13:03:43 | INFO | train_inner | epoch 030:    176 / 756 loss=4.182, nll_loss=2.527, ppl=5.76, wps=37530.4, ups=2.48, wpb=15103.8, bsz=546.9, num_updates=22100, lr=8.50871e-05, gnorm=0.664, clip=0, train_wall=38, wall=9356
2020-10-13 13:04:23 | INFO | train_inner | epoch 030:    276 / 756 loss=4.167, nll_loss=2.51, ppl=5.7, wps=37292.2, ups=2.48, wpb=15025.6, bsz=525.7, num_updates=22200, lr=8.48953e-05, gnorm=0.685, clip=0, train_wall=38, wall=9396
2020-10-13 13:05:03 | INFO | train_inner | epoch 030:    376 / 756 loss=4.173, nll_loss=2.516, ppl=5.72, wps=37895, ups=2.47, wpb=15341.7, bsz=599, num_updates=22300, lr=8.47047e-05, gnorm=0.672, clip=0, train_wall=38, wall=9436
2020-10-13 13:05:44 | INFO | train_inner | epoch 030:    476 / 756 loss=4.199, nll_loss=2.544, ppl=5.83, wps=37581, ups=2.46, wpb=15288, bsz=531.2, num_updates=22400, lr=8.45154e-05, gnorm=0.681, clip=0, train_wall=38, wall=9477
2020-10-13 13:06:25 | INFO | train_inner | epoch 030:    576 / 756 loss=4.166, nll_loss=2.509, ppl=5.69, wps=37501.3, ups=2.45, wpb=15286.1, bsz=581.5, num_updates=22500, lr=8.43274e-05, gnorm=0.684, clip=0, train_wall=38, wall=9518
2020-10-13 13:07:06 | INFO | train_inner | epoch 030:    676 / 756 loss=4.184, nll_loss=2.529, ppl=5.77, wps=37256.5, ups=2.45, wpb=15223.6, bsz=582.2, num_updates=22600, lr=8.41406e-05, gnorm=0.676, clip=0, train_wall=39, wall=9559
2020-10-13 13:07:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 13:07:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=29260.09765625Mb; avail=215267.609375Mb
2020-10-13 13:07:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002160
2020-10-13 13:07:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29260.09765625Mb; avail=215267.609375Mb
2020-10-13 13:07:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.243369
2020-10-13 13:07:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29276.23046875Mb; avail=215251.57421875Mb
2020-10-13 13:07:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.107522
2020-10-13 13:07:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.354298
2020-10-13 13:07:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29286.23828125Mb; avail=215241.56640625Mb
2020-10-13 13:07:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=29286.73828125Mb; avail=215241.06640625Mb
2020-10-13 13:07:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001947
2020-10-13 13:07:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29286.73828125Mb; avail=215241.06640625Mb
2020-10-13 13:07:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.141488
2020-10-13 13:07:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29276.421875Mb; avail=215251.3828125Mb
2020-10-13 13:07:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.117908
2020-10-13 13:07:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.262602
2020-10-13 13:07:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29288.95703125Mb; avail=215238.84765625Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:07:47 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 4.559 | nll_loss 2.852 | ppl 7.22 | wps 63771.5 | wpb 4934.1 | bsz 184.1 | num_updates 22680 | best_loss 4.559
2020-10-13 13:07:47 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:07:54 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/checkpoint_best.pt (epoch 30 @ 22680 updates, score 4.559) (writing took 6.662638873094693 seconds)
2020-10-13 13:07:54 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2020-10-13 13:07:54 | INFO | train | epoch 030 | loss 4.178 | nll_loss 2.522 | ppl 5.74 | wps 34529.6 | ups 2.28 | wpb 15169 | bsz 563.1 | num_updates 22680 | lr 8.39921e-05 | gnorm 0.678 | clip 0 | train_wall 290 | wall 9607
2020-10-13 13:07:54 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=31/shard_epoch=30
2020-10-13 13:07:54 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=31/shard_epoch=31
2020-10-13 13:07:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=29213.234375Mb; avail=215314.34765625Mb
2020-10-13 13:07:54 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.013725
2020-10-13 13:07:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.129333
2020-10-13 13:07:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29214.625Mb; avail=215312.95703125Mb
2020-10-13 13:07:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.004611
2020-10-13 13:07:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29216.8125Mb; avail=215311.32421875Mb
2020-10-13 13:07:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.205021
2020-10-13 13:07:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.340090
2020-10-13 13:07:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29353.4921875Mb; avail=215174.69140625Mb
2020-10-13 13:07:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=29360.03125Mb; avail=215168.15234375Mb
2020-10-13 13:07:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.090432
2020-10-13 13:07:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29351.40625Mb; avail=215176.77734375Mb
2020-10-13 13:07:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.004846
2020-10-13 13:07:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29351.40625Mb; avail=215176.77734375Mb
2020-10-13 13:07:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.939455
2020-10-13 13:07:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.036293
2020-10-13 13:07:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28851.078125Mb; avail=215676.69140625Mb
2020-10-13 13:07:59 | INFO | fairseq.trainer | begin training epoch 31
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:08:11 | INFO | train_inner | epoch 031:     20 / 756 loss=4.17, nll_loss=2.514, ppl=5.71, wps=22870.2, ups=1.53, wpb=14953.3, bsz=568.1, num_updates=22700, lr=8.39551e-05, gnorm=0.682, clip=0, train_wall=38, wall=9624
2020-10-13 13:08:52 | INFO | train_inner | epoch 031:    120 / 756 loss=4.154, nll_loss=2.493, ppl=5.63, wps=37418.5, ups=2.46, wpb=15185.1, bsz=566.5, num_updates=22800, lr=8.37708e-05, gnorm=0.673, clip=0, train_wall=38, wall=9665
2020-10-13 13:09:32 | INFO | train_inner | epoch 031:    220 / 756 loss=4.144, nll_loss=2.483, ppl=5.59, wps=37573.6, ups=2.48, wpb=15170.2, bsz=558.4, num_updates=22900, lr=8.35877e-05, gnorm=0.677, clip=0, train_wall=38, wall=9705
2020-10-13 13:10:13 | INFO | train_inner | epoch 031:    320 / 756 loss=4.152, nll_loss=2.492, ppl=5.63, wps=36844.2, ups=2.45, wpb=15039.2, bsz=538.3, num_updates=23000, lr=8.34058e-05, gnorm=0.668, clip=0, train_wall=39, wall=9746
2020-10-13 13:10:54 | INFO | train_inner | epoch 031:    420 / 756 loss=4.16, nll_loss=2.501, ppl=5.66, wps=37744.3, ups=2.44, wpb=15440.9, bsz=555.2, num_updates=23100, lr=8.3225e-05, gnorm=0.669, clip=0, train_wall=39, wall=9787
2020-10-13 13:11:34 | INFO | train_inner | epoch 031:    520 / 756 loss=4.176, nll_loss=2.52, ppl=5.74, wps=37615.1, ups=2.49, wpb=15082.5, bsz=561.4, num_updates=23200, lr=8.30455e-05, gnorm=0.712, clip=0, train_wall=38, wall=9827
2020-10-13 13:12:14 | INFO | train_inner | epoch 031:    620 / 756 loss=4.174, nll_loss=2.516, ppl=5.72, wps=37346.7, ups=2.47, wpb=15099.7, bsz=557.7, num_updates=23300, lr=8.28671e-05, gnorm=0.698, clip=0, train_wall=38, wall=9867
2020-10-13 13:12:55 | INFO | train_inner | epoch 031:    720 / 756 loss=4.156, nll_loss=2.497, ppl=5.65, wps=37004, ups=2.44, wpb=15140.2, bsz=576.4, num_updates=23400, lr=8.26898e-05, gnorm=0.667, clip=0, train_wall=38, wall=9908
2020-10-13 13:13:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 13:13:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=21359.6875Mb; avail=223167.65625Mb
2020-10-13 13:13:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002618
2020-10-13 13:13:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21359.6875Mb; avail=223167.65625Mb
2020-10-13 13:13:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.313062
2020-10-13 13:13:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21364.734375Mb; avail=223162.51171875Mb
2020-10-13 13:13:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.240034
2020-10-13 13:13:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.557159
2020-10-13 13:13:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21368.79296875Mb; avail=223159.42578125Mb
2020-10-13 13:13:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=21368.79296875Mb; avail=223159.42578125Mb
2020-10-13 13:13:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003213
2020-10-13 13:13:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21368.79296875Mb; avail=223159.42578125Mb
2020-10-13 13:13:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.332380
2020-10-13 13:13:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21406.28125Mb; avail=223121.89453125Mb
2020-10-13 13:13:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.208891
2020-10-13 13:13:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.546180
2020-10-13 13:13:11 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21706.60546875Mb; avail=222821.5703125Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:13:19 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 4.555 | nll_loss 2.847 | ppl 7.2 | wps 75782.7 | wpb 4934.1 | bsz 184.1 | num_updates 23436 | best_loss 4.555
2020-10-13 13:13:19 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:13:25 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/checkpoint_best.pt (epoch 31 @ 23436 updates, score 4.555) (writing took 6.46852679294534 seconds)
2020-10-13 13:13:26 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2020-10-13 13:13:26 | INFO | train | epoch 031 | loss 4.158 | nll_loss 2.498 | ppl 5.65 | wps 34599 | ups 2.28 | wpb 15168.1 | bsz 563.1 | num_updates 23436 | lr 8.26263e-05 | gnorm 0.679 | clip 0 | train_wall 289 | wall 9939
2020-10-13 13:13:26 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=32/shard_epoch=31
2020-10-13 13:13:26 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=32/shard_epoch=32
2020-10-13 13:13:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=21572.296875Mb; avail=222954.8125Mb
2020-10-13 13:13:26 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.014384
2020-10-13 13:13:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.154726
2020-10-13 13:13:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21596.8125Mb; avail=222930.32421875Mb
2020-10-13 13:13:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.010359
2020-10-13 13:13:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21596.8125Mb; avail=222930.32421875Mb
2020-10-13 13:13:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:03.407405
2020-10-13 13:13:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:03.574126
2020-10-13 13:13:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21771.30078125Mb; avail=222756.08203125Mb
2020-10-13 13:13:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=21757.953125Mb; avail=222769.40625Mb
2020-10-13 13:13:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.125465
2020-10-13 13:13:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21757.83203125Mb; avail=222769.52734375Mb
2020-10-13 13:13:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.008010
2020-10-13 13:13:30 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21757.83203125Mb; avail=222769.52734375Mb
2020-10-13 13:13:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.273549
2020-10-13 13:13:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.408781
2020-10-13 13:13:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21818.2265625Mb; avail=222709.4453125Mb
2020-10-13 13:13:32 | INFO | fairseq.trainer | begin training epoch 32
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:14:02 | INFO | train_inner | epoch 032:     64 / 756 loss=4.117, nll_loss=2.454, ppl=5.48, wps=22781, ups=1.5, wpb=15218.9, bsz=566.6, num_updates=23500, lr=8.25137e-05, gnorm=0.67, clip=0, train_wall=38, wall=9975
2020-10-13 13:14:38 | INFO | train_inner | epoch 032:    164 / 756 loss=4.151, nll_loss=2.49, ppl=5.62, wps=42091.6, ups=2.81, wpb=14956.1, bsz=530.5, num_updates=23600, lr=8.23387e-05, gnorm=0.673, clip=0, train_wall=34, wall=10011
2020-10-13 13:15:19 | INFO | train_inner | epoch 032:    264 / 756 loss=4.15, nll_loss=2.489, ppl=5.61, wps=39101.8, ups=2.57, wpb=15212.1, bsz=535.7, num_updates=23700, lr=8.21648e-05, gnorm=0.669, clip=0, train_wall=37, wall=10052
2020-10-13 13:15:59 | INFO | train_inner | epoch 032:    364 / 756 loss=4.122, nll_loss=2.458, ppl=5.5, wps=38518.8, ups=2.5, wpb=15378, bsz=593.8, num_updates=23800, lr=8.1992e-05, gnorm=0.668, clip=0, train_wall=38, wall=10092
2020-10-13 13:16:40 | INFO | train_inner | epoch 032:    464 / 756 loss=4.127, nll_loss=2.464, ppl=5.52, wps=36761.2, ups=2.47, wpb=14909.1, bsz=580.5, num_updates=23900, lr=8.18203e-05, gnorm=0.678, clip=0, train_wall=38, wall=10133
2020-10-13 13:17:21 | INFO | train_inner | epoch 032:    564 / 756 loss=4.127, nll_loss=2.465, ppl=5.52, wps=37082.6, ups=2.43, wpb=15277.9, bsz=617.4, num_updates=24000, lr=8.16497e-05, gnorm=0.679, clip=0, train_wall=39, wall=10174
2020-10-13 13:18:01 | INFO | train_inner | epoch 032:    664 / 756 loss=4.171, nll_loss=2.513, ppl=5.71, wps=38026.4, ups=2.49, wpb=15289.3, bsz=527.9, num_updates=24100, lr=8.14801e-05, gnorm=0.679, clip=0, train_wall=38, wall=10214
2020-10-13 13:18:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 13:18:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=29705.59765625Mb; avail=214822.12890625Mb
2020-10-13 13:18:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002895
2020-10-13 13:18:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29705.59765625Mb; avail=214822.12890625Mb
2020-10-13 13:18:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.334758
2020-10-13 13:18:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29695.78125Mb; avail=214831.9453125Mb
2020-10-13 13:18:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.219165
2020-10-13 13:18:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.558678
2020-10-13 13:18:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29695.875Mb; avail=214832.0546875Mb
2020-10-13 13:18:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=29695.875Mb; avail=214832.0546875Mb
2020-10-13 13:18:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003058
2020-10-13 13:18:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29695.875Mb; avail=214832.0546875Mb
2020-10-13 13:18:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.331580
2020-10-13 13:18:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29380.63671875Mb; avail=215147.08203125Mb
2020-10-13 13:18:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.233473
2020-10-13 13:18:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.569789
2020-10-13 13:18:40 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28891.46875Mb; avail=215636.25Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:18:48 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 4.544 | nll_loss 2.833 | ppl 7.13 | wps 71465.5 | wpb 4934.1 | bsz 184.1 | num_updates 24192 | best_loss 4.544
2020-10-13 13:18:48 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:18:55 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/checkpoint_best.pt (epoch 32 @ 24192 updates, score 4.544) (writing took 6.6096880990080535 seconds)
2020-10-13 13:18:55 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2020-10-13 13:18:55 | INFO | train | epoch 032 | loss 4.138 | nll_loss 2.476 | ppl 5.57 | wps 34789.5 | ups 2.29 | wpb 15168.2 | bsz 563.1 | num_updates 24192 | lr 8.1325e-05 | gnorm 0.675 | clip 0 | train_wall 283 | wall 10268
2020-10-13 13:18:55 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=33/shard_epoch=32
2020-10-13 13:18:55 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=33/shard_epoch=33
2020-10-13 13:18:55 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28477.25Mb; avail=216050.578125Mb
2020-10-13 13:18:55 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.016898
2020-10-13 13:18:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.226746
2020-10-13 13:18:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28476.88671875Mb; avail=216051.01953125Mb
2020-10-13 13:18:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.010242
2020-10-13 13:18:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28478.09765625Mb; avail=216049.80859375Mb
2020-10-13 13:18:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:03.404449
2020-10-13 13:18:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:03.643098
2020-10-13 13:18:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28574.0Mb; avail=215953.51953125Mb
2020-10-13 13:18:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28567.703125Mb; avail=215959.81640625Mb
2020-10-13 13:18:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.080154
2020-10-13 13:18:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28567.703125Mb; avail=215959.81640625Mb
2020-10-13 13:18:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.006624
2020-10-13 13:18:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28567.703125Mb; avail=215959.81640625Mb
2020-10-13 13:19:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.432138
2020-10-13 13:19:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.520379
2020-10-13 13:19:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29210.6171875Mb; avail=215317.125Mb
2020-10-13 13:19:02 | INFO | fairseq.trainer | begin training epoch 33
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:19:09 | INFO | train_inner | epoch 033:      8 / 756 loss=4.131, nll_loss=2.469, ppl=5.53, wps=22239.1, ups=1.47, wpb=15170.6, bsz=590.6, num_updates=24200, lr=8.13116e-05, gnorm=0.673, clip=0, train_wall=38, wall=10282
2020-10-13 13:19:50 | INFO | train_inner | epoch 033:    108 / 756 loss=4.091, nll_loss=2.424, ppl=5.37, wps=36657.4, ups=2.47, wpb=14839.8, bsz=559.1, num_updates=24300, lr=8.11441e-05, gnorm=0.678, clip=0, train_wall=38, wall=10323
2020-10-13 13:20:30 | INFO | train_inner | epoch 033:    208 / 756 loss=4.138, nll_loss=2.475, ppl=5.56, wps=37028.3, ups=2.47, wpb=15001.4, bsz=516.2, num_updates=24400, lr=8.09776e-05, gnorm=0.68, clip=0, train_wall=38, wall=10363
2020-10-13 13:21:11 | INFO | train_inner | epoch 033:    308 / 756 loss=4.111, nll_loss=2.446, ppl=5.45, wps=37741.4, ups=2.48, wpb=15245.5, bsz=550, num_updates=24500, lr=8.08122e-05, gnorm=0.668, clip=0, train_wall=38, wall=10404
2020-10-13 13:21:52 | INFO | train_inner | epoch 033:    408 / 756 loss=4.103, nll_loss=2.437, ppl=5.42, wps=37561.9, ups=2.44, wpb=15368, bsz=618.2, num_updates=24600, lr=8.06478e-05, gnorm=0.678, clip=0, train_wall=39, wall=10445
2020-10-13 13:22:32 | INFO | train_inner | epoch 033:    508 / 756 loss=4.129, nll_loss=2.466, ppl=5.53, wps=37821, ups=2.46, wpb=15397.1, bsz=557.8, num_updates=24700, lr=8.04844e-05, gnorm=0.69, clip=0, train_wall=38, wall=10485
2020-10-13 13:23:13 | INFO | train_inner | epoch 033:    608 / 756 loss=4.135, nll_loss=2.472, ppl=5.55, wps=37832.7, ups=2.47, wpb=15291.6, bsz=576, num_updates=24800, lr=8.03219e-05, gnorm=0.676, clip=0, train_wall=38, wall=10526
2020-10-13 13:23:53 | INFO | train_inner | epoch 033:    708 / 756 loss=4.126, nll_loss=2.463, ppl=5.51, wps=37556.3, ups=2.47, wpb=15231.8, bsz=562.6, num_updates=24900, lr=8.01605e-05, gnorm=0.675, clip=0, train_wall=38, wall=10566
2020-10-13 13:24:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 13:24:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28891.28515625Mb; avail=215636.375Mb
2020-10-13 13:24:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001917
2020-10-13 13:24:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28891.28515625Mb; avail=215636.375Mb
2020-10-13 13:24:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.140522
2020-10-13 13:24:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28891.28515625Mb; avail=215636.375Mb
2020-10-13 13:24:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.100370
2020-10-13 13:24:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.243786
2020-10-13 13:24:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28891.28515625Mb; avail=215636.375Mb
2020-10-13 13:24:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28891.28515625Mb; avail=215636.375Mb
2020-10-13 13:24:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001924
2020-10-13 13:24:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28891.28515625Mb; avail=215636.375Mb
2020-10-13 13:24:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.139960
2020-10-13 13:24:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28891.3203125Mb; avail=215636.56640625Mb
2020-10-13 13:24:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.100481
2020-10-13 13:24:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.243403
2020-10-13 13:24:13 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28896.2265625Mb; avail=215631.265625Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:24:21 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 4.557 | nll_loss 2.848 | ppl 7.2 | wps 74223.6 | wpb 4934.1 | bsz 184.1 | num_updates 24948 | best_loss 4.544
2020-10-13 13:24:21 | INFO | fairseq_cli.train | begin save checkpoint
2020-10-13 13:24:25 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/checkpoint_last.pt (epoch 33 @ 24948 updates, score 4.557) (writing took 4.154665102949366 seconds)
2020-10-13 13:24:26 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2020-10-13 13:24:26 | INFO | train | epoch 033 | loss 4.12 | nll_loss 2.456 | ppl 5.49 | wps 34684.3 | ups 2.29 | wpb 15167.6 | bsz 563 | num_updates 24948 | lr 8.00833e-05 | gnorm 0.679 | clip 0 | train_wall 289 | wall 10599
2020-10-13 13:24:26 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=34/shard_epoch=33
2020-10-13 13:24:26 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=34/shard_epoch=34
2020-10-13 13:24:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28347.74609375Mb; avail=216180.04296875Mb
2020-10-13 13:24:26 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.008628
2020-10-13 13:24:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.141741
2020-10-13 13:24:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28360.546875Mb; avail=216167.50390625Mb
2020-10-13 13:24:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.007918
2020-10-13 13:24:26 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28360.546875Mb; avail=216167.50390625Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:24:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:03.105656
2020-10-13 13:24:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:03.257178
2020-10-13 13:24:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29568.79296875Mb; avail=214959.265625Mb
2020-10-13 13:24:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=29566.97265625Mb; avail=214961.27734375Mb
2020-10-13 13:24:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.122222
2020-10-13 13:24:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29569.4921875Mb; avail=214958.73828125Mb
2020-10-13 13:24:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.008510
2020-10-13 13:24:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=29570.09765625Mb; avail=214958.1328125Mb
2020-10-13 13:24:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.434683
2020-10-13 13:24:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.567192
2020-10-13 13:24:32 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28914.3046875Mb; avail=215613.30859375Mb
2020-10-13 13:24:32 | INFO | fairseq.trainer | begin training epoch 34
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:24:58 | INFO | train_inner | epoch 034:     52 / 756 loss=4.131, nll_loss=2.466, ppl=5.53, wps=23169.6, ups=1.55, wpb=14932.2, bsz=560.1, num_updates=25000, lr=8e-05, gnorm=0.702, clip=0, train_wall=38, wall=10631
2020-10-13 13:25:38 | INFO | train_inner | epoch 034:    152 / 756 loss=4.1, nll_loss=2.432, ppl=5.4, wps=37945.2, ups=2.48, wpb=15323.6, bsz=546.6, num_updates=25100, lr=7.98405e-05, gnorm=0.666, clip=0, train_wall=38, wall=10671
2020-10-13 13:26:19 | INFO | train_inner | epoch 034:    252 / 756 loss=4.102, nll_loss=2.435, ppl=5.41, wps=37347.5, ups=2.47, wpb=15117.5, bsz=523.9, num_updates=25200, lr=7.96819e-05, gnorm=0.677, clip=0, train_wall=38, wall=10712
2020-10-13 13:26:59 | INFO | train_inner | epoch 034:    352 / 756 loss=4.105, nll_loss=2.438, ppl=5.42, wps=37586, ups=2.48, wpb=15170.2, bsz=563.8, num_updates=25300, lr=7.95243e-05, gnorm=0.696, clip=0, train_wall=38, wall=10752
2020-10-13 13:27:40 | INFO | train_inner | epoch 034:    452 / 756 loss=4.097, nll_loss=2.43, ppl=5.39, wps=37509.9, ups=2.46, wpb=15244.7, bsz=576.7, num_updates=25400, lr=7.93676e-05, gnorm=0.668, clip=0, train_wall=38, wall=10793
2020-10-13 13:28:20 | INFO | train_inner | epoch 034:    552 / 756 loss=4.099, nll_loss=2.432, ppl=5.4, wps=37256.5, ups=2.47, wpb=15080.3, bsz=576.6, num_updates=25500, lr=7.92118e-05, gnorm=0.674, clip=0, train_wall=38, wall=10833
2020-10-13 13:29:01 | INFO | train_inner | epoch 034:    652 / 756 loss=4.108, nll_loss=2.442, ppl=5.44, wps=37522, ups=2.46, wpb=15267.9, bsz=562.3, num_updates=25600, lr=7.90569e-05, gnorm=0.699, clip=0, train_wall=38, wall=10874
2020-10-13 13:29:41 | INFO | train_inner | epoch 034:    752 / 756 loss=4.092, nll_loss=2.424, ppl=5.37, wps=37249.4, ups=2.46, wpb=15132.2, bsz=591.4, num_updates=25700, lr=7.8903e-05, gnorm=0.684, clip=0, train_wall=38, wall=10914
2020-10-13 13:29:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 13:29:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28907.2734375Mb; avail=215620.07421875Mb
2020-10-13 13:29:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003357
2020-10-13 13:29:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28907.7734375Mb; avail=215619.57421875Mb
2020-10-13 13:29:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.319455
2020-10-13 13:29:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28902.14453125Mb; avail=215625.4453125Mb
2020-10-13 13:29:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.169849
2020-10-13 13:29:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.494240
2020-10-13 13:29:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28902.8125Mb; avail=215624.89453125Mb
2020-10-13 13:29:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28902.8125Mb; avail=215624.89453125Mb
2020-10-13 13:29:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002119
2020-10-13 13:29:43 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28902.8125Mb; avail=215624.89453125Mb
2020-10-13 13:29:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.230637
2020-10-13 13:29:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28902.8125Mb; avail=215624.89453125Mb
2020-10-13 13:29:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.130324
2020-10-13 13:29:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.364188
2020-10-13 13:29:44 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28917.13671875Mb; avail=215610.5703125Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:29:52 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 4.546 | nll_loss 2.837 | ppl 7.14 | wps 69773.7 | wpb 4934.1 | bsz 184.1 | num_updates 25704 | best_loss 4.544
2020-10-13 13:29:52 | INFO | fairseq_cli.train | begin save checkpoint
2020-10-13 13:29:56 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/checkpoint_last.pt (epoch 34 @ 25704 updates, score 4.546) (writing took 3.9149438010063022 seconds)
2020-10-13 13:29:56 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2020-10-13 13:29:56 | INFO | train | epoch 034 | loss 4.102 | nll_loss 2.435 | ppl 5.41 | wps 34701.7 | ups 2.29 | wpb 15167.8 | bsz 563 | num_updates 25704 | lr 7.88968e-05 | gnorm 0.683 | clip 0 | train_wall 289 | wall 10929
2020-10-13 13:29:56 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=35/shard_epoch=34
2020-10-13 13:29:56 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=35/shard_epoch=35
2020-10-13 13:29:56 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28373.87890625Mb; avail=216153.19921875Mb
2020-10-13 13:29:56 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.009559
2020-10-13 13:29:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.111884
2020-10-13 13:29:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28378.6953125Mb; avail=216148.3828125Mb
2020-10-13 13:29:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.007251
2020-10-13 13:29:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28378.6953125Mb; avail=216148.3828125Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:29:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.066558
2020-10-13 13:29:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.187196
2020-10-13 13:29:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28654.2578125Mb; avail=215873.81640625Mb
2020-10-13 13:29:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=28651.64453125Mb; avail=215876.4296875Mb
2020-10-13 13:29:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.099199
2020-10-13 13:29:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28657.98828125Mb; avail=215871.0703125Mb
2020-10-13 13:29:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.005439
2020-10-13 13:29:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28648.63671875Mb; avail=215879.4375Mb
2020-10-13 13:30:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.037478
2020-10-13 13:30:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.143520
2020-10-13 13:30:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=28531.3203125Mb; avail=215996.671875Mb
2020-10-13 13:30:01 | INFO | fairseq.trainer | begin training epoch 35
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:30:44 | INFO | train_inner | epoch 035:     96 / 756 loss=4.078, nll_loss=2.407, ppl=5.3, wps=24282.5, ups=1.6, wpb=15221.7, bsz=574.6, num_updates=25800, lr=7.87499e-05, gnorm=0.679, clip=0, train_wall=38, wall=10977
2020-10-13 13:31:25 | INFO | train_inner | epoch 035:    196 / 756 loss=4.062, nll_loss=2.39, ppl=5.24, wps=37421.9, ups=2.45, wpb=15265.1, bsz=588.3, num_updates=25900, lr=7.85977e-05, gnorm=0.684, clip=0, train_wall=39, wall=11018
2020-10-13 13:32:06 | INFO | train_inner | epoch 035:    296 / 756 loss=4.091, nll_loss=2.421, ppl=5.36, wps=36257.6, ups=2.42, wpb=15012.5, bsz=546.4, num_updates=26000, lr=7.84465e-05, gnorm=0.687, clip=0, train_wall=39, wall=11059
2020-10-13 13:32:47 | INFO | train_inner | epoch 035:    396 / 756 loss=4.09, nll_loss=2.421, ppl=5.36, wps=36871.5, ups=2.46, wpb=14993.6, bsz=553.5, num_updates=26100, lr=7.8296e-05, gnorm=0.708, clip=0, train_wall=38, wall=11100
2020-10-13 13:33:23 | INFO | train_inner | epoch 035:    496 / 756 loss=4.088, nll_loss=2.419, ppl=5.35, wps=41768.1, ups=2.74, wpb=15225.6, bsz=552.5, num_updates=26200, lr=7.81465e-05, gnorm=0.672, clip=0, train_wall=35, wall=11136
2020-10-13 13:34:04 | INFO | train_inner | epoch 035:    596 / 756 loss=4.094, nll_loss=2.426, ppl=5.37, wps=39524.3, ups=2.58, wpb=15296.9, bsz=547.3, num_updates=26300, lr=7.79978e-05, gnorm=0.675, clip=0, train_wall=37, wall=11177
2020-10-13 13:34:44 | INFO | train_inner | epoch 035:    696 / 756 loss=4.091, nll_loss=2.422, ppl=5.36, wps=38079.4, ups=2.5, wpb=15248.6, bsz=570.7, num_updates=26400, lr=7.78499e-05, gnorm=0.671, clip=0, train_wall=38, wall=11217
2020-10-13 13:35:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 13:35:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=22471.87109375Mb; avail=222080.9296875Mb
2020-10-13 13:35:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002239
2020-10-13 13:35:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22471.87109375Mb; avail=222080.9296875Mb
2020-10-13 13:35:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.317616
2020-10-13 13:35:09 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22472.07421875Mb; avail=222081.12890625Mb
2020-10-13 13:35:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.219380
2020-10-13 13:35:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.540671
2020-10-13 13:35:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22473.2265625Mb; avail=222079.37109375Mb
2020-10-13 13:35:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=22477.46484375Mb; avail=222075.73828125Mb
2020-10-13 13:35:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003042
2020-10-13 13:35:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22477.46484375Mb; avail=222075.73828125Mb
2020-10-13 13:35:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.323095
2020-10-13 13:35:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22489.80078125Mb; avail=222062.79296875Mb
2020-10-13 13:35:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.236554
2020-10-13 13:35:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.564410
2020-10-13 13:35:10 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22472.66796875Mb; avail=222080.53125Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:35:18 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 4.541 | nll_loss 2.829 | ppl 7.11 | wps 65724.2 | wpb 4934.1 | bsz 184.1 | num_updates 26460 | best_loss 4.541
2020-10-13 13:35:18 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:35:25 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/checkpoint_best.pt (epoch 35 @ 26460 updates, score 4.541) (writing took 6.502921475097537 seconds)
2020-10-13 13:35:25 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2020-10-13 13:35:25 | INFO | train | epoch 035 | loss 4.085 | nll_loss 2.416 | ppl 5.34 | wps 34871.3 | ups 2.3 | wpb 15167.9 | bsz 562.8 | num_updates 26460 | lr 7.77616e-05 | gnorm 0.684 | clip 0 | train_wall 285 | wall 11258
2020-10-13 13:35:25 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=36/shard_epoch=35
2020-10-13 13:35:25 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=36/shard_epoch=36
2020-10-13 13:35:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=22088.46875Mb; avail=222464.71875Mb
2020-10-13 13:35:25 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.017009
2020-10-13 13:35:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.156042
2020-10-13 13:35:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22106.45703125Mb; avail=222446.73046875Mb
2020-10-13 13:35:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.007508
2020-10-13 13:35:25 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22107.66796875Mb; avail=222445.51953125Mb
2020-10-13 13:35:27 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.735776
2020-10-13 13:35:27 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.901507
2020-10-13 13:35:27 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22491.640625Mb; avail=222061.8828125Mb
2020-10-13 13:35:27 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=22514.6484375Mb; avail=222038.875Mb
2020-10-13 13:35:27 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.102700
2020-10-13 13:35:27 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22524.921875Mb; avail=222028.6015625Mb
2020-10-13 13:35:27 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.009766
2020-10-13 13:35:27 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22525.52734375Mb; avail=222027.99609375Mb
2020-10-13 13:35:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.739799
2020-10-13 13:35:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.853956
2020-10-13 13:35:29 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22575.96875Mb; avail=221977.140625Mb
2020-10-13 13:35:29 | INFO | fairseq.trainer | begin training epoch 36
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:35:50 | INFO | train_inner | epoch 036:     40 / 756 loss=4.072, nll_loss=2.402, ppl=5.29, wps=22921.8, ups=1.54, wpb=14924.2, bsz=570.6, num_updates=26500, lr=7.77029e-05, gnorm=0.701, clip=0, train_wall=38, wall=11282
2020-10-13 13:36:30 | INFO | train_inner | epoch 036:    140 / 756 loss=4.063, nll_loss=2.39, ppl=5.24, wps=37060.8, ups=2.44, wpb=15159.7, bsz=535.4, num_updates=26600, lr=7.75567e-05, gnorm=0.689, clip=0, train_wall=39, wall=11323
2020-10-13 13:37:12 | INFO | train_inner | epoch 036:    240 / 756 loss=4.063, nll_loss=2.39, ppl=5.24, wps=36682.8, ups=2.42, wpb=15138.3, bsz=579.9, num_updates=26700, lr=7.74113e-05, gnorm=0.68, clip=0, train_wall=39, wall=11365
2020-10-13 13:37:53 | INFO | train_inner | epoch 036:    340 / 756 loss=4.078, nll_loss=2.407, ppl=5.3, wps=37147.3, ups=2.42, wpb=15366.2, bsz=555.8, num_updates=26800, lr=7.72667e-05, gnorm=0.684, clip=0, train_wall=39, wall=11406
2020-10-13 13:38:34 | INFO | train_inner | epoch 036:    440 / 756 loss=4.07, nll_loss=2.399, ppl=5.27, wps=36995.8, ups=2.43, wpb=15254.5, bsz=526.5, num_updates=26900, lr=7.7123e-05, gnorm=0.687, clip=0, train_wall=39, wall=11447
2020-10-13 13:39:16 | INFO | train_inner | epoch 036:    540 / 756 loss=4.069, nll_loss=2.397, ppl=5.27, wps=36668.8, ups=2.41, wpb=15233, bsz=605.4, num_updates=27000, lr=7.698e-05, gnorm=0.684, clip=0, train_wall=39, wall=11489
2020-10-13 13:39:57 | INFO | train_inner | epoch 036:    640 / 756 loss=4.078, nll_loss=2.408, ppl=5.31, wps=36268.9, ups=2.42, wpb=14963.3, bsz=552.8, num_updates=27100, lr=7.68379e-05, gnorm=0.689, clip=0, train_wall=39, wall=11530
2020-10-13 13:40:38 | INFO | train_inner | epoch 036:    740 / 756 loss=4.066, nll_loss=2.394, ppl=5.26, wps=36962.7, ups=2.42, wpb=15271.1, bsz=585.6, num_updates=27200, lr=7.66965e-05, gnorm=0.68, clip=0, train_wall=39, wall=11571
2020-10-13 13:40:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 13:40:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=22504.66015625Mb; avail=222048.12109375Mb
2020-10-13 13:40:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002565
2020-10-13 13:40:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22504.66015625Mb; avail=222048.12109375Mb
2020-10-13 13:40:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.150506
2020-10-13 13:40:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22493.828125Mb; avail=222059.01171875Mb
2020-10-13 13:40:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.110282
2020-10-13 13:40:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.264809
2020-10-13 13:40:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22494.046875Mb; avail=222058.79296875Mb
2020-10-13 13:40:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=22494.046875Mb; avail=222058.79296875Mb
2020-10-13 13:40:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001953
2020-10-13 13:40:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22494.046875Mb; avail=222058.79296875Mb
2020-10-13 13:40:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.140933
2020-10-13 13:40:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22497.60546875Mb; avail=222055.4453125Mb
2020-10-13 13:40:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.109564
2020-10-13 13:40:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.253501
2020-10-13 13:40:45 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22499.609375Mb; avail=222052.96875Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:40:54 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 4.542 | nll_loss 2.828 | ppl 7.1 | wps 73595.1 | wpb 4934.1 | bsz 184.1 | num_updates 27216 | best_loss 4.541
2020-10-13 13:40:54 | INFO | fairseq_cli.train | begin save checkpoint
2020-10-13 13:40:57 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/checkpoint_last.pt (epoch 36 @ 27216 updates, score 4.542) (writing took 3.9109728450421244 seconds)
2020-10-13 13:40:58 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2020-10-13 13:40:58 | INFO | train | epoch 036 | loss 4.069 | nll_loss 2.397 | ppl 5.27 | wps 34466.4 | ups 2.27 | wpb 15168.2 | bsz 563 | num_updates 27216 | lr 7.6674e-05 | gnorm 0.685 | clip 0 | train_wall 294 | wall 11591
2020-10-13 13:40:58 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=37/shard_epoch=36
2020-10-13 13:40:58 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=37/shard_epoch=37
2020-10-13 13:40:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=21985.6171875Mb; avail=222567.9375Mb
2020-10-13 13:40:58 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.017598
2020-10-13 13:40:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.176992
2020-10-13 13:40:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=21999.625Mb; avail=222553.9296875Mb
2020-10-13 13:40:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.007918
2020-10-13 13:40:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22000.23046875Mb; avail=222553.32421875Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:41:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.776075
2020-10-13 13:41:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.962640
2020-10-13 13:41:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23101.96875Mb; avail=221451.58203125Mb
2020-10-13 13:41:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=23126.29296875Mb; avail=221427.75Mb
2020-10-13 13:41:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.079960
2020-10-13 13:41:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23125.80078125Mb; avail=221427.75Mb
2020-10-13 13:41:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.005356
2020-10-13 13:41:01 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23126.04296875Mb; avail=221427.5078125Mb
2020-10-13 13:41:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.640750
2020-10-13 13:41:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.727185
2020-10-13 13:41:03 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23159.2734375Mb; avail=221393.84375Mb
2020-10-13 13:41:03 | INFO | fairseq.trainer | begin training epoch 37
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:41:41 | INFO | train_inner | epoch 037:     84 / 756 loss=4.053, nll_loss=2.379, ppl=5.2, wps=23915.6, ups=1.6, wpb=14977.9, bsz=573.4, num_updates=27300, lr=7.65559e-05, gnorm=0.701, clip=0, train_wall=39, wall=11634
2020-10-13 13:42:22 | INFO | train_inner | epoch 037:    184 / 756 loss=4.031, nll_loss=2.355, ppl=5.12, wps=37087.2, ups=2.42, wpb=15308.1, bsz=574.2, num_updates=27400, lr=7.64161e-05, gnorm=0.677, clip=0, train_wall=39, wall=11675
2020-10-13 13:43:04 | INFO | train_inner | epoch 037:    284 / 756 loss=4.042, nll_loss=2.366, ppl=5.16, wps=36450, ups=2.42, wpb=15068.5, bsz=604.6, num_updates=27500, lr=7.6277e-05, gnorm=0.693, clip=0, train_wall=39, wall=11717
2020-10-13 13:43:45 | INFO | train_inner | epoch 037:    384 / 756 loss=4.049, nll_loss=2.374, ppl=5.18, wps=36888.5, ups=2.45, wpb=15073, bsz=526.2, num_updates=27600, lr=7.61387e-05, gnorm=0.692, clip=0, train_wall=39, wall=11757
2020-10-13 13:44:26 | INFO | train_inner | epoch 037:    484 / 756 loss=4.058, nll_loss=2.385, ppl=5.22, wps=36662.8, ups=2.4, wpb=15256.4, bsz=555.5, num_updates=27700, lr=7.60011e-05, gnorm=0.679, clip=0, train_wall=39, wall=11799
2020-10-13 13:45:08 | INFO | train_inner | epoch 037:    584 / 756 loss=4.071, nll_loss=2.4, ppl=5.28, wps=36583.1, ups=2.41, wpb=15174.3, bsz=534.3, num_updates=27800, lr=7.58643e-05, gnorm=0.693, clip=0, train_wall=39, wall=11841
2020-10-13 13:45:49 | INFO | train_inner | epoch 037:    684 / 756 loss=4.058, nll_loss=2.385, ppl=5.23, wps=36841, ups=2.41, wpb=15276, bsz=584, num_updates=27900, lr=7.57282e-05, gnorm=0.682, clip=0, train_wall=39, wall=11882
2020-10-13 13:46:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 13:46:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=22467.63671875Mb; avail=222085.56640625Mb
2020-10-13 13:46:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.004292
2020-10-13 13:46:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22467.14453125Mb; avail=222086.05859375Mb
2020-10-13 13:46:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.144189
2020-10-13 13:46:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22464.265625Mb; avail=222088.9375Mb
2020-10-13 13:46:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.099440
2020-10-13 13:46:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.249141
2020-10-13 13:46:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22461.7421875Mb; avail=222091.4609375Mb
2020-10-13 13:46:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=22463.55859375Mb; avail=222089.64453125Mb
2020-10-13 13:46:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.002203
2020-10-13 13:46:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22463.55859375Mb; avail=222089.64453125Mb
2020-10-13 13:46:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.188737
2020-10-13 13:46:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22457.34765625Mb; avail=222095.85546875Mb
2020-10-13 13:46:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.233191
2020-10-13 13:46:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.425590
2020-10-13 13:46:19 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22457.02734375Mb; avail=222096.17578125Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:46:27 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 4.529 | nll_loss 2.818 | ppl 7.05 | wps 73869.5 | wpb 4934.1 | bsz 184.1 | num_updates 27972 | best_loss 4.529
2020-10-13 13:46:27 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:46:34 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/checkpoint_best.pt (epoch 37 @ 27972 updates, score 4.529) (writing took 6.770969489822164 seconds)
2020-10-13 13:46:35 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2020-10-13 13:46:35 | INFO | train | epoch 037 | loss 4.054 | nll_loss 2.38 | ppl 5.2 | wps 34049.5 | ups 2.24 | wpb 15168 | bsz 563.1 | num_updates 27972 | lr 7.56307e-05 | gnorm 0.688 | clip 0 | train_wall 294 | wall 11928
2020-10-13 13:46:35 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=38/shard_epoch=37
2020-10-13 13:46:35 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=38/shard_epoch=38
2020-10-13 13:46:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=22129.78515625Mb; avail=222423.51171875Mb
2020-10-13 13:46:35 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.009114
2020-10-13 13:46:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.128093
2020-10-13 13:46:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22144.76171875Mb; avail=222408.53515625Mb
2020-10-13 13:46:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.007460
2020-10-13 13:46:35 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22145.97265625Mb; avail=222407.32421875Mb
2020-10-13 13:46:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.756638
2020-10-13 13:46:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.893929
2020-10-13 13:46:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22543.9375Mb; avail=222009.1640625Mb
2020-10-13 13:46:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=22465.99609375Mb; avail=222087.10546875Mb
2020-10-13 13:46:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.076145
2020-10-13 13:46:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22482.90625Mb; avail=222070.1953125Mb
2020-10-13 13:46:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.004569
2020-10-13 13:46:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22482.90625Mb; avail=222070.1953125Mb
2020-10-13 13:46:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.607566
2020-10-13 13:46:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.689395
2020-10-13 13:46:38 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22522.54296875Mb; avail=222030.5546875Mb
2020-10-13 13:46:38 | INFO | fairseq.trainer | begin training epoch 38
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:46:54 | INFO | train_inner | epoch 038:     28 / 756 loss=4.069, nll_loss=2.396, ppl=5.26, wps=23062.3, ups=1.53, wpb=15053.8, bsz=550.7, num_updates=28000, lr=7.55929e-05, gnorm=0.693, clip=0, train_wall=39, wall=11947
2020-10-13 13:47:36 | INFO | train_inner | epoch 038:    128 / 756 loss=4.012, nll_loss=2.333, ppl=5.04, wps=36465.8, ups=2.4, wpb=15167.9, bsz=574.2, num_updates=28100, lr=7.54583e-05, gnorm=0.681, clip=0, train_wall=39, wall=11989
2020-10-13 13:48:17 | INFO | train_inner | epoch 038:    228 / 756 loss=4.03, nll_loss=2.353, ppl=5.11, wps=36920.1, ups=2.41, wpb=15314.5, bsz=588, num_updates=28200, lr=7.53244e-05, gnorm=0.7, clip=0, train_wall=39, wall=12030
2020-10-13 13:48:59 | INFO | train_inner | epoch 038:    328 / 756 loss=4.056, nll_loss=2.382, ppl=5.21, wps=36641.2, ups=2.42, wpb=15121, bsz=537.9, num_updates=28300, lr=7.51912e-05, gnorm=0.712, clip=0, train_wall=39, wall=12072
2020-10-13 13:49:40 | INFO | train_inner | epoch 038:    428 / 756 loss=4.04, nll_loss=2.364, ppl=5.15, wps=37129.4, ups=2.42, wpb=15322.4, bsz=568.1, num_updates=28400, lr=7.50587e-05, gnorm=0.7, clip=0, train_wall=39, wall=12113
2020-10-13 13:50:21 | INFO | train_inner | epoch 038:    528 / 756 loss=4.04, nll_loss=2.364, ppl=5.15, wps=36644.3, ups=2.44, wpb=14989.6, bsz=541, num_updates=28500, lr=7.49269e-05, gnorm=0.698, clip=0, train_wall=39, wall=12154
2020-10-13 13:51:02 | INFO | train_inner | epoch 038:    628 / 756 loss=4.046, nll_loss=2.371, ppl=5.17, wps=37226.2, ups=2.44, wpb=15279.9, bsz=593.1, num_updates=28600, lr=7.47958e-05, gnorm=0.684, clip=0, train_wall=38, wall=12195
2020-10-13 13:51:39 | INFO | train_inner | epoch 038:    728 / 756 loss=4.051, nll_loss=2.376, ppl=5.19, wps=40414.1, ups=2.69, wpb=15023, bsz=547.5, num_updates=28700, lr=7.46653e-05, gnorm=0.691, clip=0, train_wall=36, wall=12232
2020-10-13 13:51:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 13:51:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=15294.4375Mb; avail=229258.75390625Mb
2020-10-13 13:51:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001833
2020-10-13 13:51:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15294.4375Mb; avail=229258.75390625Mb
2020-10-13 13:51:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.138809
2020-10-13 13:51:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15287.38671875Mb; avail=229265.8046875Mb
2020-10-13 13:51:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.099042
2020-10-13 13:51:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.240506
2020-10-13 13:51:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15294.15234375Mb; avail=229259.0390625Mb
2020-10-13 13:51:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=15284.6796875Mb; avail=229268.51171875Mb
2020-10-13 13:51:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001796
2020-10-13 13:51:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15284.6796875Mb; avail=229268.51171875Mb
2020-10-13 13:51:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.138871
2020-10-13 13:51:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15294.77734375Mb; avail=229258.4140625Mb
2020-10-13 13:51:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.097848
2020-10-13 13:51:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.239370
2020-10-13 13:51:49 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15284.81640625Mb; avail=229268.77734375Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:51:55 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 4.528 | nll_loss 2.814 | ppl 7.03 | wps 85840.3 | wpb 4934.1 | bsz 184.1 | num_updates 28728 | best_loss 4.528
2020-10-13 13:51:55 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:52:02 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/checkpoint_best.pt (epoch 38 @ 28728 updates, score 4.528) (writing took 6.462182307150215 seconds)
2020-10-13 13:52:02 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2020-10-13 13:52:02 | INFO | train | epoch 038 | loss 4.039 | nll_loss 2.363 | ppl 5.14 | wps 35002.1 | ups 2.31 | wpb 15167.6 | bsz 563.1 | num_updates 28728 | lr 7.46289e-05 | gnorm 0.694 | clip 0 | train_wall 289 | wall 12255
2020-10-13 13:52:02 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=39/shard_epoch=38
2020-10-13 13:52:02 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=39/shard_epoch=39
2020-10-13 13:52:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=15796.49609375Mb; avail=228756.703125Mb
2020-10-13 13:52:02 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.014468
2020-10-13 13:52:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.141773
2020-10-13 13:52:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15828.05859375Mb; avail=228724.53515625Mb
2020-10-13 13:52:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.006042
2020-10-13 13:52:02 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=15828.6640625Mb; avail=228724.53515625Mb
2020-10-13 13:52:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:02.342481
2020-10-13 13:52:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.491788
2020-10-13 13:52:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=16132.3125Mb; avail=228420.765625Mb
2020-10-13 13:52:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=16139.578125Mb; avail=228413.5Mb
2020-10-13 13:52:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.102209
2020-10-13 13:52:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=16155.3046875Mb; avail=228397.7734375Mb
2020-10-13 13:52:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.005509
2020-10-13 13:52:05 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=16156.515625Mb; avail=228396.5625Mb
2020-10-13 13:52:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.856752
2020-10-13 13:52:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.965857
2020-10-13 13:52:07 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=16375.19140625Mb; avail=228177.88671875Mb
2020-10-13 13:52:07 | INFO | fairseq.trainer | begin training epoch 39
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:52:39 | INFO | train_inner | epoch 039:     72 / 756 loss=4.012, nll_loss=2.332, ppl=5.04, wps=25201.2, ups=1.68, wpb=14992.7, bsz=575.2, num_updates=28800, lr=7.45356e-05, gnorm=0.685, clip=0, train_wall=36, wall=12292
2020-10-13 13:53:19 | INFO | train_inner | epoch 039:    172 / 756 loss=4.001, nll_loss=2.321, ppl=5, wps=37441.9, ups=2.46, wpb=15236.8, bsz=591.2, num_updates=28900, lr=7.44065e-05, gnorm=0.683, clip=0, train_wall=38, wall=12332
2020-10-13 13:54:00 | INFO | train_inner | epoch 039:    272 / 756 loss=4.034, nll_loss=2.357, ppl=5.12, wps=36763.2, ups=2.44, wpb=15049.5, bsz=543.1, num_updates=29000, lr=7.42781e-05, gnorm=0.706, clip=0, train_wall=39, wall=12373
2020-10-13 13:54:41 | INFO | train_inner | epoch 039:    372 / 756 loss=4.033, nll_loss=2.356, ppl=5.12, wps=36393.9, ups=2.43, wpb=14993.6, bsz=519.2, num_updates=29100, lr=7.41504e-05, gnorm=0.706, clip=0, train_wall=39, wall=12414
2020-10-13 13:55:23 | INFO | train_inner | epoch 039:    472 / 756 loss=4.022, nll_loss=2.344, ppl=5.08, wps=36815.4, ups=2.41, wpb=15293.7, bsz=564.1, num_updates=29200, lr=7.40233e-05, gnorm=0.696, clip=0, train_wall=39, wall=12456
2020-10-13 13:56:04 | INFO | train_inner | epoch 039:    572 / 756 loss=4.031, nll_loss=2.354, ppl=5.11, wps=37207.8, ups=2.41, wpb=15424.2, bsz=574.6, num_updates=29300, lr=7.38969e-05, gnorm=0.686, clip=0, train_wall=39, wall=12497
2020-10-13 13:56:46 | INFO | train_inner | epoch 039:    672 / 756 loss=4.044, nll_loss=2.367, ppl=5.16, wps=36504.6, ups=2.41, wpb=15140, bsz=568.2, num_updates=29400, lr=7.37711e-05, gnorm=0.693, clip=0, train_wall=39, wall=12539
2020-10-13 13:57:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 13:57:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=22721.8046875Mb; avail=221831.15234375Mb
2020-10-13 13:57:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003488
2020-10-13 13:57:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22722.41015625Mb; avail=221830.546875Mb
2020-10-13 13:57:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.316568
2020-10-13 13:57:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22718.4453125Mb; avail=221834.51171875Mb
2020-10-13 13:57:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.190640
2020-10-13 13:57:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.512233
2020-10-13 13:57:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22719.03125Mb; avail=221833.92578125Mb
2020-10-13 13:57:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=22719.03125Mb; avail=221833.92578125Mb
2020-10-13 13:57:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.001966
2020-10-13 13:57:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22719.03125Mb; avail=221833.92578125Mb
2020-10-13 13:57:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.281524
2020-10-13 13:57:21 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22719.03125Mb; avail=221833.92578125Mb
2020-10-13 13:57:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.219602
2020-10-13 13:57:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.504501
2020-10-13 13:57:22 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22743.79296875Mb; avail=221809.1640625Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:57:30 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 4.526 | nll_loss 2.816 | ppl 7.04 | wps 75993.9 | wpb 4934.1 | bsz 184.1 | num_updates 29484 | best_loss 4.526
2020-10-13 13:57:30 | INFO | fairseq_cli.train | begin save checkpoint
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:57:37 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/checkpoint_best.pt (epoch 39 @ 29484 updates, score 4.526) (writing took 6.579474419122562 seconds)
2020-10-13 13:57:37 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2020-10-13 13:57:37 | INFO | train | epoch 039 | loss 4.025 | nll_loss 2.346 | ppl 5.09 | wps 34251.5 | ups 2.26 | wpb 15168.8 | bsz 563 | num_updates 29484 | lr 7.36659e-05 | gnorm 0.694 | clip 0 | train_wall 292 | wall 12590
2020-10-13 13:57:37 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=40/shard_epoch=39
2020-10-13 13:57:37 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=40/shard_epoch=40
2020-10-13 13:57:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=22408.859375Mb; avail=222142.62890625Mb
2020-10-13 13:57:37 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.017137
2020-10-13 13:57:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.168155
2020-10-13 13:57:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22413.31640625Mb; avail=222138.171875Mb
2020-10-13 13:57:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.008403
2020-10-13 13:57:37 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22413.921875Mb; avail=222137.56640625Mb
2020-10-13 13:57:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.972124
2020-10-13 13:57:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:02.150445
2020-10-13 13:57:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23105.21875Mb; avail=221448.2421875Mb
2020-10-13 13:57:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=23109.328125Mb; avail=221443.796875Mb
2020-10-13 13:57:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.076048
2020-10-13 13:57:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23113.5859375Mb; avail=221439.203125Mb
2020-10-13 13:57:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.006964
2020-10-13 13:57:39 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23116.828125Mb; avail=221435.71484375Mb
2020-10-13 13:57:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.586858
2020-10-13 13:57:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.670980
2020-10-13 13:57:41 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=23140.1328125Mb; avail=221412.265625Mb
2020-10-13 13:57:41 | INFO | fairseq.trainer | begin training epoch 40
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 13:57:52 | INFO | train_inner | epoch 040:     16 / 756 loss=4.014, nll_loss=2.336, ppl=5.05, wps=22850.1, ups=1.51, wpb=15095.4, bsz=568.3, num_updates=29500, lr=7.3646e-05, gnorm=0.697, clip=0, train_wall=39, wall=12605
2020-10-13 13:58:33 | INFO | train_inner | epoch 040:    116 / 756 loss=3.993, nll_loss=2.31, ppl=4.96, wps=36689.6, ups=2.42, wpb=15190.9, bsz=578.4, num_updates=29600, lr=7.35215e-05, gnorm=0.692, clip=0, train_wall=39, wall=12646
2020-10-13 13:59:15 | INFO | train_inner | epoch 040:    216 / 756 loss=4.012, nll_loss=2.331, ppl=5.03, wps=36613.2, ups=2.43, wpb=15056.1, bsz=541, num_updates=29700, lr=7.33976e-05, gnorm=0.693, clip=0, train_wall=39, wall=12687
2020-10-13 13:59:56 | INFO | train_inner | epoch 040:    316 / 756 loss=4.018, nll_loss=2.338, ppl=5.06, wps=37147.9, ups=2.44, wpb=15247.1, bsz=562.2, num_updates=29800, lr=7.32743e-05, gnorm=0.703, clip=0, train_wall=39, wall=12728
2020-10-13 14:00:37 | INFO | train_inner | epoch 040:    416 / 756 loss=4.008, nll_loss=2.329, ppl=5.02, wps=36587.4, ups=2.41, wpb=15180.5, bsz=559.1, num_updates=29900, lr=7.31517e-05, gnorm=0.694, clip=0, train_wall=39, wall=12770
2020-10-13 14:01:18 | INFO | train_inner | epoch 040:    516 / 756 loss=4.028, nll_loss=2.349, ppl=5.1, wps=36903.7, ups=2.42, wpb=15251.7, bsz=555.1, num_updates=30000, lr=7.30297e-05, gnorm=0.698, clip=0, train_wall=39, wall=12811
2020-10-13 14:02:00 | INFO | train_inner | epoch 040:    616 / 756 loss=3.999, nll_loss=2.318, ppl=4.99, wps=36951, ups=2.42, wpb=15285.5, bsz=589, num_updates=30100, lr=7.29083e-05, gnorm=0.681, clip=0, train_wall=39, wall=12853
2020-10-13 14:02:41 | INFO | train_inner | epoch 040:    716 / 756 loss=4.026, nll_loss=2.348, ppl=5.09, wps=36526.3, ups=2.42, wpb=15073.1, bsz=559.8, num_updates=30200, lr=7.27875e-05, gnorm=0.704, clip=0, train_wall=39, wall=12894
2020-10-13 14:02:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2020-10-13 14:02:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=22723.57421875Mb; avail=221829.09375Mb
2020-10-13 14:02:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003330
2020-10-13 14:02:57 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22723.57421875Mb; avail=221829.09375Mb
2020-10-13 14:02:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.331254
2020-10-13 14:02:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22724.46875Mb; avail=221828.2890625Mb
2020-10-13 14:02:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.234805
2020-10-13 14:02:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.571030
2020-10-13 14:02:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22735.33203125Mb; avail=221817.8203125Mb
2020-10-13 14:02:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=22725.4921875Mb; avail=221827.66015625Mb
2020-10-13 14:02:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler order indices time: 0:00:00.003194
2020-10-13 14:02:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22725.4921875Mb; avail=221827.66015625Mb
2020-10-13 14:02:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler filter_by_size time: 0:00:00.338722
2020-10-13 14:02:58 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22818.83203125Mb; avail=221734.3203125Mb
2020-10-13 14:02:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] @batch_sampler batch_by_size time: 0:00:00.223278
2020-10-13 14:02:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | [valid] per epoch batch_sampler set-up time: 0:00:00.566930
2020-10-13 14:02:59 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=22823.41796875Mb; avail=221729.734375Mb
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.
	Try to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.
2020-10-13 14:03:07 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 4.523 | nll_loss 2.809 | ppl 7.01 | wps 62833.9 | wpb 4934.1 | bsz 184.1 | num_updates 30240 | best_loss 4.523
2020-10-13 14:03:07 | INFO | fairseq_cli.train | begin save checkpoint
2020-10-13 14:03:13 | INFO | fairseq.checkpoint_utils | saved checkpoint fairseq/checkpoints/ted_belbeprusrup_sepspm8000/M2O/checkpoint_best.pt (epoch 40 @ 30240 updates, score 4.523) (writing took 6.550482975086197 seconds)
2020-10-13 14:03:14 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2020-10-13 14:03:14 | INFO | train | epoch 040 | loss 4.011 | nll_loss 2.331 | ppl 5.03 | wps 34066.4 | ups 2.25 | wpb 15167.7 | bsz 563 | num_updates 30240 | lr 7.27393e-05 | gnorm 0.697 | clip 0 | train_wall 294 | wall 12927
2020-10-13 14:03:14 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | establishing a new set of global virtual indices for epoch=41/shard_epoch=40
2020-10-13 14:03:14 | INFO | fairseq.data.multilingual.sampled_multi_epoch_dataset | to load next epoch/shard in next load_dataset: epoch=41/shard_epoch=41
2020-10-13 14:03:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | start batch sampler: mem usage: used=19481.421875Mb; avail=225083.88671875Mb
2020-10-13 14:03:14 | INFO | fairseq.data.multilingual.sampled_multi_dataset | sizes() calling time: 0:00:00.009260
2020-10-13 14:03:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler order indices time: 0:00:00.102401
2020-10-13 14:03:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=19486.3203125Mb; avail=225078.98828125Mb
2020-10-13 14:03:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler filter_by_size time: 0:00:00.004940
2020-10-13 14:03:14 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=19486.3203125Mb; avail=225078.98828125Mb
2020-10-13 14:03:15 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] @batch_sampler batch_by_size time: 0:00:01.601184
2020-10-13 14:03:15 | INFO | fairseq.tasks.translation_multi_simple_epoch | [train] per epoch batch_sampler set-up time: 0:00:01.709675
2020-10-13 14:03:15 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: used=19968.02734375Mb; avail=224597.53125Mb
2020-10-13 14:03:16 | INFO | fairseq_cli.train | done training in 12926.5 seconds
/home/ubuntu/anaconda3/envs/torch16/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 160 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
